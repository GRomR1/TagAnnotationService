Глава 2.
Процессы и потоки
Теперь мы перейдем к подробному рассмотрению разработки и устройства операционных
систем. Основным понятием в любой операционной системе является процесс:
абстракция, описывающая выполняющуюся программу. Все остальное зависит от этого
понятия, поэтому крайне важно, чтобы разработчики операционных систем (а также
студенты) получили полное представление о концепции процесса как можно раньше.
Процессы — это одна из самых старых и наиболее важных абстракций, присущих
операционной системе. Они поддерживают возможность осуществления (псевдо) параллельных
операций даже при наличии всего одного центрального процессора. Они
превращают один центральный процессор в несколько виртуальных. Без абстракции
процессов современные вычисления просто не могут существовать. В этой главе мы
углубимся во многие подробности, касающиеся процессов и их ближайших родственников
— потоков.
2.1. Процессы
Современные компьютеры, как правило, заняты сразу несколькими делами. Возможно,
люди, привыкшие к работе с компьютерами, не до конца осознают этот факт, поэтому
рассмотрим ряд примеров. Сначала представим себе веб-сервер. К нему отовсюду
приходят запросы, требующие предоставления веб-страниц. Когда приходит запрос,
сервер проверяет, нет ли нужной страницы в кэше. Если она там присутствует, он
отправляет эту страницу; если ее там нет, осуществляется запрос к диску для ее извлечения.
Но с точки зрения центрального процессора запрос информации с диска
занимает целую вечность. За время ожидания результатов запроса информации с диска
может поступить множество других запросов. Если в системе установлено несколько
дисков, то некоторые из новых запросов или все они могут быть направлены на другие
диски задолго до того, как будет удовлетворен первый запрос. Понятно, что нужен
какой-нибудь способ, чтобы смоделировать эту параллельную работу и управлять ею.
Справиться с этим помогают процессы (и особенно потоки).
Теперь рассмотрим персональный компьютер. При запуске системы запускается множество
процессов, о которых пользователь зачастую даже и не подозревает. Например,
может быть запущен процесс, ожидающий входящей электронной почты. Другой запущенный
процесс может принадлежать антивирусной программе и предназначаться для
периодической проверки доступности определений каких-нибудь новых вирусов. В дополнение
к этому могут быть запущены процессы, инициированные пользователем в явном
виде, — печать файлов или сброс пользовательских фотографий на USB-накопитель,
и все они работают одновременно с браузером, с помощью которого пользователь просматривает
Интернет. Всей этой работой нужно управлять, и здесь нам очень пригодится
многозадачная система, поддерживающая работу нескольких процессов.
В любой многозадачной системе центральный процессор быстро переключается
между процессами, предоставляя каждому из них десятки или сотни миллисекунд.
При этом хотя в каждый конкретный момент времени центральный процессор работает
только с одним процессом, в течение 1 секунды он может успеть поработать
с несколькими из них, создавая иллюзию параллельной работы. Иногда в этом случае
говорят о псевдопараллелизме в отличие от настоящего аппаратного параллелизма
в многопроцессорных системах (у которых имеется не менее двух центральных процессоров,
использующих одну и ту же физическую память). Людям довольно трудно
отслеживать несколько действий, происходящих параллельно. Поэтому разработчики
операционных систем за прошедшие годы создали концептуальную модель последовательных
процессов, упрощающую работу с параллельными вычислениями. Эта модель,
ее применение и некоторые последствия ее применения и станут темой данной главы.
2.1.1. Модель процесса
В этой модели все выполняемое на компьютере программное обеспечение, иногда
включая операционную систему, сведено к ряду последовательных процессов, или, для
краткости, просто процессов. Процесс — это просто экземпляр выполняемой программы,
включая текущие значения счетчика команд, регистров и переменных. Концептуально
у каждого процесса есть свой, виртуальный, центральный процессор. Разумеется,
на самом деле настоящий центральный процессор постоянно переключается между
процессами, но чтобы понять систему, куда проще думать о наборе процессов, запущенных
в (псевдо) параллельном режиме, чем пытаться отслеживать, как центральный
процессор переключается между программами. Это постоянное переключение между
процессами, как мы уяснили в главе 1, называется мультипрограммированием, или
многозадачным режимом работы.
На рис. 2.1, а показан компьютер, работающий в многозадачном режиме и имеющий
в памяти четыре программы. На рис. 2.1, б показаны четыре процесса, каждый из
которых имеет собственный алгоритм управления (то есть собственный логический
счетчик команд) и работает независимо от всех остальных. Понятно, что на самом деле
имеется только один физический счетчик команд, поэтому при запуске каждого процесса
его логический счетчик команд загружается в реальный счетчик. Когда работа
с процессом будет на некоторое время прекращена, значение физического счетчика
команд сохраняется в логическом счетчике команд, размещаемом процессом в памяти.
На рис. 2.1, в показано, что за довольно длительный период наблюдения продвинулись
вперед все процессы, но в каждый отдельно взятый момент времени реально работает
только один процесс.
В этой главе мы будем исходить из того, что в нашем распоряжении имеется
лишь один центральный процессор. Хотя все чаще такие предположения противоречат
истине, поскольку новые кристаллы зачастую являются многоядерными,
имеющими два, четыре и большее число ядер. Многоядерным кристаллам
и мультипроцессорам будет в основном посвящена глава 8, но сейчас нам проще
думать, что в конкретный момент времени работает только один центральный
процессор. Поэтому, когда мы говорим, что центральный процессор в действительности
способен в конкретный момент времени работать только с одним процессом,
то если он обладает двумя ядрами (или центральными процессорами), на каждом
из них в конкретный момент времени может запускаться только один процесс.
Рис. 2.1. Компьютер: а — четыре программы, работающие в многозадачном режиме;
б — концептуальная модель четырех независимых друг от друга последовательных процессов;
в — в отдельно взятый момент активна только одна программа
Поскольку центральный процессор переключается между процессами, скорость,
с которой процесс выполняет свои вычисления, не будет одинаковой и, скорее всего,
не сможет быть вновь показана, если тот же процесс будет запущен еще раз. Поэтому
процессы не должны программироваться с использованием каких-либо жестко заданных
предположений относительно времени их выполнения. Рассмотрим, к примеру,
аудиопроцесс, проигрывающий музыку для сопровождения высококачественного
видео, запущенного на другом устройстве. Поскольку аудио может быть запущено
немного позднее видео, аудиопроцесс сигнализирует видеосерверу о пуске проигрывания,
а затем перед проигрыванием аудио запускает холостой цикл 10 000 раз.
Если цикл послужит надежным таймером, то все пройдет как надо, но если же при
выполнении холостого цикла процессор решит переключиться на другой процесс,
аудиопроцесс может возобновиться, когда соответствующие кадры уже будут показаны,
и, к сожалению, синхронизация видео и аудио будет сбита. Когда у процесса
есть подобные критичные для его работы требования, касающиеся реального масштаба
времени, то через определенное количество миллисекунд должны происходить
конкретные события, и для того чтобы они произошли, должны быть предприняты
специальные меры. Но, как правило, на большинство процессов не влияют ни установленный
режим многозадачности центрального процессора, ни относительные
скорости выполнения различных процессов.
Разница между процессом и программой довольно тонкая, но весьма существенная.
Здесь нам, наверное, поможет какая-нибудь аналогия. Представим себе программиста,
решившего заняться кулинарией и испечь пирог на день рождения дочери. У него есть
рецепт пирога, а на кухне есть все ингредиенты: мука, яйца, сахар, ванильный экстракт
и т. д. В данной аналогии рецепт — это программа (то есть алгоритм, выраженный в некой
удобной форме записи), программист — это центральный процессор, а ингредиенты
пирога — это входные данные. Процесс — это действия, состоящие из чтения рецепта
нашим кулинаром, выбора ингредиентов и выпечки пирога.
Теперь представим, что на кухню вбегает сын программиста и кричит, что его ужалила
пчела. Программист записывает, на каком месте рецепта он остановился (сохраняется
состояние текущего процесса), достает книгу советов по оказанию первой помощи
и приступает к выполнению изложенных в ней инструкций. Перед нами процессор,
переключенный с одного процесса (выпечки) на другой процесс, имеющий более высокую
степень приоритета (оказание медицинской помощи), и у каждого из процессов
есть своя программа (рецепт против справочника по оказанию первой помощи). После
извлечения пчелиного жала программист возвращается к пирогу, продолжая выполнять
действия с того места, на котором остановился.
Ключевая идея здесь в том, что процесс — это своего рода действия. У него есть программа,
входные и выходные данные и состояние. Один процессор может совместно
использоваться несколькими процессами в соответствии с неким алгоритмом планирования,
который используется для определения того, когда остановить один процесс
и обслужить другой. В отличие от процесса программа может быть сохранена на диске
и вообще ничего не делать.
Стоит отметить, что если программа запущена дважды, то считается, что ею заняты два
процесса. Например, зачастую возможно дважды запустить текстовый процессор или
одновременно распечатать два файла, если одновременно доступны два принтера. Тот
факт, что два работающих процесса запущены от одной и той же программы, во внимание
не принимается, поскольку это два разных процесса. Операционная система может
позволить им использовать общий код, поэтому в памяти будет присутствовать только
одна копия этого кода, но это чисто техническая деталь, не меняющая концептуальную
ситуацию, касающуюся двух работающих процессов.
2.1.2. Создание процесса
Операционным системам необходим какой-нибудь способ для создания процессов.
В самых простых системах или в системах, сконструированных для запуска только
одного приложения (например, в контроллере микроволновой печи), появляется возможность
присутствия абсолютно всех необходимых процессов при вводе системы
в действие. Но в универсальных системах нужны определенные способы создания
и прекращения процессов по мере необходимости.
Существуют четыре основных события, приводящих к созданию процессов.
1. Инициализация системы.
2. Выполнение работающим процессом системного вызова, предназначенного для
создания процесса.
3. Запрос пользователя на создание нового процесса.
4. Инициация пакетного задания.
При запуске операционной системы создаются, как правило, несколько процессов.
Некоторые из них представляют собой высокоприоритетные процессы, то есть процессы,
взаимодействующие с пользователями и выполняющие для них определенную
работу. Остальные являются фоновыми процессами, не связанными с конкретными
пользователями, но выполняющими ряд специфических функций. Например, фоновый
процесс, который может быть создан для приема входящих сообщений электронной
почты, основную часть времени проводит в спящем режиме, активизируясь
только по мере появления писем. Другой фоновый процесс, который может быть
создан для приема входящих запросов на веб-страницы, размещенные на машине,
просыпается при поступлении запроса с целью его обслуживания. Фоновые процессы,
предназначенные для обработки какой-либо активной деятельности, связанной,
например, с электронной почтой, веб-страницами, новостями, выводом информации
на печать и т. д., называются демонами. Обычно у больших систем насчитываются
десятки демонов. В UNIX 1 для отображения списка запущенных процессов может
быть использована программа  ps . В Windows для этой цели может использоваться
диспетчер задач.
Вдобавок к процессам, созданным во время загрузки, новые процессы могут быть созданы
и после нее. Часто бывает так, что работающий процесс осуществляет системный
вызов для создания одного или более новых вспомогательных процессов. Создание
новых процессов особенно полезно, когда выполняемая работа может быть легко выражена
в понятиях нескольких связанных друг с другом, но в остальном независимых
друг от друга взаимодействующих процессов. Например, если из сети выбирается
большой объем данных для последующей обработки, наверное, будет удобно создать
один процесс для выборки данных и помещения их в общий буфер, чтобы в то же самое
время второй процесс забирал элементы данных и проводил их обработку. Также
можно ускорить выполнение работы, если на многопроцессорной системе разрешить
каждому процессу работать на разных центральных процессорах.
В интерактивных системах пользователи могут запустить программу вводом команды
или щелчком (двойным щелчком) на значке. Любое из этих действий дает начало новому
процессу и запускает в нем выбранную программу. В основанных на применении
команд UNIX-системах с работающей X-оболочкой новый процесс получает окно,
в котором он был запущен. При запуске в Microsoft Windows процесс не имеет окна,
но он может создать одно или несколько окон, и в большинстве случаев так и происходит.
В обеих системах пользователи могут одновременно открыть несколько окон,
в каждом из которых запущен какой-нибудь процесс. Используя мышь, пользователь
может выбрать окно и взаимодействовать с процессом, например, если потребуется,
вводить данные.
Последнее событие, приводящее к созданию процесса, применимо только к системам
пакетной обработки данных, имеющимся на больших универсальных машинах. Представьте
себе управление запасами товаров в конце рабочего дня в сети магазинов. Здесь
пользователи могут отправлять системе пакетные задания (возможно, с помощью удаленного
доступа). Когда операционная система решает, что у нее достаточно ресурсов
для запуска еще одного задания, она создает новый процесс и запускает новое задание
из имеющейся у нее очереди входящих заданий.
С технической точки зрения во всех этих случаях новый процесс создается за счет уже
существующего процесса, который выполняет системный вызов, предназначенный для
создания процесса. Этим процессом может быть работающий пользовательский процесс,
системный процесс, вызванный событиями клавиатуры или мыши, или процесс
управления пакетными заданиями. Данный процесс осуществляет системный вызов
для создания нового процесса. Этот системный вызов предписывает операционной
системе создать новый процесс и прямо или косвенно указывает, какую программу
в нем запустить.
В UNIX существует только один системный вызов для создания нового процесса —
fork. Этот вызов создает точную копию вызывающего процесса. После выполнения
системного вызова fork два процесса, родительский и дочерний, имеют единый образ
1 В этой главе под UNIX следует подразумевать практически все системы, основанные на
POSIX, включая Linux, FreeBSD, OS X, Solaris и т. д., и, за некоторым исключением, также
Android и iOS.
памяти, единые строки описания конфигурации и одни и те же открытые файлы.
И больше ничего. Обычно после этого дочерний процесс изменяет образ памяти
и запускает новую программу, выполняя системный вызов execve или ему подобный.
Например, когда пользователь набирает в оболочке команду sort, оболочка создает ответвляющийся
дочерний процесс, в котором и выполняется команда sort. Смысл этого
двухступенчатого процесса заключается в том, чтобы позволить дочернему процессу
управлять его файловыми дескрипторами после разветвления, но перед выполнением
execve с целью выполнения перенаправления стандартного ввода, стандартного вывода
и стандартного вывода сообщений об ошибках.
В Windows все происходит иначе: одним вызовом функции Win32 CreateProcess
создается процесс, и в него загружается нужная программа. У этого вызова имеется
10 параметров, включая выполняемую программу, параметры командной строки
для этой программы, различные параметры безопасности, биты, управляющие наследованием
открытых файлов, информацию о приоритетах, спецификацию окна,
создаваемого для процесса (если оно используется), и указатель на структуру, в которой
вызывающей программе будет возвращена информация о только что созданном
процессе. В дополнение к функции CreateProcess в Win32 имеется около 100 других
функций для управления процессами и их синхронизации, а также выполнения всего,
что с этим связано.
В обеих системах, UNIX и Windows, после создания процесса родительский и дочерний
процессы обладают своими собственными, отдельными адресными пространствами.
Если какой-нибудь процесс изменяет слово в своем адресном пространстве, другим
процессам эти изменения не видны. В UNIX первоначальное состояние адресного пространства
дочернего процесса является копией адресного пространства родительского
процесса, но это абсолютно разные адресные пространства — у них нет общей памяти,
доступной для записи данных. Некоторые реализации UNIX делят между процессами
текст программы без возможности его модификации. Кроме того, дочерний процесс
может совместно использовать всю память родительского процесса, но если память совместно
используется в режиме копирования при записи (copy on write), это означает,
что при каждой попытке любого из процессов модифицировать часть памяти эта часть
сначала явным образом копируется, чтобы гарантировать модификацию только в закрытой
области памяти. Следует также заметить, что память, используемая в режиме
записи, совместному использованию не подлежит.
Тем не менее вновь созданный процесс может делить со своим создателем часть других
ресурсов, например открытые файлы. В Windows адресные пространства родительского
и дочернего процессов различаются с самого начала.
2.1.3. Завершение процесса
После создания процесс начинает работать и выполняет свою задачу. Но ничто не длится
вечно, даже процессы. Рано или поздно новые процессы будут завершены, обычно
в силу следующих обстоятельств:
? обычного выхода (добровольно);
? выхода при возникновении ошибки (добровольно);
? возникновения фатальной ошибки (принудительно);
? уничтожения другим процессом (принудительно).
Большинство процессов завершаются по окончании своей работы. Когда компилятор
откомпилирует заданную ему программу, он осуществляет системный вызов, сообщающий
операционной системе о завершении своей работы. Этим вызовом в UNIX является
exit, а в Windows — ExitProcess. Программы, работающие с экраном, также
поддерживают добровольное завершение. Текстовые процессоры, интернет-браузеры
и аналогичные программы всегда содержат значок или пункт меню, на котором пользователь
может щелкнуть, чтобы приказать процессу удалить все временные файлы,
которые им были открыты, и завершить свою работу.
Вторая причина завершения — обнаружение процессом фатальной ошибки. Например,
если пользователь наберет команду
cc foo.c
с целью компиляции программы foo.c, а файла с таким именем не будет, то произойдет
простое объявление о наличии данного факта и выход из компилятора. Выхода из интерактивных,
использующих экран процессов при задании им неверных параметров
обычно не происходит. Вместо этого появляется диалоговое окно с просьбой о повторной
попытке ввода параметров.
Третья причина завершения — ошибка, вызванная самим процессом, чаще всего
связанная с ошибкой в программе. В качестве примеров можно привести неверную
инструкцию, ссылку на несуществующий адрес памяти или деление на нуль. В некоторых
системах (например, UNIX) процесс может сообщить операционной системе
о своем намерении обработать конкретные ошибки самостоятельно, в таком случае,
когда встречается одна из таких ошибок, процесс получает сигнал (прерывается), а не
завершается.
Четвертая причина, из-за которой процесс может быть завершен, — это выполнение
процессом системного вызова, приказывающего операционной системе завершить
некоторые другие процессы. В UNIX этот вызов называется kill. Соответствующая
функция Win32 называется TerminateProcess. В обоих случаях у процесса, вызывающего
завершение, должны быть на это соответствующие полномочия. В некоторых системах
при добровольном или принудительном завершении процесса тут же завершаются и все
созданные им процессы. Но ни UNIX, ни Windows так не делают.
2.1.4. Иерархии процессов
В некоторых системах, когда процесс порождает другой процесс, родительский и дочерний
процессы продолжают оставаться определенным образом связанными друг
с другом. Дочерний процесс может и сам создать какие-нибудь процессы, формируя
иерархию процессов. Следует заметить, что, в отличие от растений и животных, использующих
половую репродукцию, у процесса есть только один родитель (но нуль,
один, два или более детей). Следовательно, процесс больше похож на гидру, чем, скажем,
на корову.
В UNIX процесс, все его дочерние процессы и более отдаленные потомки образуют
группу процессов. Когда пользователь отправляет сигнал с клавиатуры, тот достигает
всех участников этой группы процессов, связанных на тот момент времени с клавиатурой
(обычно это все действующие процессы, которые были созданы в текущем окне).
Каждый процесс по отдельности может захватить сигнал, игнорировать его или совершить
действие по умолчанию, которое должно быть уничтожено сигналом.
В качестве другого примера, поясняющего ту ключевую роль, которую играет иерархия
процессов, давайте рассмотрим, как UNIX инициализирует саму себя при запуске
сразу же после начальной загрузки компьютера. В загрузочном образе присутствует
специальный процесс, называемый init. В начале своей работы он считывает файл,
сообщающий о количестве терминалов. Затем он разветвляется, порождая по одному
процессу на каждый терминал. Эти процессы ждут, пока кто-нибудь не зарегистрируется
в системе. Если регистрация проходит успешно, процесс регистрации порождает
оболочку для приема команд. Эти команды могут породить другие процессы и т. д.
Таким образом, все процессы во всей системе принадлежат единому дереву, в корне
которого находится процесс init.
В отличие от этого в Windows не существует понятия иерархии процессов, и все процессы
являются равнозначными. Единственным намеком на иерархию процессов
можно считать присвоение родительскому процессу, создающему новый процесс, специального
маркера (называемого дескриптором), который может им использоваться
для управления дочерним процессом. Но он может свободно передавать этот маркер
какому-нибудь другому процессу, нарушая тем самым иерархию. А в UNIX процессы
не могут лишаться наследственной связи со своими дочерними процессами.
2.1.5. Состояния процессов
Несмотря на самостоятельность каждого процесса, наличие собственного счетчика
команд и внутреннего состояния, процессам зачастую необходимо взаимодействовать
с другими процессами. Один процесс может генерировать выходную информацию, используемую
другими процессами в качестве входной информации. В команде оболочки
cat chapter1 chapter2 chapter3 | grep tree
первый процесс, запускающий программу cat, объединяет и выдает на выходе содержимое
трех файлов. Второй процесс, запускающий программу grep, выбирает все строки,
в которых содержится слово «tree». В зависимости от относительной скорости этих
двух процессов (которая зависит от двух факторов: относительной сложности программ
и количества выделяемого каждому из них времени работы центрального процессора)
может получиться так, что программа grep готова к работе, но ожидающие ее входные
данные отсутствуют. Тогда она должна блокироваться до поступления входных данных.
Процесс блокируется из-за того, что, по логике, он не может продолжаться, как правило,
потому что ожидает недоступных в настоящий момент входных данных. Может
случиться и так, что останавливается тот процесс, который в принципе готов к работе
и может быть запущен, а причина кроется в том, что операционная система решила на
некоторое время выделить центральный процессор другому процессу. Эти два условия
полностью отличаются друг от друга. В первом случае приостановка порождена какойнибудь
проблемой (вы не можете обработать пользовательскую командную строку,
пока она не будет введена). Во втором случае на первый план выступает техническая
сторона вопроса (не хватает центральных процессоров, чтобы каждому процессу выделить
собственный процессор). На рис. 2.2 показана диаграмма, отображающая три
состояния, в которых может находиться процесс:
? выполняемый (в данный момент использующий центральный процессор);
? готовый (работоспособный, но временно приостановленный, чтобы дать возможность
выполнения другому процессу);
? заблокированный (неспособный выполняться, пока не возникнет какое-нибудь
внешнее событие).
Логически первые два состояния похожи друг на друга. В обоих случаях процесс
желает выполняться, но во втором состоянии временно отсутствует доступный для
этого процессор. Третье состояние коренным образом отличается от первых двух тем,
что процесс не может выполняться, даже если процессору кроме него больше нечем
заняться.
Рис. 2.2. Процесс может быть в выполняемом, заблокированном или готовом состоянии.
Стрелками показаны переходы между этими состояниями
Как показано на рисунке, между этими тремя состояниями могут быть четыре перехода.
Переход 1 происходит в том случае, если операционная система определит, что
процесс в данный момент выполняться не может. В некоторых системах для перехода
в заблокированное состояние процесс может осуществить такой системный вызов,
как pause. В других системах, включая UNIX, когда процесс осуществляет чтение из
канала или специального файла (например, с терминала) и доступные входные данные
отсутствуют, процесс блокируется автоматически.
Переходы 2 и 3 вызываются планировщиком процессов, который является частью
операционной системы, без какого-либо оповещения самого процесса. Переход 2 происходит,
когда планировщик решит, что выполняемый процесс продвинулся достаточно
далеко и настало время позволить другому процессу получить долю рабочего времени
центрального процессора. Переход 3 происходит, когда все другие процессы получили
причитающуюся им долю времени и настал момент предоставить центральный процессор
первому процессу для возобновления его выполнения. Вопрос планирования,
то есть решение, какой именно процесс, когда и сколько времени должен выполняться,
играет весьма важную роль и будет рассмотрен в этой главе чуть позже. В попытках
сбалансировать конкурирующие требования соблюдения эффективности системы
в целом и справедливого отношения к отдельному процессу было изобретено множество
алгоритмов. Некоторые из них еще будут рассмотрены в этой главе.
Переход 4 осуществляется в том случае, если происходит внешнее событие, ожидавшееся
процессом (к примеру, поступление входных данных). Если к этому моменту
нет других выполняемых процессов, будет вызван переход 3 и процесс возобновится.
В противном случае ему придется немного подождать в состоянии готовности, пока не
станет доступен центральный процессор и не придет его очередь.
Использование модели процесса облегчает представление о том, что происходит внутри
системы. Некоторые процессы запускают программу, выполняющую команды, введенные
пользователем. Другие процессы являются частью системы, справляясь с такими
задачами, как выполнение запросов на обслуживание файлов или управление деталями
работы дискового или ленточного привода. Когда происходят дисковые прерывания,
система принимает решение остановить выполнение текущего процесса и запустить
процесс работы с диском, заблокированный в ожидании этого прерывания. Таким образом,
вместо того чтобы думать о прерываниях, мы можем думать о пользовательских
процессах, процессах работы с диском, процессах работы с терминалом и т. д., которые
блокируются, когда ожидают каких-то событий. Когда считана информация с диска
или набран символ, процесс, ожидающий это событие, разблокируется и получает
право на возобновление выполнения.
В результате такого представления возникает модель, показанная на рис. 2.3. На этом
рисунке самым нижним уровнем операционной системы является планировщик, над
которым изображен ряд процессов. Вся обработка прерываний и подробности действий,
запускающих и останавливающих процессы, здесь скрыты под тем, что называется
планировщиком, для реализации которого используется сравнительно небольшой
объем кода. Вся остальная часть операционной системы неплохо структурирована
в виде процессов. Но такой структурой обладает сравнительно небольшое количество
настоящих систем.
Рис. 2.3. Самый низший уровень структурированной в виде процессов
операционной системы обрабатывает прерывания и планирует выполнение процессов.
Выше этого уровня находятся последовательные процессы
2.1.6. Реализация процессов
Для реализации модели процессов операционная система ведет таблицу (состоящую
из массива структур), называемую таблицей процессов, в которой каждая запись соответствует
какому-нибудь процессу. (Ряд авторов называют эти записи блоками управления
процессом.) Эти записи содержат важную информацию о состоянии процесса,
включая счетчик команд, указатель стека, распределение памяти, состояние открытых
им файлов, его учетную и планировочную информацию и все остальное, касающееся
процесса, что должно быть сохранено, когда процесс переключается из состояния выполнения
в состояние готовности или блокировки, чтобы позже он мог возобновить
выполнение, как будто никогда не останавливался.
В табл. 2.1 показан ряд ключевых полей типовой системы. Поля первого столбца
относятся к управлению процессами. Поля остальных двух столбцов относятся
к управлению памятью и файлами соответственно. Следует заметить, что наличие
тех или иных полей в таблице процессов в большей степени зависит от системы, но
в этой таблице изложено основное представление о типе необходимой информации.
Теперь, после изучения таблицы процессов, появилась возможность чуть лучше объяснить,
как создается иллюзия нескольких последовательных процессов, выполняемых
на одном (или на каждом) центральном процессоре. Существует область памяти
(обычно это фиксированная область в нижних адресах), связанная с каждым классом
устройств ввода-вывода, которая называется вектором прерывания. В ней содержится
адрес процедуры, обслуживающей прерывание. Предположим, что при возникновении
дискового прерывания выполнялся пользовательский процесс № 3. Счетчик команд
Таблица 2.1. Некоторые из полей типичной записи таблицы процессов
Управление процессом Управление памятью Управление файлами
Регистры Указатель на информацию
о текстовом сегменте
Корневой каталог
Счетчик команд Указатель на информацию
о сегменте данных
Рабочий каталог
Слово состояния программы Указатель на информацию
о сегменте стека
Дескрипторы файлов
Указатель стека Идентификатор пользователя
Состояние процесса Идентификатор группы
Приоритет
Параметры планирования
Идентификатор процесса
Родительский процесс
Группа процесса
Сигналы
Время запуска процесса
Использованное время процессора
Время процессора, использованное дочерними процессами
Время следующего аварийного сигнала
этого процесса, слово состояния программы, а иногда и один или несколько регистров
помещаются в текущий стек аппаратными средствами прерывания. Затем компьютер
переходит на адрес, указанный в векторе прерывания. На этом работа аппаратных
средств заканчивается и вступает в действие программное обеспечение, а именно процедура
обслуживания прерывания.
Все прерывания сначала сохраняют состояния регистров, зачастую используя для
этого запись текущего процесса в таблице процессов. Затем информация, помещенная
в стек прерыванием, удаляется и указатель стека переустанавливается на временный
стек, используемый обработчиком прерывания. Такие действия, как сохранение регистров
и переустановка указателя стека, не могут быть выражены на языках высокого
уровня (например, C), поэтому они выполняются небольшой подпрограммой на языке
ассемблера, обычно одной и той же для всех прерываний, поскольку характер работы
по сохранению регистров не изменяется, какой бы ни была причина прерывания.
Когда эта подпрограмма завершает свою работу, она вызывает C-процедуру, которая
делает всю остальную работу для данного конкретного типа прерывания. (Мы предполагаем,
что операционная система написана на языке C, который обычно и выбирается
для всех настоящих операционных систем.) Возможно, когда работа этой процедуры
будет завершена, какой-нибудь процесс переходит в состояние готовности к работе
и вызывается планировщик, чтобы определить, какой процесс будет выполняться
следующим. После этого управление передается обратно коду, написанному на языке
ассемблера, чтобы он загрузил для нового текущего процесса регистры и карту памяти
и запустил выполнение этого процесса. Краткое изложение процесса обработки прерывания
и планирования приведено в табл. 2.2. Следует заметить, что детали от системы
к системе могут несколько различаться.
Таблица 2.2. Схема работы низшего уровня операционной системы
при возникновении прерывания
1 Оборудование помещает в стек счетчик команд и т. п.
2 Оборудование загружает новый счетчик команд из вектора прерывания
3 Процедура на ассемблере сохраняет регистры
4 Процедура на ассемблере устанавливает указатель на новый стек
5 Запускается процедура на языке C, обслуживающая прерывание (как правило, она
считывает входные данные и помещает их в буфер)
6 Планировщик принимает решение, какой процесс запускать следующим
7 Процедура на языке C возвращает управление ассемблерному коду
8 Процедура на ассемблере запускает новый текущий процесс
Процесс во время своего выполнения может быть прерван тысячи раз, но ключевая
идея состоит в том, что после каждого прерывания прерванный процесс возвращается
в точности к такому же состоянию, в котором он был до того, как случилось прерывание.
2.1.7. Моделирование режима многозадачности
Режим многозадачности позволяет использовать центральный процессор более рационально.
При грубой прикидке, если для среднестатистического процесса вычисления
занимают лишь 20 % времени его пребывания в памяти, то при пяти одновременно
находящихся в памяти процессах центральный процессор будет загружен постоянно.
Но в эту модель заложен абсолютно нереальный оптимизм, поскольку в ней заведомо
предполагается, что все пять процессов никогда не будут одновременно находиться
в ожидании окончания какого-нибудь процесса ввода-вывода.
Лучше выстраивать модель на основе вероятностного взгляда на использование центрального
процессора. Предположим, что процесс проводит часть своего времени p
в ожидании завершения операций ввода-вывода. При одновременном присутствии
в памяти n процессов вероятность того, что все n процессов ожидают завершения вводавывода
(в случае чего процессор простаивает), равна p n . Тогда время задействования
процессора вычисляется по формуле
Время задействования ценрального процессора = 1 ? p n .
На рис. 2.4 показано время задействования центрального процессора в виде функции
от аргумента n, который называется степенью многозадачности.
Судя по рисунку, если процесс тратит 80 % своего времени на ожидание завершения
ввода-вывода, то для снижения простоя процессора до уровня не более 10 % в памяти
могут одновременно находиться по крайней мере 10 процессов. Когда вы поймете, что
к ожиданию ввода-вывода относится и ожидание интерактивного процесса пользовательского
ввода с терминала (или щелчка кнопкой мыши на значке), станет понятно,
что время ожидания завершения ввода-вывода, составляющее 80 % и более, не такая
уж редкость. Но даже на серверах процессы, осуществляющие множество операций
ввода-вывода, зачастую имеют такой же или даже больший процент простоя.
Справедливости ради следует заметить, что рассмотренная нами вероятностная модель
носит весьма приблизительный характер. В ней безусловно предполагается, что
Рис. 2.4. Время задействования центрального процессора в виде функции
от количества процессов, присутствующих в памяти
все n процессов являются независимыми друг от друга, а значит, в системе с пятью
процессами в памяти вполне допустимо иметь три выполняемых и два ожидающих
процесса. Но имея один центральный процессор, мы не может иметь сразу три выполняемых
процесса, поэтому процесс, который становится готовым к работе при занятом
центральном процессоре, вынужден ожидать своей очереди. Из-за этого процессы не
обладают независимостью. Более точная модель может быть выстроена с использованием
теории очередей, но сделанный нами акцент на многозадачность, позволяющую
загружать процессор во избежание его простоя, по-прежнему сохраняется, даже если
реальные кривые немного отличаются от тех, что показаны на рис. 2.4.
Несмотря на упрощенность модели, представленной на рис. 2.4, тем не менее она
может быть использована для специфических, хотя и весьма приблизительных предсказаний,
касающихся производительности центрального процессора. Предположим,
к примеру, что память компьютера составляет 8 Гбайт, операционная система и ее
таблицы занимают до 2 Гбайт, а каждая пользовательская программа также занимает
до 2 Гбайт. Этот объем позволяет одновременно разместить в памяти три пользовательские
программы. При среднем ожидании ввода-вывода, составляющем 80 % времени,
мы имеем загруженность центрального процессора (если игнорировать издержки на
работу операционной системы), равную 1 – 0,8 3 , или около 49 %. Увеличение объема
памяти еще на 8 Гбайт позволит системе перейти от трехкратной многозадачности
к семикратной, что повысит загруженность центрального процессора до 79 %. Иными
словами, дополнительные 8 Гбайт памяти увеличат его производительность на 30 %.
Увеличение памяти еще на 8 Гбайт поднимет уровень производительности всего лишь
с 79 до 91 %, то есть дополнительный прирост производительности составит только
12 %. Используя эту модель, владельцы компьютеров могут прийти к выводу, что
первое наращивание объема памяти, в отличие от второго, станет неплохим вкладом
в повышение производительности процессора.
2.2. Потоки
В традиционных операционных системах у каждого процесса есть адресное пространство
и единственный поток управления. Фактически это почти что определение
процесса. Тем не менее нередко возникают ситуации, когда неплохо было бы иметь
в одном и том же адресном пространстве несколько потоков управления, выполняемых
квазипараллельно, как будто они являются чуть ли не обособленными процессами
(за исключением общего адресного пространства). В следующих разделах будут рассмотрены
именно такие ситуации и их применение.
2.2.1. Применение потоков
Зачем нам нужна какая-то разновидность процесса внутри самого процесса? Необходимость
в подобных мини-процессах, называемых потоками, обусловливается целым
рядом причин. Рассмотрим некоторые из них. Основная причина использования потоков
заключается в том, что во многих приложениях одновременно происходит несколько
действий, часть которых может периодически быть заблокированной. Модель
программирования упрощается за счет разделения такого приложения на несколько
последовательных потоков, выполняемых в квазипараллельном режиме.
Мы уже сталкивались с подобными аргументами. Именно они использовались в поддержку
создания процессов. Вместо того чтобы думать о прерываниях, таймерах и контекстных
переключателях, мы можем думать о параллельных процессах. Но только
теперь, рассматривая потоки, мы добавляем новый элемент: возможность использования
параллельными процессами единого адресного пространства и всех имеющихся данных.
Эта возможность играет весьма важную роль для тех приложений, которым не подходит
использование нескольких процессов (с их раздельными адресными пространствами).
Вторым аргументом в пользу потоков является легкость (то есть быстрота) их создания
и ликвидации по сравнению с более «тяжеловесными» процессами. Во многих системах
создание потоков осуществляется в 10–100 раз быстрее, чем создание процессов.
Это свойство особенно пригодится, когда потребуется быстро и динамично изменять
количество потоков.
Третий аргумент в пользу потоков также касается производительности. Когда потоки
работают в рамках одного центрального процессора, они не приносят никакого прироста
производительности, но когда выполняются значительные вычисления, а также значительная
часть времени тратится на ожидание ввода-вывода, наличие потоков позволяет
этим действиям перекрываться по времени, ускоряя работу приложения.
И наконец, потоки весьма полезны для систем, имеющих несколько центральных процессоров,
где есть реальная возможность параллельных вычислений. К этому вопросу
мы вернемся в главе 8.
Понять, в чем состоит польза от применения потоков, проще всего на конкретных
примерах. Рассмотрим в качестве первого примера текстовый процессор. Обычно
эти программы отображают создаваемый документ на экране в том виде, в каком он
будет выводиться на печать. В частности, все концы строк и концы страниц находятся
именно там, где они в результате и появятся на бумаге, чтобы пользователь мог при
необходимости их проверить и подправить (например, убрать на странице начальные
и конечные висячие строки, имеющие неэстетичный вид).
Предположим, что пользователь пишет какую-то книгу. С авторской точки зрения проще
всего всю книгу иметь в одном файле, облегчая поиск тем, выполнение глобальных
замен и т. д. С другой точки зрения каждая глава могла бы быть отдельным файлом. Но
если каждый раздел и подраздел будут размещаться в отдельных файлах, это принесет
массу неудобств, когда понадобится вносить во всю книгу глобальные изменения, поскольку
тогда придется отдельно и поочередно редактировать сотни файлов. Например,
если предложенный стандарт xxxx одобрен непосредственно перед выходом книги в печать,
то в последнюю минуту все вхождения «Проект стандарта xxxx» нужно заменить
на «Стандарт xxxx». Если вся книга представлена одним файлом, то, как правило, все
замены могут быть произведены с помощью одной команды. А если книга разбита на
более чем 300 файлов, редактированию должен быть подвергнут каждый из них.
Теперь представим себе, что происходит, когда пользователь вдруг удаляет одно предложение
на первой странице 800-страничного документа. Теперь, проверив внесенные
изменения, он хочет внести еще одну поправку на 600-й странице и набирает команду,
предписывающую текстовому процессору перейти на эту страницу (возможно, посредством
поиска фразы, которая только там и встречается). Теперь текстовый процессор
вынужден немедленно переформатировать всю книгу вплоть до 600-й страницы, поскольку
он не знает, какой будет первая строка на 600-й странице, пока не обработает
всех предыдущие страницы. Перед отображением 600-й страницы может произойти
существенная задержка, вызывающая недовольство пользователя.
И здесь на помощь могут прийти потоки. Предположим, что текстовый процессор
написан как двухпоточная программа. Один из потоков взаимодействует с пользователем,
а другой занимается переформатированием в фоновом режиме. Как только
предложение с первой страницы будет удалено, поток, отвечающий за взаимодействие
с пользователем, приказывает потоку, отвечающему за формат, переформатировать всю
книгу. Пока взаимодействующий поток продолжает отслеживать события клавиатуры
и мыши, реагируя на простые команды вроде прокрутки первой страницы, второй
поток с большой скоростью выполняет вычисления. Если немного повезет, то переформатирование
закончится как раз перед тем, как пользователь запросит просмотр
600-й страницы, которая тут же сможет быть отображена.
Ну раз уж начали, то почему бы не добавить и третий поток? Многие текстовые процессоры
обладают свойством автоматического сохранения всего файла на диск каждые
несколько минут, чтобы уберечь пользователя от утраты его дневной работы в случае
программных или системных сбоев или отключения электропитания. Третий поток
может заниматься созданием резервных копий на диске, не мешая первым двум. Ситуация,
связанная с применением трех потоков, показана на рис. 2.5.
Рис. 2.5. Текстовый процессор, использующий три потока
Если бы программа была рассчитана на работу только одного потока, то с начала
создания резервной копии на диске и до его завершения игнорировались бы команды
с клавиатуры или мыши. Пользователь ощущал бы это как слабую производительность.
Можно было бы сделать так, чтобы события клавиатуры или мыши прерывали создание
резервной копии на диске, позволяя достичь более высокой производительности,
но это привело бы к сложной модели программирования, основанной на применении
прерываний. Программная модель, использующая три потока, гораздо проще. Первый
поток занят только взаимодействием с пользователем. Второй поток по необходимости
занимается переформатированием документа. А третий поток периодически сбрасывает
содержимое ОЗУ на диск.
Вполне очевидно, что три отдельных процесса так работать не будут, поскольку с документом
необходимо работать всем трем потокам. Три потока вместо трех процессов
используют общую память, таким образом, все они имеют доступ к редактируемому
документу. При использовании трех процессов такое было бы невозможно.
Аналогичная ситуация складывается во многих других интерактивных программах.
Например, электронная таблица является программой, позволяющей поддерживать
матрицу, данные элементов которой предоставляются пользователем. Остальные
элементы вычисляют исходя из введенных данных с использованием потенциально
сложных формул. Когда пользователь изменяет значение одного элемента, нужно пересчитывать
значения многих других элементов. При использовании потоков пересчета,
работающих в фоновом режиме, поток, взаимодействующий с пользователем, может
позволить последнему, пока идут вычисления, вносить дополнительные изменения.
Подобным образом третий поток может сам по себе периодически сбрасывать на диск
резервные копии.
Рассмотрим еще один пример, где могут пригодиться потоки: сервер для веб-сайта.
Поступают запросы на веб-страницы, и запрошенные страницы отправляются обратно
клиентам. На большинстве веб-сайтов некоторые страницы запрашиваются чаще
других. Например, главная страница веб-сайта Sony запрашивается намного чаще,
чем страница, находящаяся глубже, в ответвлении дерева, содержащем техническое
описание какой-нибудь конкретной видеокамеры. Веб-службы используют это обстоятельство
для повышения производительности за счет размещения содержания
часто используемых страниц в основной памяти, чтобы исключить необходимость
обращаться за ними к диску. Такие подборки называются кэшем и используются
также во многих других случаях. Кэши центрального процессора уже рассматривались
в главе 1.
Один из способов организации веб-сервера показан на рис. 2.6. Один из потоков —
диспетчер — читает входящие рабочие запросы из сети. После анализа запроса он
выбирает простаивающий (то есть заблокированный) рабочий поток и передает ему
запрос, возможно, путем записи указателя на сообщение в специальное слово, связанное
с каждым потоком. Затем диспетчер пробуждает спящий рабочий поток, переводя
его из заблокированного состояния в состояние готовности.
При пробуждении рабочий поток проверяет, может ли запрос быть удовлетворен из
кэша веб-страниц, к которому имеют доступ все потоки. Если нет, то он, чтобы получить
веб-страницу, приступает к операции чтения с диска и блокируется до тех пор,
пока не завершится дисковая операция. Когда поток блокируется на дисковой операции,
выбирается выполнение другого потока, возможно, диспетчера, с целью получения
следующей задачи или, возможно, другого рабочего потока, который находится
в готовности к выполнению.
Рис. 2.6. Многопоточный веб-сервер
Эта модель позволяет запрограммировать сервер в виде коллекции последовательных
потоков. Программа диспетчера состоит из бесконечного цикла для получения рабочего
запроса и перепоручения его рабочему потоку. Код каждого рабочего потока состоит
из бесконечного цикла, в котором принимается запрос от диспетчера и веб-кэш проверяется
на присутствие в нем страницы. Если страница в кэше, она возвращается клиенту.
Если нет, поток получает страницу с диска, возвращает ее клиенту и блокируется
в ожидании нового запроса.
Приблизительный набросок кода показан на рис. 2.7. Здесь, как и во всей книге, константа
TRUE предполагается равной 1. Также buf и page являются структурами, предназначенными
для хранения рабочего запроса и веб-страницы соответственно.
Рис. 2.7. Приблизительный набросок кода для модели, изображенной на рис. 2.6:
а — для потока-диспетчера; б — для рабочего потока
Рассмотрим, как можно было бы написать код веб-сервера в отсутствие потоков. Можно
заставить его работать в виде единого потока. Основной цикл веб-сервера получает
запрос, анализирует его и завершает обработку до получения следующего запроса.
Ожидая завершения дисковой операции, сервер простаивает и не обрабатывает никаких
других входящих запросов. Если веб-сервер запущен на специально выделенной
машине, что чаще всего и бывает, то центральный процессор, ожидая завершения
дисковой операции, остается без дела. В итоге происходит значительное сокращение
количества запросов, обрабатываемых в секунду. Таким образом, потоки существенно
повышают производительность, но каждый из них программируется последовательно,
то есть обычным способом.
До сих пор мы видели две возможные конструкции: многопоточный и однопоточный
веб-серверы. Представьте, что потоки недоступны, а системные программисты считают,
что потери производительности при использовании одного потока недопустимы.
Если доступна неблокирующая версия системного вызова read, то возможен и третий
подход. При поступлении запроса его анализирует один-единственный поток. Если
запрос может быть удовлетворен из кэша, то все в порядке, но если нет, то стартует
неблокирующая дисковая операция.
Сервер записывает состояние текущего запроса в таблицу, а затем приступает к получению
следующего события. Этим событием может быть либо запрос на новую задачу, либо
ответ от диска, связанный с предыдущей операцией. Если это новая задача, то процесс
приступает к ее выполнению. Если это ответ от диска, то из таблицы выбирается соответствующая
информация и происходит обработка ответа. При использовании неблокирующего
ввода-вывода ответ, наверное, должен принять форму сигнала или прерывания.
При такой конструкции модель «последовательного процесса», присутствующая
в первых двух случаях, уже не работает. Состояние вычисления должно быть явным
образом сохранено и восстановлено из таблицы при каждом переключении сервера
с обработки одного запроса на обработку другого. В результате потоки и их стеки
имитируются более сложным образом. Подобная конструкция, в которой у каждого
вычисления есть сохраняемое состояние и имеется некоторый набор событий, которые
могут происходить с целью изменения состояния, называются машиной с конечным
числом состояний (finite-state machine), или конечным автоматом. Это понятие получило
в вычислительной технике весьма широкое распространение.
Теперь, наверное, уже понятно, чем должны быть полезны потоки. Они дают возможность
сохранить идею последовательных процессов, которые осуществляют блокирующие
системные вызовы (например, для операций дискового ввода-вывода), но при
этом позволяют все же добиться распараллеливания работы. Блокирующие системные
вызовы упрощают программирование, а параллельная работа повышает производительность.
Однопоточные серверы сохраняют простоту блокирующих системных вызовов,
но уступают им в производительности. Третий подход позволяет добиться высокой
производительности за счет параллельной работы, но использует неблокирующие
вызовы и прерывания, усложняя процесс программирования. Сводка моделей приведена
в табл. 2.3.
Таблица 2.3. Три способа создания сервера
Модель Характеристики
Потоки Параллельная работа, блокирующие системные вызовы
Однопоточный процесс Отсутствие параллельной работы, блокирующие системные
вызовы
Машина с конечным числом
состояний
Параллельная работа, неблокирующие системные вызовы,
прерывания
Третьим примером, подтверждающим пользу потоков, являются приложения, предназначенные
для обработки очень большого объема данных. При обычном подходе блок
данных считывается, после чего обрабатывается, а затем снова записывается. Проблема
в том, что при доступности лишь блокирующих вызовов процесс блокируется и при поступлении
данных, и при их возвращении. Совершенно ясно, что простой центрального
процесса при необходимости в большом объеме вычислений слишком расточителен
и его по возможности следует избегать.
Проблема решается с помощью потоков. Структура процесса может включать входной
поток, обрабатывающий поток и выходной поток. Входной поток считывает данные
во входной буфер. Обрабатывающий поток извлекает данные из входного буфера, обрабатывает
их и помещает результат в выходной буфер. Выходной буфер записывает
эти результаты обратно на диск. Таким образом, ввод, вывод и обработка данных могут
осуществляться одновременно. Разумеется, эта модель работает лишь при том условии,
что системный вызов блокирует только вызывающий поток, а не весь процесс.
2.2.2. Классическая модель потоков
Разобравшись в пользе потоков и в порядке их использования, давайте рассмотрим их
применение более пристально. Модель процесса основана на двух независимых понятиях:
группировке ресурсов и выполнении. Иногда их полезно отделить друг от друга,
и тут на первый план выходят потоки. Сначала будет рассмотрена классическая модель
потоков, затем изучена модель потоков, используемая в Linux, которая размывает грань
между процессами и потоками.
Согласно одному из взглядов на процесс, он является способом группировки в единое
целое взаимосвязанных ресурсов. У процесса есть адресное пространство, содержащее
текст программы и данные, а также другие ресурсы. Эти ресурсы могут включать открытые
файлы, необработанные аварийные сигналы, обработчики сигналов, учетную
информацию и т. д. Управление этими ресурсами можно значительно облегчить, если
собрать их воедино в виде процесса.
Другое присущее процессу понятие — поток выполнения — обычно сокращается до слова
поток. У потока есть счетчик команд, отслеживающий, какую очередную инструкцию
нужно выполнять. У него есть регистры, в которых содержатся текущие рабочие переменные.
У него есть стек с протоколом выполнения, содержащим по одному фрейму для
каждой вызванной, но еще не возвратившей управление процедуры. Хотя поток может
быть выполнен в рамках какого-нибудь процесса, сам поток и его процесс являются разными
понятиями и должны рассматриваться по отдельности. Процессы используются
для группировки ресурсов в единое образование, а потоки являются «сущностью», распределяемой
для выполнения на центральном процессоре.
Потоки добавляют к модели процесса возможность реализации нескольких в значительной
степени независимых друг от друга выполняемых задач в единой среде
процесса. Наличие нескольких потоков, выполняемых параллельно в рамках одного
процесса, является аналогией наличия нескольких процессов, выполняемых параллельно
на одном компьютере. В первом случае потоки используют единое адресное
пространство и другие ресурсы. А в последнем случае процессы используют общую
физическую память, диски, принтеры и другие ресурсы. Поскольку потоки обладают
некоторыми свойствами процессов, их иногда называют облегченными процессами.
Термин «многопоточный режим» также используется для описания ситуации, при
которой допускается работа нескольких потоков в одном и том же процессе. В главе 1
было показано, что некоторые центральные процессоры обладают непосредственной
аппаратной поддержкой многопоточного режима и проводят переключение потоков
за наносекунды.
На рис. 2.8, а показаны три традиционных процесса. У каждого из них имеется собственное
адресное пространство и единственный поток управления. В отличие от этого,
на рис. 2.8, б показан один процесс, имеющий три потока управления. Хотя в обоих
случаях у нас имеется три потока, на рис. 2.8, а каждый из них работает в собственном
адресном пространстве, а на рис. 2.8, б все три потока используют общее адресное пространство.

Рис. 2.8. а — три процесса, у каждого из которых по одному потоку;
б — один процесс с тремя потоками
Когда многопоточный процесс выполняется на однопроцессорной системе, потоки
выполняются, сменяя друг друга. На рис. 2.1 мы видели работу процессов в многозадачном
режиме. За счет переключения между несколькими процессами система создавала
иллюзию параллельно работающих отдельных последовательных процессов. Многопоточный
режим осуществляется аналогичным способом. Центральный процессор
быстро переключается между потоками, создавая иллюзию, что потоки выполняются
параллельно, пусть даже на более медленном центральном процессоре, чем реально используемый.
При наличии в одном процессе трех потоков, ограниченных по скорости
вычисления, будет казаться, что потоки выполняются параллельно и каждый из них
выполняется на центральном процессоре, имеющем скорость, которая составляет одну
треть от скорости реального процессора.
Различные потоки в процессе не обладают той независимостью, которая есть у различных
процессов. У всех потоков абсолютно одно и то же адресное пространство, а значит,
они так же совместно используют одни и те же глобальные переменные. Поскольку
каждый поток может иметь доступ к любому адресу памяти в пределах адресного
пространства процесса, один поток может считывать данные из стека другого потока,
записывать туда свои данные и даже стирать оттуда данные. Защита между потоками
отсутствует, потому что ее невозможно осуществить и в ней нет необходимости. В отличие
от различных процессов, которые могут принадлежать различным пользователям
и которые могут враждовать друг с другом, один процесс всегда принадлежит одному
и тому же пользователю, который, по-видимому, и создал несколько потоков для их
совместной работы, а не для вражды. В дополнение к использованию общего адресного
пространства все потоки, как показано в табл. 2.4, могут совместно использовать одни
и те же открытые файлы, дочерние процессы, ожидаемые и обычные сигналы и т. п.
Поэтому структура, показанная на рис. 2.8, а, может использоваться, когда все три
процесса фактически не зависят друг от друга, а структура, показанная на рис. 2.8, б,
может применяться, когда три потока фактически являются частью одного и того же
задания и активно и тесно сотрудничают друг с другом.
Таблица 2.4. Использование объектов потоками
Элементы, присущие каждому процессу Элементы, присущие каждому потоку
Адресное пространство Счетчик команд
Глобальные переменные Регистры
Открытые файлы Стек
Дочерние процессы Состояние
Необработанные аварийные сигналы
Сигналы и обработчики сигналов
Учетная информация
Элементы в первом столбце относятся к свойствам процесса, а не потоков. Например,
если один из потоков открывает файл, этот файл становится видимым в других потоках,
принадлежащих процессу, и они могут производить с этим файлом операции
чтения-записи. Это вполне логично, поскольку именно процесс, а не поток является
элементом управления ресурсами. Если бы у каждого потока были собственные адресное
пространство, открытые файлы, необработанные аварийные сигналы и т. д., то он
был бы отдельным процессом. С помощью потоков мы пытаемся достичь возможности
выполнения нескольких потоков, использующих набор общих ресурсов с целью тесного
сотрудничества при реализации какой-нибудь задачи.
Подобно традиционному процессу (то есть процессу только с одним потоком), поток
должен быть в одном из следующих состояний: выполняемый, заблокированный,
готовый или завершенный. Выполняемый поток занимает центральный процессор
и является активным в данный момент. В отличие от этого, заблокированный поток
ожидает события, которое его разблокирует. Например, когда поток выполняет системный
вызов для чтения с клавиатуры, он блокируется до тех пор, пока на ней не
будет что-нибудь набрано. Поток может быть заблокирован в ожидании какого-то
внешнего события или его разблокировки другим потоком. Готовый поток планируется
к выполнению и будет выполнен, как только подойдет его очередь. Переходы
между состояниями потока аналогичны переходам между состояниями процесса
(см. рис. 2.2).
Следует учесть, что каждый поток имеет собственный стек (рис. 2.9). Стек каждого потока
содержит по одному фрейму для каждой уже вызванной, но еще не возвратившей
управление процедуры. Такой фрейм содержит локальные переменные процедуры
и адрес возврата управления по завершении ее вызова. Например, если процедура X
вызывает процедуру Y, а Y вызывает процедуру Z, то при выполнении Z в стеке будут
фреймы для X, Y и Z. Каждый поток будет, как правило, вызывать различные процедуры
и, следовательно, иметь среду выполнения, отличающуюся от среды выполнения других
потоков. Поэтому каждому потоку нужен собственный стек.
Рис. 2.9. У каждого потока имеется собственный стек
Когда используется многопоточность, процесс обычно начинается с использования
одного потока. Этот поток может создавать новые потоки, вызвав библиотечную процедуру,
к примеру thread_create. В параметре thread_create обычно указывается имя
процедуры, запускаемой в новом потоке. Нет необходимости (или даже возможности)
указывать для нового потока какое-нибудь адресное пространство, поскольку он автоматически
запускается в адресном пространстве создающего потока. Иногда потоки
имеют иерархическую структуру, при которой у них устанавливаются взаимоотношения
между родительскими и дочерними потоками, но чаще всего такие взаимоотношения
отсутствуют и все потоки считаются равнозначными. Независимо от наличия или
отсутствия иерархических взаимоотношений создающий поток обычно возвращает
идентификатор потока, который дает имя новому потоку.
Когда поток завершает свою работу, выход из него может быть осуществлен за счет
вызова библиотечной процедуры, к примеру thread_exit. После этого он прекращает
свое существование и больше не фигурирует в работе планировщика. В некоторых использующих
потоки системах какой-нибудь поток для выполнения выхода может ожидать
выхода из какого-нибудь другого (указанного) потока после вызова про цедуры,
к примеру thread_join. Эта процедура блокирует вызывающий поток до тех пор, пока не
будет осуществлен выход из другого (указанного) потока. В этом отношении создание
и завершение работы потока очень похожи на создание и завершение работы процесса
при использовании примерно одних и тех же параметров.
Другой распространенной процедурой, вызываемой потоком, является thread_yield.
Она позволяет потоку добровольно уступить центральный процессор для выполнения
другого потока. Важность вызова такой процедуры обусловливается отсутствием
прерывания по таймеру, которое есть у процессов и благодаря которому фактически
задается режим многозадачности. Для потоков важно проявлять вежливость и время
от времени добровольно уступать центральный процессор, чтобы дать возможность
выполнения другим потокам. Другие вызываемые процедуры позволяют одному потоку
ожидать, пока другой поток не завершит какую-нибудь работу, а этому потоку —
оповестить о том, что он завершил определенную работу, и т. д.
Хотя потоки зачастую приносят пользу, они вносят в модель программирования и ряд
сложностей. Для начала рассмотрим эффект, возникающий при осуществлении системного
вызова fork, принадлежащего ОС UNIX. Если у родительского процесса есть
несколько потоков, должны ли они быть у дочернего процесса? Если нет, то процесс
может неверно функционировать из-за того, что все они составляют его неотъемлемую
часть.
Но если дочерний процесс получает столько же потоков, сколько их было у родительского
процесса, что произойдет, если какой-нибудь из потоков родительского процесса
был заблокирован системным вызовом read, используемым, к примеру, для чтения
с клавиатуры? Будут ли теперь два потока, в родительском и в дочернем процессах, заблокированы
на вводе с клавиатуры? Если будет набрана строка, получат ли оба потока
ее копию? Или ее получит только поток родительского процесса? А может быть, она
будет получена только потоком дочернего процесса? Сходные проблемы существуют
и при открытых сетевых подключениях.
Другой класс проблем связан с тем, что потоки совместно используют многие структуры
данных. Что происходит в том случае, если один поток закрывает файл в тот
момент, когда другой поток еще не считал с него данные? Предположим, что один поток
заметил дефицит свободной памяти и приступил к выделению дополнительного
объема. На полпути происходит переключение потоков, и новый поток тоже замечает
дефицит свободной памяти и приступает к выделению дополнительного объема. Вполне
возможно, что дополнительная память будет выделена дважды. Для решения этих
проблем следует приложить ряд усилий, но для корректной работы многопоточных
программ требуется все тщательно продумать и спроектировать.
2.2.3. Потоки в POSIX
Чтобы предоставить возможность создания переносимых многопоточных программ,
в отношении потоков институтом IEEE был определен стандарт IEEE standard 1003.1c.
Определенный в нем пакет, касающийся потоков, называется Pthreads. Он поддерживается
большинством UNIX-систем. В стандарте определено более 60 вызовов функций.
Рассмотреть в этой книге такое количество функций мы не в состоянии. Лучше
опишем ряд самых основных функций, чтобы дать представление о том, как они работают.
В табл. 2.5 перечислены все вызовы функций, которые мы будем рассматривать.
Таблица 2.5. Ряд вызовов функций стандарта Pthreads
Вызовы, связанные с потоком Описание
pthread_create Создание нового потока
pthread_exit Завершение работы вызвавшего потока
pthread_join Ожидание выхода из указанного потока
pthread_yield Освобождение центрального процессора, позволяющее
выполняться другому потоку
pthread_attr_init Создание и инициализация структуры атрибутов потока
pthread_attr_destroy Удаление структуры атрибутов потока
Все потоки Pthreads имеют определенные свойства. У каждого потока есть свои идентификатор,
набор регистров (включая счетчик команд) и набор атрибутов, которые
сохраняются в определенной структуре. Атрибуты включают размер стека, параметры
планирования и другие элементы, необходимые при использовании потока.
Новый поток создается с помощью вызова функции pthread_create. В качестве значения
функции возвращается идентификатор только что созданного потока. Этот вызов намеренно
сделан очень похожим на системный вызов fork (за исключением параметров),
а идентификатор потока играет роль PID, главным образом для идентификации ссылок
на потоки в других вызовах.
Когда поток заканчивает возложенную на него работу, он может быть завершен путем
вызова функции pthread_exit. Этот вызов останавливает поток и освобождает пространство,
занятое его стеком.
Зачастую потоку необходимо перед продолжением выполнения ожидать окончания
работы и выхода из другого потока. Ожидающий поток вызывает функцию pthread_join,
чтобы ждать завершения другого указанного потока. В качестве параметра этой функции
передается идентификатор потока, чьего завершения следует ожидать.
Иногда бывает так, что поток не является логически заблокированным, но считает, что
проработал достаточно долго, и намеревается дать шанс на выполнение другому потоку.
Этой цели он может добиться за счет вызова функции pthread_yield. Для процессов
подобных вызовов функций не существует, поскольку предполагается, что процессы
сильно конкурируют друг с другом и каждый из них требует как можно больше времени
центрального процессора. Но поскольку потоки одного процесса, как правило,
пишутся одним и тем же программистом, то он добивается от них, чтобы они давали
друг другу шанс на выполнение.
Два следующих вызова функций, связанных с потоками, относятся к атрибутам. Функция
pthread_attr_init создает структуру атрибутов, связанную с потоком, и инициализирует
ее значениями по умолчанию. Эти значения (например, приоритет) могут быть
изменены за счет работы с полями в структуре атрибутов.
И наконец, функция pthread_attr_destroy удаляет структуру атрибутов, принадлежащую
потоку, освобождая память, которую она занимала. На поток, который использовал
данную структуру, это не влияет, и он продолжает свое существование.
Чтобы лучше понять, как работают функции пакета Pthread, рассмотрим простой
пример, показанный в листинге 2.1. Основная программа этого примера работает
в цикле столько раз, сколько указано в константе NUMBER_OF_THREADS (количество
потоков), создавая при каждой итерации новый поток и предварительно сообщив
о своих намерениях. Если создать поток не удастся, она выводит сообщение об ошибке
и выполняет выход. После создания всех потоков осуществляется выход из основной
программы.
Листинг 2.1. Пример программы, использующей потоки
#include <pthread.h>
#include <stdio.h>
#include <stdlib.h>
#define NUMBER_OF_THREADS 10
void *print_hello_world(void *tid)
{
/* Эта функция выводит идентификатор потока, а затем осуществляет выход */
printf("Привет, мир. Тебя приветствует поток № %d\n", tid);
pthread_exit(NULL);
}
int main(int argc, char *argv[])
{
/* Основная программа создает 10 потоков, а затем осуществляет выход. */
pthread_t threads[NUMBER_OF_THREADS];
int status, i;
for(i=0; i < NUMBER_OF_THREADS; i++) {
printf("Это основная программа. Создание потока № %d\n"", i);
status = pthread_create(&threads[i], NULL, print_hello_world,
(void *)i);
if (status != 0) {
printf("Жаль, функция pthread_create вернула код ошибки %d\n"",
status);
exit(-1);
}
}
exit(NULL);
}
При создании поток выводит однострочное сообщение, объявляя о своем существовании,
после чего осуществляет выход. Порядок, в котором выводятся различные
сообщения, не определен и при нескольких запусках программы может быть разным.
Конечно же описанные функции Pthreads составляют лишь небольшую часть многочисленных
функций, имеющихся в этом пакете. Чуть позже, после обсуждения синхронизации
процессов и потоков, мы изучим и некоторые другие функции.
2.2.4. Реализация потоков
в пользовательском пространстве
Есть два основных места реализации набора потоков: в пользовательском пространстве
и в ядре. Это утверждение носит несколько спорный характер, поскольку возможна еще
и гибридная реализация. А теперь мы опишем эти способы со всеми их достоинствами
и недостатками.
Первый способ — это поместить весь набор потоков в пользовательском пространстве.
И об этом наборе ядру ничего не известно. Что касается ядра, оно управляет обычными,
однопотоковыми процессами. Первое и самое очевидное преимущество состоит в том,
что набор потоков на пользовательском уровне может быть реализован в операционной
системе, которая не поддерживает потоки. Под эту категорию подпадают все операционные
системы, даже те, которые еще находятся в разработке. При этом подходе потоки
реализованы с помощью библиотеки.
У всех этих реализаций одна и та же общая структура (рис. 2.10, а). Потоки запускаются
поверх системы поддержки исполнения программ (run-time system), которая представляет
собой набор процедур, управляющих потоками. Четыре из них: pthread_create,
pthread_exit, pthread_join и pthread_yield — мы уже рассмотрели, но обычно в наборе
есть и другие процедуры.
Когда потоки управляются в пользовательском пространстве, каждому процессу необходимо
иметь собственную таблицу потоков, чтобы отслеживать потоки, имеющиеся
в этом процессе. Эта таблица является аналогом таблицы процессов, имеющейся в ядре,
Рис. 2.10. Набор потоков: а — на пользовательском уровне; б — управляемый ядром
за исключением того, что в ней содержатся лишь свойства, принадлежащие каждому
потоку, такие как счетчик команд потока, указатель стека, регистры, состояние и т. д.
Таблица потоков управляется системой поддержки исполнения программ. Когда поток
переводится в состояние готовности или блокируется, информация, необходимая для
возобновления его выполнения, сохраняется в таблице потоков, точно так же, как ядро
хранит информацию о процессах в таблице процессов.
Когда поток совершает какие-то действия, которые могут вызвать его локальную
блокировку, например ожидание, пока другой поток его процесса не завершит какуюнибудь
работу, он вызывает процедуру системы поддержки исполнения программ.
Эта процедура проверяет, может ли поток быть переведен в состояние блокировки.
Если может, она сохраняет регистры потока (то есть собственные регистры) в таблице
потоков, находит в таблице поток, готовый к выполнению, и перезагружает регистры
машины сохраненными значениями нового потока. Как только будут переключены
указатель стека и счетчик команд, автоматически возобновится выполнение нового
потока. Если машине дается инструкция сохранить все регистры и следующая
инструкция — загрузить все регистры, то полное переключение потока может быть
осуществлено за счет всего лишь нескольких инструкций. Переключение потоков,
осуществленное таким образом, по крайней мере на порядок, а может быть, и больше,
быстрее, чем перехват управления ядром, что является веским аргументом в пользу
набора потоков, реализуемого на пользовательском уровне.
Но у потоков есть одно основное отличие от процессов. Когда поток на время останавливает
свое выполнение, например когда он вызывает thread_yield, код процедуры
thread_yield может самостоятельно сохранять информацию о потоке в таблице потоков.
Более того, он может затем вызвать планировщик потоков, чтобы тот выбрал для
выполнения другой поток. Процедура, которая сохраняет состояние потока, и планировщик
— это всего лишь локальные процедуры, поэтому их вызов намного более
эффективен, чем вызов ядра. Помимо всего прочего, не требуется перехват управления
ядром, осуществляемый инструкцией trap, не требуется переключение контекста, кэш
в памяти не нужно сбрасывать на диск и т. д. Благодаря этому планировщик потоков
работает очень быстро.
У потоков, реализованных на пользовательском уровне, есть и другие преимущества.
Они позволяют каждому процессу иметь собственные настройки алгоритма планирования.
Например, для некоторых приложений, которые имеют поток сборщика
мусора, есть еще один плюс — им не следует беспокоиться о потоках, остановленных
в неподходящий момент. Эти потоки также лучше масштабируются, поскольку потоки
в памяти ядра безусловно требуют в ядре пространства для таблицы и стека, что при
очень большом количестве потоков может вызвать затруднения.
Но несмотря на лучшую производительность, у потоков, реализованных на пользовательском
уровне, есть ряд существенных проблем. Первая из них — как реализовать
блокирующие системные вызовы. Представьте, что поток считывает информацию
с клавиатуры перед нажатием какой-нибудь клавиши. Мы не можем разрешить потоку
осуществить настоящий системный вызов, поскольку это остановит выполнение
всех потоков. Одна из главных целей организации потоков в первую очередь состояла
в том, чтобы позволить каждому потоку использовать блокирующие вызовы, но при
этом предотвратить влияние одного заблокированного потока на выполнение других
потоков. Работая с блокирующими системными вызовами, довольно трудно понять,
как можно достичь этой цели без особого труда.
Все системные вызовы могут быть изменены и превращены в неблокирующие (например,
считывание с клавиатуры будет просто возвращать нуль байтов, если в буфере на
данный момент отсутствуют символы), но изменения, которые для этого необходимо
внести в операционную систему, не вызывают энтузиазма. Кроме того, одним из аргументов
за использование потоков, реализованных на пользовательском уровне, было
именно то, что они могут выполняться под управлением существующих операционных
систем. Вдобавок ко всему изменение семантики системного вызова read потребует
изменения множества пользовательских программ.
В том случае, если есть возможность заранее сообщить, будет ли вызов блокирующим,
существует и другая альтернатива. В большинстве версий UNIX существует системный
вызов select, позволяющий сообщить вызывающей программе, будет ли предполагаемый
системный вызов read блокирующим. Если такой вызов имеется, библиотечная
процедура read может быть заменена новой процедурой, которая сначала осуществляет
вызов процедуры select и только потом — вызов read, если он безопасен (то есть не будет
выполнять блокировку). Если вызов read будет блокирующим, он не осуществляется.
Вместо этого запускается выполнение другого потока. В следующий раз, когда система
поддержки исполнения программ получает управление, она может опять проверить,
будет ли на этот раз вызов read безопасен. Для реализации такого подхода требуется
переписать некоторые части библиотеки системных вызовов, что нельзя рассматривать
в качестве эффективного и элегантного решения, но все же это тоже один из вариантов.
Код, который помещается вокруг системного вызова с целью проверки, называется конвертом
(jacket), или оболочкой, или оберткой (wrapper).
С проблемой блокирующих системных вызовов несколько перекликается проблема
ошибки отсутствия страницы. Мы изучим эту проблему в главе 3. А сейчас достаточно
сказать, что компьютеры могут иметь такую настройку, что в одно и то же время в оперативной
памяти находятся не все программы. Если программа вызывает инструкции
(или переходит к инструкциям), отсутствующие в памяти, возникает ошибка обращения
к отсутствующей странице и операционная система обращается к диску и получает
отсутствующие инструкции (и их соседей). Это называется ошибкой вызова отсутствующей
страницы. Процесс блокируется до тех пор, пока не будет найдена и считана необходимая
инструкция. Если ошибка обращения к отсутствующей странице возникает
при выполнении потока, ядро, которое даже не знает о существовании потоков, как
и следовало ожидать, блокирует весь процесс до тех пор, пока не завершится дисковая
операция ввода-вывода, даже если другие потоки будут готовы к выполнению.
Использование набора потоков, реализованного на пользовательском уровне, связано
еще с одной проблемой: если начинается выполнение одного из потоков, то никакой
другой поток, принадлежащий этому процессу, не сможет выполняться до тех пор,
пока первый поток добровольно не уступит центральный процессор. В рамках единого
процесса нет прерываний по таймеру, позволяющих планировать работу процессов по
круговому циклу (поочередно). Если поток не войдет в систему поддержки выполнения
программ по доброй воле, у планировщика не будет никаких шансов на работу.
Проблему бесконечного выполнения потоков можно решить также путем передачи
управления системе поддержки выполнения программ за счет запроса сигнала (прерывания)
по таймеру с периодичностью один раз в секунду, но для программы это далеко не
самое лучшее решение. Возможность периодических и довольно частых прерываний по
таймеру предоставляется не всегда, но даже если она и предоставляется, общие издержки
могут быть весьма существенными. Более того, поток может также нуждаться в прерываниях
по таймеру, мешая использовать таймер системе поддержки выполнения программ.
Другой наиболее сильный аргумент против потоков, реализованных на пользовательском
уровне, состоит в том, что программистам потоки обычно требуются именно в тех
приложениях, где они часто блокируются, как, к примеру, в многопоточном веб-сервере.
Эти потоки часто совершают системные вызовы. Как только для выполнения системного
вызова ядро осуществит перехват управления, ему не составит особого труда заняться
переключением потоков, если прежний поток заблокирован, а когда ядро займется
решением этой задачи, отпадет необходимость постоянного обращения к системному
вызову select, чтобы определить безопасность системного вызова read. Зачем вообще
использовать потоки в тех приложениях, которые, по существу, полностью завязаны на
скорость работы центрального процессора и редко используют блокировку? Никто не
станет всерьез предлагать использование потоков при вычислении первых n простых
чисел или при игре в шахматы, поскольку в данных случаях от них будет мало проку.
2.2.5. Реализация потоков в ядре
Теперь давайте рассмотрим, что произойдет, если ядро будет знать о потоках и управлять
ими. Как показано на рис. 2.10, б, здесь уже не нужна система поддержки исполнения
программ. Также здесь нет и таблицы процессов в каждом потоке. Вместо
этого у ядра есть таблица потоков, в которой отслеживаются все потоки, имеющиеся
в системе. Когда потоку необходимо создать новый или уничтожить существующий
поток, он обращается к ядру, которое и создает или разрушает путем обновления таблицы
потоков в ядре.
В таблице потоков, находящейся в ядре, содержатся регистры каждого потока,
состояние и другая информация. Вся информация аналогична той, которая использовалась
для потоков, создаваемых на пользовательском уровне, но теперь она
содержится в ядре, а не в пространстве пользователя (внутри системы поддержки
исполнения программ). Эта информация является подмножеством той информации,
которую поддерживают традиционные ядра в отношении своих однопоточных
процессов, то есть подмножеством состояния процесса. Вдобавок к этому ядро
поддерживает также традиционную таблицу процессов с целью их отслеживания.
Все вызовы, способные заблокировать поток, реализованы как системные, с более
существенными затратами, чем вызов процедуры в системе поддержки исполнения
программ. Когда поток блокируется, ядро по своему выбору может запустить либо
другой поток из этого же самого процесса (если имеется готовый к выполнению поток),
либо поток из другого процесса. Когда потоки реализуются на пользовательском
уровне, система поддержки исполнения программ работает с запущенными потоками
собственного процесса до тех пор, пока ядро не заберет у нее центральный процессор
(или не останется ни одного готового к выполнению потока).
Поскольку создание и уничтожение потоков в ядре требует относительно более весомых
затрат, некоторые системы с учетом складывающейся ситуации применяют более
правильный подход и используют свои потоки повторно. При уничтожении потока он
помечается как неспособный к выполнению, но это не влияет на его структуру данных,
имеющуюся в ядре. Чуть позже, когда должен быть создан новый поток, вместо этого
повторно активируется старый поток, что приводит к экономии времени. Повторное
использование потоков допустимо и на пользовательском уровне, но для этого нет
достаточно веских оснований, поскольку издержки на управление потоками там значительно
меньше.
Для потоков, реализованных на уровне ядра, не требуется никаких новых, неблокирующих
системных вызовов. Более того, если один из выполняемых потоков столкнется
с ошибкой обращения к отсутствующей странице, ядро может с легкостью проверить
наличие у процесса любых других готовых к выполнению потоков и при наличии таковых
запустить один из них на выполнение, пока будет длиться ожидание извлечения
запрошенной страницы с диска. Главный недостаток этих потоков состоит в весьма
существенных затратах времени на системный вызов, поэтому, если операции над потоками
(создание, удаление и т. п.) выполняются довольно часто, это влечет за собой
более существенные издержки.
Хотя потоки, создаваемые на уровне ядра, и позволяют решить ряд проблем, но справиться
со всеми существующими проблемами они не в состоянии. Что будет, к примеру,
когда произойдет разветвление многопоточного процесса? Будет ли у нового
процесса столько же потоков, сколько у старого, или только один поток? Во многих
случаях наилучший выбор зависит от того, выполнение какого процесса запланировано
следующим. Если он собирается вызвать команду exec, чтобы запустить новую
программу, то, наверное, правильным выбором будет наличие только одного потока.
Но если он продолжит выполнение, то лучше всего было бы, наверное, воспроизвести
все имеющиеся потоки.
Другой проблемой являются сигналы. Стоит вспомнить, что сигналы посылаются
процессам, а не потокам, по крайней мере, так делается в классической модели. Какой
из потоков должен обработать поступающий сигнал? Может быть, потоки должны зарегистрировать
свои интересы в конкретных сигналах, чтобы при поступлении сигнала
он передавался потоку, который заявил о своей заинтересованности в этом сигнале?
Тогда возникает вопрос: что будет, если на один и тот же сигнал зарегистрировались
два или более двух потоков? И это только две проблемы, создаваемые потоками, а ведь
на самом деле их значительно больше.
2.2.6. Гибридная реализация
В попытках объединить преимущества создания потоков на уровне пользователя и на
уровне ядра была исследована масса различных путей. Один из них (рис. 2.11) заключается
в использовании потоков на уровне ядра, а затем нескольких потоков на уровне
пользователя в рамках некоторых или всех потоков на уровне ядра. При использовании
такого подхода программист может определить, сколько потоков использовать на
уровне ядра и на сколько потоков разделить каждый из них на уровне пользователя.
Эта модель обладает максимальной гибкостью.
Рис. 2.11. Разделение на пользовательские потоки в рамках потока ядра
При таком подходе ядру известно только о потоках самого ядра, работу которых оно
и планирует. У некоторых из этих потоков могут быть несколько потоков на пользовательском
уровне, которые расходятся от их вершины. Создание, удаление и планирование
выполнения этих потоков осуществляется точно так же, как и у пользовательских
потоков, принадлежащих процессу, запущенному под управлением операционной
системы, не способной на многопоточную работу. В этой модели каждый поток на
уровне ядра обладает определенным набором потоков на уровне пользователя, которые
используют его по очереди.
2.2.7. Активация планировщика
Хотя потоки на уровне ядра по ряду ключевых позиций превосходят потоки на уровне
пользователя, они, несомненно, более медлительны. Поэтому исследователи искали
способы улучшения ситуации без потери их положительных свойств. Далее мы опишем
один из таких способов, изобретенный Андерсоном (Anderson et al., 1992), который
называется активацией планировщика. Родственная работа рассматривается Элдером
и Скоттом (Edler et al.,1988; Scott et al., 1990).
Цель работы по активации планировщика заключается в имитации функциональных
возможностей потоков на уровне ядра, но при лучшей производительности и более
высокой гибкости, свойственной пакетам потоков, реализуемых в пользовательском
пространстве. В частности, пользовательские потоки не должны выполнять специальные
неблокирующие системные вызовы или заранее проверять, будет ли безопасным
осуществление конкретного системного вызова. Тем не менее, когда поток блокируется
на системном вызове или на ошибке обращения к отсутствующей странице, должна
оставаться возможность выполнения другого потока в рамках того же процесса, если
есть хоть один готовый к выполнению поток.
Эффективность достигается путем уклонения от ненужных переходов между пространствами
пользователя и ядра. Если, к примеру, поток блокируется в ожидании
каких-либо действий другого потока, то обращаться к ядру не имеет смысла, благодаря
чему снижаются издержки на переходах между пространствами ядра и пользователя.
Имеющаяся в пространстве пользователя система поддержки исполнения программ
может заблокировать синхронизирующийся поток и самостоятельно спланировать
работу другого потока.
При использовании активации планировщика ядро назначает каждому процессу определенное
количество виртуальных процессоров, а системе поддержки исполняемых
программ (в пользовательском пространстве) разрешается распределять потоки по процессорам.
Этот механизм также может быть использован на мультипроцессорной системе,
где виртуальные процессоры могут быть представлены настоящими центральными
процессорами. Изначально процессу назначается только один виртуальный процессор,
но процесс может запросить дополнительное количество процессоров, а также вернуть
уже не используемые процессоры. Ядро также может забрать назад уже распределенные
виртуальные процессоры с целью переназначения их более нуждающимся процессам.
Работоспособность этой схемы определяется следующей основной идеей: когда ядро
знает, что поток заблокирован (например, из-за выполнения блокирующего системного
вызова или возникновения ошибки обращения к несуществующей странице),
оно уведомляет принадлежащую процессу систему поддержки исполнения программ,
передавая через стек в качестве параметров номер данного потока и описание произошедшего
события. Уведомление осуществляется за счет того, что ядро активирует
систему поддержки исполнения программ с заранее известного стартового адреса, —
примерно так же, как действуют сигналы в UNIX. Этот механизм называется upcall
(вызов наверх).
Активированная таким образом система поддержки исполнения программ может
перепланировать работу своих потоков, как правило, переводя текущий поток в заблокированное
состояние, выбирая другой поток из списка готовых к выполнению,
устанавливая значения его регистров и возобновляя его выполнение. Чуть позже,
когда ядро узнает, что исходный поток может возобновить свою работу (например, заполнился
канал, из которого он пытался считать данные, или была извлечена из диска
ранее не существовавшая страница), оно выполняет еще один вызов наверх (upcall)
в адрес системы поддержки исполнения программ, чтобы уведомить ее об этом событии.
Система поддержки исполнения программ может либо немедленно возобновить
выполнение заблокированного потока, либо поместить его в список ожидающих потоков
для последующего выполнения.
При возникновении в период выполнения пользовательского потока аппаратного
прерывания центральный процессор, в котором произошло прерывание, переключается
в режим ядра. Если прерывание вызвано событием, не интересующим прерванный
процесс, например завершением операции ввода-вывода, относящейся к другому
процессу, то при завершении работы обработчика прерывания прерванный поток
возвращается назад, в то состояние, в котором он был до возникновения прерывания.
Если же процесс заинтересован в этом прерывании — например, доставлена страница,
необходимая одному из потоков, принадлежащих этому процессу, — выполнение
прерванного потока не возобновляется. Вместо этого прерванный поток приостанавливается
и на виртуальном процессоре запускается система поддержки исполнения
программ, имеющая в стеке состояние прерванного потока. Затем на систему
поддержки исполнения программ возлагается решение, выполнение какого именно
потока спланировать на этом центральном процессоре: прерванного, последнего
ставшего готовым к выполнению или какого-нибудь третьего.
Недостатком активаций планировщика является полная зависимость этой технологии
от вызовов наверх (upcall) — концепции, нарушающей структуру, свойственную любой
многоуровневой системе. Как правило, уровень n предоставляет определенные услуги,
которые могут быть запрошены уровнем n + 1, но уровень n не может вызывать процедуры,
имеющиеся на уровне n + 1. Вызовы наверх (upcall) этому фундаментальному
принципу не следуют.
2.2.8. Всплывающие потоки
Потоки часто используются в распределенных системах. Хорошим примером может
послужить обработка входящих сообщений, к примеру запросов на обслуживание.
Традиционный подход заключается в использовании процесса или потока, блокирующегося
системным вызовом receive в ожидании входящего сообщения. По прибытии
сообщения он его принимает, распаковывает, проверяет его содержимое и проводит
дальнейшую обработку.
Возможен и совершенно иной подход, при котором поступление сообщения вынуждает
систему создать новый поток для его обработки. Такой поток (рис. 2.12) называется
Рис. 2.12. Создание нового потока при поступлении сообщения:
а — до поступления; б — после поступления
всплывающим. Основное преимущество всплывающих потоков заключается в том,
что они создаются заново и не имеют прошлого — никаких регистров, стека и всего
остального, что должно быть восстановлено. Каждый такой поток начинается с чистого
листа, и каждый их них идентичен всем остальным. Это позволяет создавать такие потоки
довольно быстро. Новый поток получает сообщение для последующей обработки.
В результате использования всплывающих потоков задержку между поступлением
и началом обработки сообщения можно свести к минимуму.
При использовании всплывающих потоков требуется предварительное планирование.
К примеру, возникает вопрос: в каком процессе следует запускать поток? Если
система поддерживает потоки, выполняемые в пространстве ядра, поток может быть
запущен в этом пространстве (именно поэтому ядро на рис. 2.12 не показано). Как
правило, запустить всплывающий поток в пространстве ядра легче и быстрее, чем
поместить его в пользовательское пространство. К тому же всплывающий поток
в пространстве ядра получает простой доступ ко всем таблицам ядра и к устройствам
ввода-вывода, которые могут понадобиться для обработки прерывания. В то же время
дефектный поток в пространстве ядра может нанести более существенный урон,
чем такой же поток в пространстве пользователя. К примеру, если он выполняется
слишком долго, а способов его вытеснения не существует, входные данные могут
быть утрачены навсегда.
2.2.9. Превращение однопоточного кода в многопоточный
Многие из существующих программ создавались под однопоточные процессы. Превратить
их в многопоточные куда сложнее, чем может показаться на первый взгляд.
Далее мы рассмотрим лишь некоторые из имеющихся подводных камней.
Начнем с того, что код потока, как и код процесса, обычно содержит несколько процедур.
У этих процедур могут быть локальные и глобальные переменные, а также параметры.
Локальные переменные и параметры проблем не создают, проблемы возникают
с теми переменными, которые носят глобальный характер для потока, но не для всей
программы. Глобальность этих переменных заключается в том, что их использует множество
процедур внутри потока (поскольку они могут использовать любую глобальную
переменную), но другие потоки логически должны их оставить в покое.
Рассмотрим в качестве примера переменную errno, поддерживаемую UNIX. Когда
процесс (или поток) осуществляет системный вызов, терпящий неудачу, код ошибки
помещается в errno. На рис. 2.13 поток 1 выполняет системный вызов access, чтобы
определить, разрешен ли доступ к конкретному файлу. Операционная система возвращает
ответ в глобальной переменной errno. После возвращения управления потоку 1,
но перед тем, как он получает возможность прочитать значение errno, планировщик
решает, что поток 1 на данный момент времени вполне достаточно использовал время
центрального процессора и следует переключиться на выполнение потока 2. Поток 2
выполняет вызов open, который терпит неудачу, что вызывает переписывание значения
переменной errno, и код access первого потока утрачивается навсегда. Когда чуть
позже возобновится выполнение потока 1, он считает неверное значение и поведет
себя некорректно.
Существуют разные способы решения этой проблемы. Можно вообще запретить использование
глобальных переменных. Какой бы заманчивой ни была эта идея, она
вступает в конфликт со многими существующими программами. Другой способ заклюРис.
2.13. Конфликт потоков при использовании глобальной переменной
чается в назначении каждому потоку собственных глобальных переменных (рис. 2.14).
В этом случае у каждого потока есть своя закрытая копия errno и других глобальных
переменных, позволяющая избежать возникновения конфликтов. В результате такого
решения создается новый уровень области определения, где переменные видны всем
процедурам потока (но не видны другим потокам), вдобавок к уже существующим областям
определений, где переменные видны только одной процедуре и где переменные
видны из любого места программы.
Рис. 2.14. У потоков могут быть закрытые глобальные переменные
Однако доступ к закрытым глобальным переменным несколько затруднен, поскольку
большинство языков программирования имеют способ выражения локальных
и глобальных переменных, но не содержат промежуточных форм. Есть возможность
распределить часть памяти для глобальных переменных и передать ее каждой процедуре
потока в качестве дополнительного параметра. Решение не самое изящное, но
работоспособное.
В качестве альтернативы можно ввести новые библиотечные процедуры для создания,
установки и чтения глобальных переменных, видимых только внутри потока. Первый
вызов процедуры может иметь следующий вид:
create_global("bufptr");
Он выделяет хранилище для указателя по имени bufptr в динамически распределяемой
области памяти или в специальной области памяти, зарезервированной для вызывающего
потока. Независимо от того, где именно размещено хранилище, к глобальным
переменным имеет доступ только вызывающий поток. Если другой поток создает
глобальную переменную с таким же именем, она получает другое место хранения и не
конфликтует с уже существующей переменной.
Для доступа к глобальным переменным нужны два вызова: один для записи, а другой
для чтения. Процедура для записи может иметь следующий вид:
set global("bufptr", &buf);
Она сохраняет значение указателя в хранилище, ранее созданном вызовом процедуры
create_global. Процедура для чтения глобальной переменной может иметь следующий
вид:
bufptr = read_global("bufptr");
Она возвращает адрес для доступа к данным, хранящимся в глобальной переменной.
Другой проблемой, возникающей при превращении однопоточной программы в многопоточную,
является отсутствие возможности повторного входа во многие библиотечные
процедуры. То есть они не создавались с расчетом на то, что каждая отдельно взятая
процедура будет вызываться повторно еще до того, как завершился ее предыдущий
вызов. К примеру, отправка сообщения по сети может быть запрограммирована на то,
чтобы предварительно собрать сообщение в фиксированном буфере внутри библиотеки,
а затем для его отправки осуществить перехват управления ядром. Представляете,
что произойдет, если один поток собрал свое сообщение в буфере, а затем прерывание
по таймеру вызвало переключение на выполнение второго потока, который тут же
переписал буфер своим собственным сообщением?
Подобная проблема возникает и с процедурами распределения памяти, к примеру
с процедурой malloc в UNIX, работающей с весьма важными таблицами использования
памяти, например со связанным списком доступных участков памяти. Когда
процедура malloc занята обновлением этих списков, они могут временно пребывать
в несообразном состоянии, с указателями, которые указывают в никуда. Если в момент
такого несообразного состояния произойдет переключение потоков и из другого потока
поступит новый вызов, будут использованы неверные указатели, что приведет к сбою
программы. Для эффективного устранения всех этих проблем потребуется переписать
всю библиотеку. А это далеко не самое простое занятие с реальной возможностью внесения
труднообнаруживаемых ошибок.
Другим решением может стать предоставление каждой процедуре оболочки, которая
устанавливает бит, отмечающий, что библиотека уже используется. Любая попытка
другого потока воспользоваться библиотечной процедурой до завершения предыдущего
вызова будет заблокирована. Хотя этот подход вполне осуществим, он существенно
снижает потенциальную возможность параллельных вычислений.
А теперь рассмотрим сигналы. Некоторые сигналы по своей логике имеют отношение
к потокам, а некоторые не имеют к ним никакого отношения. К примеру, если поток
осуществляет системный вызов alarm, появляется смысл направить результирующий
сигнал к вызывающему потоку. Но когда потоки целиком реализованы в пользовательском
пространстве, ядро даже не знает о потоках и вряд ли сможет направить сигнал
к нужному потоку. Дополнительные сложности возникают в том случае, если у процесса
на данный момент есть лишь один необработанный аварийный сигнал и несколько потоков
осуществляют системный вызов alarm независимо друг от друга.
Другие сигналы, например прерывания клавиатуры, не имеют определенного отношения
к потокам. Кто их должен перехватывать? Один специально назначенный поток?
Или все потоки? А может быть, заново создаваемый всплывающий поток? Кроме того,
что произойдет, если один из потоков вносит изменения в обработчики сигналов, не
уведомляя об этом другие потоки? А что случится, если одному потоку потребуется
перехватить конкретный сигнал (например, когда пользователь нажмет  CTRL+C ), а другому
потоку этот сигнал понадобится для завершения процесса? Подобная ситуация
может сложиться, если в одном или нескольких потоках выполняются стандартные
библиотечные процедуры, а в других — процедуры, созданные пользователем. Совершенно
очевидно, что такие требования потоков несовместимы. В общем, с сигналами не
так-то легко справиться и при наличии лишь одного потока, а переход к многопоточной
среде отнюдь не облегчает их обработку.
Остается еще одна проблема, создаваемая потоками, — управление стеком. Во многих
системах при переполнении стека процесса ядро автоматически предоставляет ему
дополнительное пространство памяти. Когда у процесса несколько потоков, у него
должно быть и несколько стеков. Если ядро ничего не знает о существовании этих
стеков, оно не может автоматически наращивать их пространство при ошибке стека.
Фактически оно даже не сможет понять, что ошибка памяти связана с разрастанием
стека какого-нибудь потока.
Разумеется, эти проблемы не являются непреодолимыми, но они наглядно демонстрируют,
что простое введение потоков в существующую систему без существенной
доработки приведет к ее полной неработоспособности. Возможно, необходимый
минимум будет состоять в переопределении семантики системных вызовов и переписывании
библиотек. И все это должно быть сделано так, чтобы сохранялась обратная
совместимость с существующими программами, когда все ограничивается процессом,
имеющим только один поток. Дополнительную информацию о потоках можно найти
в трудах Хаузера (Hauser et al., 1993), Марша (Marsh et al., 1991) и Родригеса (Rodrigues
et al., 2010).
2.3. Взаимодействие процессов
Довольно часто процессам необходимо взаимодействовать с другими процессами.
Например, в канале оболочки выходные данные одного процесса могут передаваться
другому процессу, и так далее вниз по цепочке. Поэтому возникает необходимость во
взаимодействии процессов, и желательно по хорошо продуманной структуре без использования
прерываний. В следующих разделах мы рассмотрим некоторые вопросы,
связанные со взаимодействием процессов, или межпроцессным взаимодействием
(InterProcess Communication (IPC)).
Короче говоря, будут рассмотрены три вопроса. Первый будет касаться уже упомянутого
примера: как один процесс может передавать информацию другому процессу. Второй
коснется обеспечения совместной работы процессов без создания взаимных помех,
когда, к примеру, два процесса в системе бронирования авиабилетов одновременно
пытаются захватить последнее место в самолете для разных клиентов. Третий вопрос
коснется определения правильной последовательности на основе существующих взаимозависимостей:
если процесс А вырабатывает данные, а процесс Б их распечатывает,
то процесс Б, перед тем как печатать, должен подождать, пока процесс А не выработает
определенные данные. Изучение всех трех вопросов начнется со следующего раздела.
Следует отметить, что два из этих трех вопросов также применимы и к потокам. Первый
из них, касающийся передачи информации, применительно к потокам решается
значительно легче, поскольку потоки имеют общее адресное пространство (взаимодействующие
потоки, реализованные в различных адресных пространствах, подпадают
под категорию взаимодействия процессов). А вот два других вопроса — относительно
исключения взаимных помех и правильной последовательности — в полной мере
применимы и к потокам: сходные проблемы и сходные методы их решения. Далее проблемы
будут рассматриваться в контексте процессов, но нужно иметь в виду, что те же
проблемы и решения применяются и в отношении потоков.
2.3.1. Состязательная ситуация
В некоторых операционных системах совместно работающие процессы могут использовать
какое-нибудь общее хранилище данных, доступное каждому из них по чтению и по
записи. Это общее хранилище может размещаться в оперативной памяти (возможно,
в структуре данных ядра) или может быть представлено каким-нибудь общим файлом.
Расположение общей памяти не меняет характера взаимодействия и возникающих при
этом проблем. Чтобы посмотреть, как взаимодействие процессов осуществляется на
практике, давайте рассмотрим простой общеизвестный пример — спулер печати. Когда
процессу необходимо распечатать какой-нибудь файл, он помещает имя этого файла
в специальный каталог спулера.
Другой процесс под названием демон принтера периодически проверяет наличие файлов
для печати и в том случае, если такие файлы имеются, распечатывает их и удаляет
их имена из каталога.
Представьте, что в нашем каталоге спулера имеется большое количество областей
памяти с номерами 0, 1, 2..., в каждой из которых может храниться имя файла. Также
представьте, что есть две общие переменные: out, указывающая на следующий файл,
предназначенный для печати, и in, указывающая на следующую свободную область
в каталоге. Эти две переменные могли бы неплохо сохраняться в файле, состоящем
из двух слов и доступном всем процессам. В какой-то момент времени области от 0 до
3 пустуют (файлы уже распечатаны). Почти одновременно процессы А и Б решают,
что им нужно поставить файл в очередь на печать. Эта ситуация показана на рис. 2.15.
В правовом пространстве, где применимы законы Мэрфи, может случиться следующее.
Процесс А считывает значение переменной in и сохраняет значение 7 в локальной
переменной по имени next_ free_slot (следующая свободная область). Сразу же после
этого происходит прерывание по таймеру, центральный процессор решает, что процесс
А проработал достаточно долго, и переключается на выполнение процесса Б. Процесс
Б также считывает значение переменной in и также получает число 7. Он также
сохраняет его в своей локальной переменной next_ free_slot. К текущему моменту оба
процесса полагают, что следующей доступной областью будет 7. Процесс Б продолжает
Рис. 2.15. Одновременное стремление двух процессов получить доступ к общей памяти
выполняться. Он сохраняет имя своего файла в области 7 и присваивает переменной
in обновленное значение 8. Затем он переходит к выполнению каких-нибудь других
действий. Через некоторое время выполнение процесса А возобновляется с того места,
где он был остановлен. Он считывает значение переменной next_ free_slot, видит там
число 7 и записывает имя своего файла в область 7, затирая то имя файла, которое
только что было в него помещено процессом Б. Затем он вычисляет next_ free_slot + 1,
получает значение 8 и присваивает его переменной in. В каталоге спулера нет внутренних
противоречий, поэтому демон печати не заметит никаких нестыковок, но процесс Б
никогда не получит вывода на печать.
Пользователь Б будет годами бродить вокруг принтера, тоскливо надеясь получить распечатку,
которой не будет никогда. Подобная ситуация, когда два или более процесса
считывают или записывают какие-нибудь общие данные, а окончательный результат
зависит от того, какой процесс и когда именно выполняется, называется состязательной
ситуацией. Отладка программ, в которых присутствует состязательная ситуация,
особой радости не доставляет. Результаты большинства прогонов могут быть вполне
приемлемыми, но до поры до времени, пока не наступит тот самый редкий случай, когда
произойдет нечто таинственное и необъяснимое. К сожалению, с ростом параллелизма
из-за все большего количества ядер состязательные ситуации встречаются все чаще.
2.3.2. Критические области
Как же избежать состязательной ситуации? Ключом к предупреждению проблемы
в этой и во многих других ситуациях использования общей памяти, общих файлов
и вообще чего-нибудь общего может послужить определение способа, при котором
в каждый конкретный момент времени доступ к общим данным для чтения и записи
может получить только один процесс. Иными словами, нам нужен способ взаимного
исключения, то есть некий способ, обеспечивающий правило, при котором если общие
данные или файл используются одним процессом, возможность их использования
всеми другими процессами исключается. Описанные выше трудности произошли
благодаря тому, что процесс Б стал использовать общие переменные еще до того, как
процесс А завершил работу с ними. Выбор подходящих элементарных операций для
достижения взаимного исключения является основной проблемой конструирования
любой операционной системы, и именно ее мы будем подробно рассматривать в следующих
разделах.
Проблемы обхода состязательных ситуаций могут быть сформулированы также
в абстрактной форме. Какую-то часть времени процесс занят внутренними вычислениями
и чем-нибудь другим, не создающим состязательных ситуаций. Но иногда
он вынужден обращаться к общей памяти или файлам либо совершать какие-нибудь
другие значимые действия, приводящие к состязаниям. Та часть программы, в которой
используется доступ к общей памяти, называется критической областью или критической
секцией. Если бы удалось все выстроить таким образом, чтобы никакие два
процесса не находились одновременно в своих критических областях, это позволило
бы избежать состязаний.
Хотя выполнение этого требования позволяет избежать состязательных ситуаций, его
недостаточно для того, чтобы параллельные процессы правильно выстраивали совместную
работу и эффективно использовали общие данные. Для приемлемого решения
необходимо соблюдение четырех условий:
1. Два процесса не могут одновременно находиться в своих критических областях.
2. Не должны выстраиваться никакие предположения по поводу скорости или количества
центральных процессоров.
3. Никакие процессы, выполняемые за пределами своих критических областей, не
могут блокироваться любым другим процессом.
4. Процессы не должны находиться в вечном ожидании входа в свои критические
области.
В абстрактном смысле необходимое нам поведение показано на рис. 2.16. Мы видим,
что процесс А входит в свою критическую область во время T 1 . Чуть позже, когда наступает
время T 2 , процесс Б пытается войти в свою критическую область, но терпит
неудачу, поскольку другой процесс уже находится в своей критической области, а мы
допускаем это в каждый момент времени только для одного процесса. Следовательно,
Рис. 2.16. Взаимное исключение использования критических областей
Б временно приостанавливается до наступления времени T 3 , когда A покинет свою критическую
область, позволяя Б тут же войти в свою критическую область. Со временем
(в момент T 4 ) Б покидает свою критическую область, и мы возвращаемся в исходную
ситуацию, когда ни один из процессов не находится в своей критической области.
2.3.3. Взаимное исключение с активным ожиданием
В этом разделе будут рассмотрены различные предложения для достижения режима
взаимного исключения, при котором, пока один процесс занят обновлением общей
памяти и находится в своей критической области, никакой другой процесс не сможет
войти в свою критическую область и создать проблему.
Запрещение прерываний
В однопроцессорных системах простейшим решением является запрещение всех прерываний
каждым процессом сразу после входа в критическую область и их разрешение
сразу же после выхода из критической области. При запрещении прерываний не могут
осуществляться никакие прерывания по таймеру. Поскольку центральный процессор
переключается с одного процесса на другой в результате таймерных или каких-нибудь
других прерываний, то при выключенных прерываниях он не сможет переключиться
на другой процесс. Поскольку процесс запретил прерывания, он может исследовать
и обновлять общую память, не опасаясь вмешательства со стороны любого другого
процесса.
Но вообще-то этот подход не слишком привлекателен, поскольку абсолютно неразумно
давать пользовательским процессам полномочия выключать все прерывания. Представьте,
что получится, если один из них выключил и не включил прерывания? Это
может вызвать крах всей системы. Более того, если мы имеем дело с многопроцессорной
системой (с двумя или, может быть, несколькими центральными процессорами),
запрещение прерываний действует только на тот центральный процессор, на котором
выполняется запретительная инструкция. Все остальные процессоры продолжат свою
работу и смогут обращаться к общей памяти.
В то же время запрещение прерываний всего на несколько инструкций зачастую
является очень удобным средством для самого ядра, когда оно обновляет переменные
или списки. К примеру, когда прерывание происходит в момент изменения
состояния списка готовых процессов, может сложиться состязательная ситуация.
Вывод здесь следующий: запрещение прерываний в большинстве своем является полезной
технологией внутри самой операционной системы, но не подходит в качестве
универсального механизма взаимных блокировок для пользовательских процессов.
Благодаря увеличению количества многоядерных центральных процессоров даже на
недорогих персональных компьютерах возможности достижения взаимного исключения
за счет запрещения прерываний даже внутри ядра сужаются. Уже становится
привычным наличие двухъядерных процессоров, на многих машинах имеются четыре
ядра, и не за горами распространение 8-, 16- или 32-ядерных процессоров. Запрещение
прерываний на одном центральном процессоре в многоядерных (то есть мультипроцессорных)
системах не запрещает другим центральным процессорам препятствовать
операциям, выполняемым первым центральным процессором. Следовательно, возникает
потребность в применении более сложных схем.
Блокирующие переменные
В качестве второй попытки рассмотрим программное решение, в котором используется
одна общая (блокирующая) переменная, исходное значение которой равно нулю. Когда
процессу требуется войти в свою критическую область, сначала он проверяет значение
блокирующей переменной. Если оно равно 0, процесс устанавливает его в 1 и входит
в критическую область. Если значение уже равно 1, процесс просто ждет, пока оно не
станет равно нулю. Таким образом, нулевое значение показывает, что ни один из процессов
не находится в своей критической области, а единица — что какой-то процесс
находится в своей критической области.
К сожалению, реализация этой идеи приводит к точно такому же фатальному исходу,
который мы уже видели в примере с каталогом спулера. Предположим, что один процесс
считывает значение блокирующей переменной и видит, что оно равно нулю. Перед
тем как он сможет установить значение в единицу, планировщик запускает другой процесс,
который устанавливает значение в единицу. Когда возобновляется выполнение
первого процесса, он также установит значение блокирующей переменной в единицу,
и два процесса одновременно окажутся в своих критических областях.
Может показаться, что эту проблему можно обойти, считывая сначала значение блокирующей
переменной, а затем проверяя ее значение повторно, прежде чем сохранить
в ней новое значение, но на самом деле это не поможет. Состязание возникнет в том
случае, если второй процесс изменит значение блокирующей переменной сразу же после
того, как первый процесс завершит повторную проверку ее значения.
Строгое чередование
Третий подход к решению проблемы взаимных исключений показан на рис. 2.17. Этот
программный фрагмент, как почти все фрагменты, приводимые в этой книге, написан
на языке C. Выбор пал именно на этот язык, поскольку настоящие операционные
системы почти всегда пишутся на C (изредка на C++) и практически никогда не пишутся
на Java, Pyton или Haskell. Мощность, эффективность и предсказуемость языка
С — именно те характеристики, которые крайне необходимы для написания операционных
систем. Java, к примеру, не является предсказуемым языком, поскольку в самый
неподходящий момент у него может закончиться свободная память и возникнуть потребность
в вызове сборщика мусора для очистки памяти. Для C это не свойственно,
поскольку в этом языке нет сборщика мусора. Количественное сравнение C, C++, Java
и четырех других языков приведено в работе Пречелда (Precheld, 2000).
Рис. 2.17. Предлагаемое решение проблемы критической области: а — процесс 0;
б — процесс 1. В обоих случаях следует убедиться, что в коде присутствует точка с запятой,
завершающая оператор while
Изначально целочисленная переменная turn, показанная на рис. 2.17, равна нулю
и отслеживает, чья настала очередь входить в критическую область и проверять или
обновлять общую память. Сначала процесс 0 проверяет значение turn, определяет, что
оно равно нулю, и входит в критическую область. Процесс 1 также определяет, что значение
этой переменной равно нулю, из-за чего находится в коротком цикле, постоянно
проверяя, когда turn получит значение 1. Постоянная проверка значения переменной,
пока она не приобретет какое-нибудь значение, называется активным ожиданием.
Как правило, этого ожидания следует избегать, поскольку оно тратит впустую время
центрального процессора. Активное ожидание используется только в том случае, если
есть основание полагать, что оно будет недолгим. Блокировка, использующая активное
ожидание, называется спин-блокировкой.
Когда процесс 0 выходит из критической области, он устанавливает значение переменной
turn в 1, разрешая процессу 1 войти в его критическую область. Предположим,
что процесс 1 быстро выходит из своей критической области, в результате чего оба
процесса находятся вне своих критических областей, а переменная turn установлена
в 0. Теперь процесс 0 быстро завершает свой полный цикл, выходит из критической
области и устанавливает значение turn в 1. В этот момент значение turn равно 1 и оба
процесса выполняются вне своих критических областей.
Внезапно процесс 0 завершает работу вне своей критической области и возвращается
к началу цикла. К сожалению, в данный момент ему не разрешено войти в его критическую
область, поскольку переменная turn имеет значение 1 и процесс 1 занят работой
вне своей критической области. Процесс 0 зависает в своем цикле while до тех пор, пока
процесс 1 не установит значение turn в 0. Иначе говоря, когда один процесс работает
существенно медленнее другого, поочередная организация вхождения в критическую
область вряд ли подойдет.
Эта ситуация нарушает сформулированное ранее третье условие: процесс 0 оказывается
заблокированным тем процессом, который не находится в своей критической области.
Вернемся к ранее рассмотренному каталогу спулера. Если в такой ситуации мы свяжем
критическую область с чтением или записью в каталог спулера, процессу 0 будет запрещено
распечатать следующий файл, поскольку процесс 1 будет занят чем-нибудь другим.
Фактически это решение требует, чтобы, к примеру, при помещении файлов в каталог
спулера два процесса входили в свои критические области, строго чередуясь друг с другом.
Ни одному из них не разрешено поместить файл в спулер два раза подряд. Хотя
этот алгоритм позволяет предотвращать любые состязательные ситуации, его нельзя
рассматривать в качестве серьезного кандидата на решение проблемы, поскольку он
нарушает третье условие.
Алгоритм Петерсона
Используя сочетание идеи очередности с идеей блокирующих и предупреждающих
переменных, голландский математик Деккер (T. Dekker) стал первым, кто придумал
программное решение проблемы взаимного исключения, не требующее четкой очередности.
Обсуждение алгоритма Деккера приведено в книге Дейкстры (Dijkstra, 1965).
В 1981 году Петерсон придумал гораздо более простой способ достижения взаимного
исключения, которое перевело решение Деккера в разряд устаревших. Алгоритм Петерсона
показан в листинге 2.2. Этот алгоритм состоит из двух процедур, написанных
на ANSI C, а это значит, что для всех определенных и используемых функций должны
быть предоставлены функции-прототипы. Но в целях экономии места мы не будем
показывать прототипы ни в этом, ни в последующих примерах.
Листинг 2.2. Решение Петерсона, позволяющее добиться взаимного исключения
#define FALSE 0
#define TRUE 1
#define N 2 /* количество процессов */
int turn; /* чья очередь? */
int interested[N]; /* все исходные значения равны 0 (FALSE) */
void enter_region(int process); /* process имеет значение 0 или 1 */
{
int other; /* номер другого процесса */
other = 1 ? process; /* противостоящий процесс */
interested[process] = TRUE; /* демонстрация заинтересованности */
turn = process; /* установка флажка */
while (turn == process && interested[other] == TRUE)/* цикл без инструкции
*/;
}
void leave_region(int process) /* процесс, покидающий критическую область */
{
interested[process] = FALSE; /* признак выхода из критической области */ }
Перед использованием общих переменных (то есть перед входом в свою критическую
область) каждый процесс вызывает функцию enter_region, передавая ей в качестве
аргумента свой собственный номер процесса, 0 или 1. Этот вызов заставляет процесс
ждать, если потребуется, безопасного входа в критическую область. После завершения
работы с общими переменными процесс, чтобы показать это и разрешить вход другому
процессу, если ему это требуется, вызывает функцию leave_region.
Рассмотрим работу алгоритма. Изначально ни один из процессов не находится в критической
области. Затем процесс 0 вызывает функцию enter_region. Он демонстрирует свою
заинтересованность, устанавливая свой элемент массива и присваивая переменной turn
значение 0. Поскольку процесс 1 заинтересованности во входе в критическую область
не проявил, функция enter_region тотчас же возвращает управление. Теперь, если процесс
1 вызовет функцию enter_region, он зависнет до тех пор, пока interested[0] не получит
значение FALSE, а это произойдет только в том случае, если процесс 0 вызовет функцию
leave_region, чтобы выйти из критической области.
Теперь рассмотрим случай, когда оба процесса практически одновременно вызывают
функцию enter_region. Оба они будут сохранять свой номер процесса в переменной
turn. В расчет берется последнее сохранение, поскольку первое будет переписано
и утрачено. Предположим, что процесс 1 сохранил свой номер последним и turn имеет
значение 1. Когда оба процесса доберутся до оператора while, процесс 0 не выполнит
его ни одного раза и войдет в свою критическую область. Процесс 1 войдет в цикл и не
будет входить в свою критическую область до тех пор, пока процесс 0 не выйдет из
своей критической области.
Команда TSL
А теперь давайте рассмотрим предложение, для реализации которого требуется небольшая
помощь со стороны оборудования. Некоторые компьютеры, в особенности те,
которые разрабатывались с прицелом на работу нескольких процессов, располагают
командой
TSL RX,LOCK
(TSL — Test and Set Lock, то есть проверь и установи блокировку), которая работает
следующим образом. Она считывает содержимое слова памяти lock в регистр RX, а по
адресу памяти, отведенному для lock, записывает ненулевое значение. При этом гарантируются
неделимость операций чтения слова и сохранение в нем нового значения —
никакой другой процесс не может получить доступ к слову в памяти, пока команда не
завершит свою работу. Центральный процессор, выполняющий команду TSL, блокирует
шину памяти, запрещая другим центральным процессорам доступ к памяти до тех пор,
пока не будет выполнена эта команда.
Следует заметить, что блокировка шины памяти существенно отличается от запрета
на прерывания. Если при выполнении чтения слова памяти с последующей записью
в него запретить прерывания, ничто не помешает второму центральному процессору,
подключенному к шине памяти, получить доступ к слову между чтением и записью.
Получается, что запрет прерываний на процессоре 1 не оказывает абсолютно никакого
воздействия на процессор 2. Перекрыть процессору 2 доступ к памяти, пока
процессор 1 не завершит выполнение команды, можно только одним способом — заблокировав
шину, а для этого требуется специальное оборудование (в основном для
этого используется линия шины, сигнал на которой блокирует шину, исключая к ней
доступ всех процессоров, кроме того, который ее заблокировал).
Чтобы задействовать команду TSL, мы воспользуемся общей переменной lock, позволяющей
скоординировать доступ к общей памяти. Когда lock имеет значение 0, любой
процесс, используя команду TSL, может установить ее значение в 1, а затем производить
операции чтения или записи с общей памятью. Когда процесс завершит эти операции,
он возвращает переменной lock значение 0, используя обычную команду move.
Как же воспользоваться этой командой для предотвращения одновременного входа
двух процессов в их критические области? Решение продемонстрировано в листинге
2.3. В нем показана подпрограмма, состоящая из четырех команд, написанная на
вымышленном (но типовом) языке ассемблера. Первая команда копирует прежнее
значение переменной lock в регистр, а затем присваивает ей значение 1. Затем прежнее
значение сравнивается с нулем. Если оно ненулевое, значит, блокировка уже
была установлена, поэтому программа просто возвращается в самое начало и повторно
проверяет значение переменной. Рано или поздно это значение превратится
в 0 (когда процесс, находившийся в своей критической области, завершит в ней
работу и произойдет выход из подпрограммы с установкой блокировки). Снятие
блокировки осуществляется довольно просто: программе достаточно присвоить
переменной lock нулевое значение. Для этого не нужны никакие специальные
команды синхронизации.
Теперь суть одного из решений проблемы критических областей прояснилась. Перед
входом в свою критическую область процесс вызывает функцию enter_region, которая
входит в цикл активного ожидания, пока не будет снята блокировка, затем она устанавливает
блокировку и возвращает управление. Завершив работу в критической области,
процесс вызывает функцию leave_region, которая присваивает переменной lock
нулевое значение. Как и во всех решениях проблемы критических областей, чтобы
этот способ заработал, процессы должны своевременно вызывать функции enter_region
и leave_region. Если какой-нибудь из процессов не выполнит это условие, взаимное исключение
не сработает. Иными словами, критические области работают, только если
процессы взаимодействуют.
Листинг 2.3. Вход и выход из критической области
с использованием команды TSL
enter region:
TSL REGISTER,LOCK | копирование lock в регистр с присвоением ей 1
CMP REGISTER,#0 | было ли значение lock нулевым?
JNE enter_region | если оно было ненулевым, значит, блокировка
| уже установлена и нужно войти в цикл
RET | возврат управления вызывающей программе;
| вход в критическую область осуществлен
leave region:
MOVE LOCK,#0 | присвоение переменной lock нулевого значения
RET | возврат управления вызывающей программе
Альтернативой команде TSL служит команда XCHG, осуществляющая атомарный
обмен содержимого двух областей памяти, например регистра и слова памяти. Можно
заметить, что код, показанный в листинге 2.4, практически такой же, как и в решении
с использованием команды TSL. Команда XCHG используется для низкоуровневой
синхронизации всеми центральными процессорами семейства Intel x86.
Листинг 2.4. Вход и выход из критической области
с использованием команды XCHG
Enter_region:
MOVE REGISTER,#1 | помещение 1 в регистр
XCHG REGISTER,LOCK | обмен содержимого регистра и переменной lock
CMP REGISTER,#0 | было ли значение lock нулевым?
JNE enter_region | если оно было ненулевым, значит, блокировка
| уже установлена и нужно войти в цикл
RET | возврат управления вызывающей программе;
| вход в критическую область осуществлен
leave region:
MOVE LOCK,#0 | присвоение переменной lock нулевого значения
RET | возврат управления вызывающей программе
2.3.4. Приостановка и активизация
И алгоритм Петерсона, и решение, использующее команду TSL или XCHG, вполне работоспособны,
но у них есть один недостаток — необходимость пребывания в режиме
активного ожидания. По сути эти решения сводятся к следующему: когда процессу
требуется войти в критическую область, он проверяет, разрешен ли этот вход. Если
вход запрещен, процесс просто входит в короткий цикл, ожидая разрешения.
Этот подход не только приводит к пустой трате процессорного времени, но и может
иметь совершенно неожиданные эффекты. Рассмотрим компьютер с двумя процессами:
H с высокой степенью приоритета и L с низкой степенью приоритета. Правила
планирования их работы предусматривают, что H выполняется сразу же после входа
в состояние готовности. В определенный момент, когда L находится в критической
области, H входит в состояние готовности (к примеру, после завершения операции
ввода-вывода). Теперь H входит в режим активного ожидания, но поскольку, пока выполняется
процесс H, выполнение L не планируется, у L не остается шансов вый ти из
своей критической области, поэтому H пребывает в бесконечном цикле. На подобную
ситуацию иногда ссылаются как на проблему инверсии приоритета.
Теперь рассмотрим некоторые примитивы взаимодействия процессов, которые блокируют
работу, пока им не разрешается входить в критическую область, вместо напрасной
траты времени центрального процессора. Представителями простейшей пары таких
примитивов являются sleep и wakeup. Системный вызов sleep блокирует вызывающий
его процесс, который приостанавливается до тех пор, пока его не активизирует другой
процесс. Активизирующий вызов wakeup использует один аргумент — активизируемый
процесс. Дополнительно и sleep и wakeup используют еще один аргумент — адрес памяти,
используемой для соотнесения вызовов sleep с вызовами wakeup.
Задача производителя и потребителя
В качестве примера применения этих примитивов рассмотрим задачу производителя
и потребителя (также известную как задача ограниченного буфера). Два процесса
используют общий буфер фиксированного размера. Один из них, производитель,
помещает информацию в буфер, а другой, потребитель, извлекает ее оттуда. (Можно
также расширить проблему до m производителей и n потребителей, но мы будем рассматривать
только случай с одним производителем и одним потребителем, поскольку
такое допущение упрощает решение.)
Проблемы возникают в тот момент, когда производителю требуется поместить новую
запись в уже заполненный буфер. Решение заключается в блокировании производителя
до тех пор, пока потребитель не извлечет как минимум одну запись. Также, если потребителю
нужно извлечь запись из буфера и он видит, что буфер пуст, он блокируется
до тех пор, пока производитель не поместит что-нибудь в буфер и не активизирует
этого потребителя.
На первый взгляд этот подход выглядит довольно простым, но он приводит к той же
разновидности состязательной ситуации, которая нам уже встречалась в примере
с каталогом спулера. Для отслеживания количества записей в буфере нам потребуется
переменная count. Если максимальное количество записей, которое может содержаться
в буфере, равно N, то программа производителя должна сначала проверить, не имеет
ли count значение N. Если переменная имеет такое значение, производитель должен заблокировать
свое выполнение, а если не имеет, производитель должен добавить запись
и увеличить показание счетчика count.
Программа потребителя работает схожим образом: сначала проверяет, не является ли
значение count нулевым. Если оно равно нулю, процесс блокирует свое выполнение,
а если не равно нулю, он извлекает запись и уменьшает значение счетчика. Каждый
из процессов также проверяет, не нужно ли активизировать другой процесс, и если
нужно, проводит эту активизацию. Программы производителя и потребителя показаны
в листинге 2.5.
Чтобы выразить вызовы sleep и wakeup на языке C, мы покажем их в виде вызовов
библиотечных процедур. Они не являются частью стандартной библиотеки C,
но, по-видимому, были бы доступны на любой системе, имеющей эти системные
вызовы.
Листинг 2.5. Задача производителя и потребителя с фатальной состязательной
ситуацией
#define N 100 /* количество мест для записей в буфере */
int count = 0; /* количество записей в буфере */
void producer(void)
{
int item;
while (TRUE) { /* бесконечное повторение */
item = produce_item( ); /* генерация новой записи */
if (count == N) sleep( ); /* если буфер полон, заблокироваться */
insert_item(item); /* помещение записи в буфер */
count = count + 1; /* увеличение счетчика записей в буфере */
if (count == 1) wakeup(consumer); /* был ли буфер пуст? */
}
}
void consumer(void)
{
int item;
while (TRUE) { /* бесконечное повторение */
if (count == 0) sleep(); /* если буфер пуст, заблокироваться */
item = remove_item( ); /* извлечь запись из буфера */
count = count? 1; /* уменьшение счетчика записей в буфере */
if (count == N ? 1) wakeup(producer); /* был ли буфер полон? */
consume_item(item); /* распечатка записи */
}
}
Не показанные в листинге процедуры insert_item и remove_item занимаются помещением
записей в буфер и извлечением их оттуда.
Вернемся теперь к состязательной ситуации. Причиной ее появления может стать свободный
доступ к счетчику count. Как следствие может сложиться следующая ситуация.
Буфер пуст, и потребитель только что считал показания count, чтобы увидеть, что его
значение равно 0. В этот самый момент планировщик решает временно приостановить
выполнение процесса потребителя и возобновить выполнение процесса производителя.
Производитель помещает запись в буфер, увеличивает значение счетчика count
и замечает, что теперь оно равно 1. Приняв во внимание, что только что счетчик имел
нулевое значение, при котором потребитель должен находиться в заблокированном
состоянии, производитель вызывает процедуру wakeup, чтобы активизировать выполнение
процесса потребителя.
К сожалению, с точки зрения логики программы потребитель не находился в бездействующем
состоянии, поэтому сигнал на активизацию будет утрачен. Когда подойдет
очередь возобновить выполнение процесса потребителя, он проверит ранее считанное
значение счетчика, определит, что оно было равно 0, и снова перейдет в заблокированное
состояние. Рано или поздно производитель заполнит буфер и тоже перейдет
в заблокированное состояние. И оба процесса впадут в вечную спячку.
Суть возникшей проблемы заключается в утрате вызова wakeup в отношении процесса,
который не находится в состоянии блокировки по собственной воле. Если бы этот вызов
не утрачивался, то все бы работало должным образом. Быстро устранить проблему
позволит изменение правил за счет добавления к картине событий бита ожидания
активизации. Этот бит устанавливается, когда в отношении процесса, который не находится
в состоянии бездействия, вызывается процедура wakeup. Затем, когда процесс
попытается заблокироваться при установленном бите ожидания активизации, этот
бит снимается, но процесс не блокируется. Бит ожидания активизации становится
своеобразной копилкой, хранящей сигналы активизации. Потребитель снимает бит
ожидания активизации в каждой итерации цикла.
Хотя в нашем простом примере бит ожидания активизации спасает положение, нетрудно
создать такие примеры, где фигурируют три и более процесса, для которых
одного бита ожидания активизации явно недостаточно. Можно внести другие правки
и добавить второй бит ожидания активизации, а может быть, 8 или 32 таких бита, но,
в принципе, проблема останется нерешенной.
 году, когда Дейкстра предложил использовать целочисленную
переменную для подсчета количества активизаций, отложенных на будущее.
Он предложил учредить новый тип переменной — семафор (semaphore). Значение
семафора может быть равно 0, что будет свидетельствовать об отсутствии сохраненных
активизаций, или иметь какое-нибудь положительное значение, если ожидается не
менее одной активизации.
Дейкстра предложил использовать две операции с семафорами, которые сейчас обычно
называют down и up (обобщения sleep и wakeup соответственно). Операция down выясняет,
отличается ли значение семафора от 0. Если отличается, она уменьшает это значение
на 1 (то есть использует одну сохраненную активизацию) и продолжает свою работу.
Если значение равно 0, процесс приостанавливается, не завершая в этот раз операцию
down. И проверка значения, и его изменение, и, возможно, приостановка процесса осуществляются
как единое и неделимое атомарное действие. Тем самым гарантируется,
что с началом семафорной операции никакой другой процесс не может получить доступ
к семафору до тех пор, пока операция не будет завершена или заблокирована. Атомарность
является абсолютно необходимым условием для решения проблем синхронизации
и исключения состязательных ситуаций. Атомарные действия, в которых группа взаимосвязанных
операций либо выполняется без каких-либо прерываний, либо вообще не
выполняется, приобрели особую важность и во многих других областях информатики.
Операция up увеличивает значение, адресуемое семафором, на 1. Если с этим семафором
связаны один или более приостановленных процессов, способных завершить
ранее начатые операции down, система выбирает один из них (к примеру, произвольным
образом) и позволяет ему завершить его операцию down. Таким образом, после применения
операции up в отношении семафора, с которым были связаны приостановленные
процессы, значение семафора так и останется нулевым, но количество приостановленных
процессов уменьшится на 1. Операция увеличения значения семафора на 1
и активизации одного из процессов также является неделимой. Ни один из процессов
не может быть заблокирован при выполнении операции up, равно как ни один из процессов
не может быть заблокирован при выполнении wakeup в предыдущей модели.
Между прочим, в первоначальном варианте своей работы Дейкстра вместо down и up
использовал имена P и V соответственно. Но в них не было никакого мнемонического
смысла для тех, кто не говорит по-голландски, да и для тех, кто говорит, смысл был
едва уловим — Proberen (пытаться) и Verhogen (поднимать выше), поэтому вместо них
мы будет употреблять down и up. Впервые они были представлены в языке программирования
Algol 68.
Решение задачи производителя-потребителя
с помощью семафоров
В листинге 2.6 показано, как с помощью семафоров решается проблема утраченных активизаций.
Чтобы заставить их корректно работать, очень важно, чтобы их реализация
предусматривала неделимый режим работы. Вполне естественно было бы реализовать
операции up и down в виде системных вызовов, чтобы операционная система на время
тестирования семафора, обновления его значения и приостановки процесса при необходимости
кратковременно запрещала все прерывания. Поскольку все эти действия
занимают только несколько команд, запрет на прерывания не причинит никакого вреда.
Если используются несколько центральных процессоров, каждый семафор должен
быть защищен переменной lock, а для гарантии того, что семафор в отдельно взятый
момент времени задействуется только одним центральным процессором, используется
команда TSL или XCHG.
Нужно усвоить, что использование TSL или XCHG для предупреждения одновременного
доступа к семафору нескольких центральных процессоров в корне отличается от
режима активного ожидания производителем или потребителем момента опустошения
или наполнения буфера. Операция работы с семафором займет лишь несколько микросекунд,
а ожидание производителя или потребителя может быть сколь угодно долгим.
В этом решении используются три семафора: один из них называется full и предназначен
для подсчета количества заполненных мест в буфере, другой называется empty
и предназначен для подсчета количества пустых мест в буфере, третий называется
mutex, он предотвращает одновременный доступ к буферу производителя и потребителя.
Семафор full изначально равен 0, семафор empty изначально равен количеству
мест в буфере, семафор mutex изначально равен 1. Семафоры, инициализированные
значением 1 и используемые двумя или более процессами для исключения их одновременного
нахождения в своих критических областях, называются двоичными семафорами.
Взаимное исключение гарантируется в том случае, если каждый процесс
совершает операцию down непосредственно перед входом в свою критическую область
и операцию up сразу же после выхода из нее.
Теперь, когда в нашем распоряжении имеется хороший примитив взаимодействия
процессов, давайте вернемся назад и заново рассмотрим последовательность прерываний,
показанную в табл. 2.2. В системе, использующей семафоры, естественным
способом скрыть прерывания станет использование семафора с исходным нулевым
значением, связанным с каждым устройством ввода-вывода. Сразу же после запуска
устройства ввода-вывода управляющий процесс выполняет операцию down в отношении
связанного с этим устройством семафора, при этом немедленно переходя
в состояние заблокированности. Затем при поступлении прерывания его обработчик
выполняет операцию up в отношении связанного с устройством семафора, которая
переводит соответствующий процесс в состояние готовности к продолжению выполнения.
В этой модели шаг 5 из табл. 2.2 состоит из выполнения операции up
над семафором устройства, с тем чтобы на шаге 6 планировщик мог запустить программу,
управляющую устройством. Разумеется, если к этому моменту будут готовы
к выполнению сразу несколько процессов, планировщик может выбрать следующим
для выполнения более важный процесс. Позже в этой главе мы еще рассмотрим некоторые
алгоритмы, используемые для работы планировщика.
В примере, приведенном в листинге 2.6, семафоры используются двумя различными
способами. Различия этих способов настолько важны, что требуют дополнительного
разъяснения. Семафор mutex используется для организации взаимного исключения.
Его предназначение — гарантировать, что в каждый отдельно взятый момент времени
к буферу и соответствующим переменным имеет доступ по чтению или записи только
один процесс. Организуемое взаимное исключение призвано предотвратить хаос.
В следующем разделе мы изучим взаимное исключение и способы его достижения.
Листинг 2.6. Задача производителя и потребителя, решаемая с помощью
семафоров
#define N 100 /* Количество мест в буфере */
typedef int semaphore; /* Семафоры — это специальная разновидность
целочисленной переменной */
semaphore mutex = 1; /* управляет доступом к критической области */
semaphore empty = N; /* подсчитывает пустые места в буфере */
semaphore full = 0; /* подсчитывает занятые места в буфере */
void producer(void)
{
int item;
while (TRUE) { /* TRUE — константа, равная 1 */
item = produce_item( ); /* генерация чего-нибудь для помещения в
буфер */
down(&empty); /* уменьшение счетчика пустых мест */
down(&mutex); /* вход в критическую область */
insert_item(item); /* помещение новой записи в буфер */
up(&mutex); /* покинуть критическую область */
up(&full); /* инкремент счетчика занятых мест */
}
}
void consumer(void)
{
int item;
while (TRUE) { /* бесконечный цикл */
down(&full); /* уменьшение счетчика занятых мест */
down(&mutex); /* вход в критическую область */
item = remove_item( ); /* извлечение записи из буфера */
up(&mutex); /* выход из критической области */
up(&empty); /* увеличение счетчика пустых мест */
consume_item(item); /* работа с записью */
}
}
Другие семафоры используются для синхронизации. Семафоры full и empty нужны для
гарантии наступления или ненаступления тех или иных конкретных последовательностей
событий. В данном случае они гарантируют, что производитель приостановит
свою работу при заполненном буфере, а потребитель приостановит свою работу, если
этот буфер опустеет. Эти семафоры используются совсем не так, как при обеспечении
взаимного исключения.
2.3.6. Мьютексы
Иногда при невостребованности возможностей семафоров в качестве счетчиков используется
их упрощенная версия, называемая мьютексом. Мьютексы справляются лишь
с управлением взаимным исключением доступа к общим ресурсам или фрагментам
кода. Простота и эффективность реализации мьютексов делает их особенно полезными
для совокупности потоков, целиком реализованных в пользовательском пространстве.
Мьютекс — это совместно используемая переменная, которая может находиться в одном
из двух состояний: заблокированном или незаблокированном. Следовательно,
для их представления нужен только один бит, но на практике зачастую используется
целое число, при этом нуль означает незаблокированное, а все остальные значения —
заблокированное состояние. Для работы с мьютексами используются две процедуры.
Когда потоку (или процессу) необходим доступ к критической области, он вызывает
процедуру mutex_lock. Если мьютекс находится в незаблокированном состоянии
(означающем доступность входа в критическую область), вызов проходит удачно
и вызывающий поток может свободно войти в критическую область.
В то же время, если мьютекс уже заблокирован, вызывающий поток блокируется до тех
пор, пока поток, находящийся в критической области, не завершит свою работу и не
вызовет процедуру mutex_unlock. Если на мьютексе заблокировано несколько потоков,
то произвольно выбирается один из них, которому разрешается воспользоваться заблокированностью
других потоков.
Благодаря исключительной простоте мьютексов они легко могут быть реализованы
в пользовательском пространстве при условии доступности команды TSL или XCHG.
В листинге 2.7 показан код процедур mutex_lock и mutex_unlock, предназначенных для
использования в совокупности потоков, работающих в пользовательском пространстве.
Решение, в котором используется команда XCHG, по сути, ничем не отличается.
Листинг 2.7. Реализация mutex_lock и mutex_unlock
mutex_lock:
TSL REGISTER,MUTEX | копирование мьютекса в регистр и установка
| его в 1
CMP REGISTER,#0 | был ли мьютекс нулевым?
JZE ok | если он был нулевым, значит, не был
| заблокирован,поэтому нужно вернуть
| управление вызывающей программе
CALL thread_yield | мьютекс занят; пусть планировщик
| возобновит работу другого потока
JMP mutex lock | повторная попытка
ok: RET | возврат управления вызывающей программе;
| будет осуществлен вход в критическую
| область
mutex_unlock:
MOVE MUTEX,#0 | сохранение в мьютексе значения 0
RET | возврат управления вызывающей программе
Код процедуры mutex_lock похож на код enter_region в листинге 2.2, но с одной существенной
разницей. Когда процедуре enter_region не удается войти в критическую область,
она продолжает повторное тестирование значения переменной lock (выполняет
активное ожидание). По истечении определенного времени планировщик возобновляет
работу какого-нибудь другого процесса. Рано или поздно возобновляется работа процесса,
удерживающего блокировку, и он ее освобождает.
При работе с потоками (в пользовательском пространстве) складывается несколько
иная ситуация, связанная с отсутствием таймера, останавливающего работу слишком
долго выполняющегося процесса. Следовательно, поток, пытающийся воспользоваться
блокировкой, находясь в состоянии активного ожидания, войдет в бесконечный цикл
и никогда не завладеет блокировкой, поскольку он никогда не позволит никакому
другому потоку возобновить выполнение и снять блокировку.
Вот в этом и заключается разница между enter_region и mutex_lock. Когда последняя из
этих процедур не может завладеть блокировкой, она вызывает процедуру thread_ yield,
чтобы уступить центральный процессор другому потоку. Следовательно, активное
ожидание отсутствует. Когда поток в очередной раз возобновит свою работу, он снова
проверяет состояние блокировки.
Поскольку процедура thread_ yield представляет собой всего лишь вызов планировщика
потоков в пользовательском пространстве, она работает очень быстро. Следовательно,
ни mutex_lock, ни mutex_unlock не требуют никаких вызовов ядра. Благодаря их использованию
потоки, работающие на пользовательском уровне, могут синхронизироваться
целиком в пространстве пользователя с использованием процедур, для реализации
которых требуется совсем небольшая группа команд.
Рассмотренная ранее система мьютексов составляет основу набора вызовов. Но программному
обеспечению всегда требуется что-то большее, и примитивы синхронизации
здесь не исключение. Например, иногда совокупности потоков предлагается вызов
процедуры mutex_trylock, которая либо овладевает блокировкой, либо возвращает код
отказа, но не вызывает блокировку. Этот вызов придает потоку возможность гибко
решать, что делать дальше, если есть альтернативы простому ожиданию.
До сих пор оставалась еще одна слегка замалчиваемая нами проблема, о которой
все же стоит упомянуть. Пока речь идет о совокупности потоков, реализованных
в пользовательском пространстве, проблем с совместным доступом нескольких потоков
к одному и тому же мьютексу не возникает, поскольку потоки выполняются
в общем адресном пространстве. Но в большинстве предыдущих решений, например
в алгоритме Петерсона и семафорах, было невысказанное предположение, что несколько
процессов имеют доступ по крайней мере к какому-то объему общей памяти,
возможно, всего лишь к одному слову памяти, но все же имеют. Если у процессов
разоб щенные адресные пространства, о чем мы неизменно упоминали, то как они
будут совместно использовать переменную turn в алгоритме Петерсона, или семафоры,
или общий буфер?
На этот вопрос есть два ответа. Во-первых, некоторые общие структуры данных, например
семафоры, могут храниться в ядре и быть доступны только через системные
вызовы. Такой подход позволяет устранить проблему. Во-вторых, большинство современных
операционных систем (включая UNIX и Windows) предлагают процессам
способ, позволяющий использовать некоторую часть их адресного пространства совместно
с другими процессами. В этом случае допускается совместное использование
буферов и других структур данных. В худшем случае, когда нет доступа ни к чему
другому, можно воспользоваться общим файлом.
Если два или более процесса совместно используют все свои адресные пространства
или их большие части, различие между процессами и потоками немного размывается,
но все равно присутствует. Два процесса, использующие общее адресное пространство,
все равно имеют различные открытые файлы, аварийные таймеры и другие присущие
процессам отличительные свойства, а вот для потоков в рамках одного процесса эти
свойства являются общими. И никуда не деться от того обстоятельства, что несколько
процессов, использующих общее адресное пространство, никогда не будут столь же
эффективными, как потоки, реализованные на пользовательском уровне, поскольку
к управлению процессами неизменно привлекается ядро.
Фьютексы
С ростом параллелизма очень важное значение для производительности приобретают
эффективная синхронизация и блокировка. Спин-блокировки обладают быстротой
при недолгом ожидании, но если ожидание затянется, они будут тратить циклы центрального
процессора впустую. При высокой конкуренции более эффективным решением
будет блокировать процесс и позволить ядру разблокировать его, только когда
блокировка будет свободна. К сожалению, возникает обратная проблема: это хорошо
работает в условиях высокой конкуренции, но если конкуренция с самого начала невысока,
постоянные переключения в режим ядра обходятся слишком дорого. Хуже
того, предсказать количество конкурентных блокировок может быть весьма нелегко.
Одним из интересных решений, пытающихся объединить все самое лучшее из обоих
миров, является так называемый фьютекс, или fast user space mutex, — быстрый мьютекс
в пользовательском пространстве. Фьютекс относится к свойствам Linux, реализующим
основную блокировку (во многом похожую на мьютекс), но избегающим выпадения
в режим ядра до возникновения в этом реальной надобности. Поскольку переключение
в режим ядра и обратно обходится слишком дорого, применение такой технологии существенно
повышает производительность. Фьютекс состоит из двух частей: службы ядра
и пользовательской библиотеки. Служба ядра предоставляет «очередь ожидания», позволяющую
ожидать снятия блокировки нескольким процессам. Они не будут запущены,
пока ядро не разблокирует их явным образом. Чтобы процесс попал в очередь ожидания,
требуется (довольно дорого обходящийся) системный вызов, чего следует избегать.
Зато при отсутствии конкуренции фьютекс работает полностью в пользовательском
пространстве. Говоря конкретнее, процессы совместно используют общую переменную
блокировки, являющуюся вымышленным названием для выровненного 32-разрядного
целочисленного значения, которое служит в качестве блокировки.
Предположим, что исходное значение блокировки равно 1, и под этим подразумевается,
что блокировка свободна. Поток захватывает блокировку, проводя атомарное
«уменьшение на единицу и тестирование» (атомарные функции в Linux состоят из
встроенного ассемблерного кода, заключенного в функции языка C, и определены в заголовочных
файлах). Затем поток анализирует результат, выясняя, была ли блокировка
свободна. Если она была в незаблокированном состоянии, все обходится благополучно
и наш поток успешно захватывает блокировку. Но если блокировка удерживается
другим потоком, наш поток вынужден ждать. В таком случае библиотека фьютекса не
обращается к спину, а использует системный вызов для помещения потока в очередь
ожидания в пространстве ядра. Есть надежда на то, что затраты на переключение в режим
ядра теперь оправданны, поскольку поток все равно был бы заблокирован. Когда
поток, захвативший блокировку, выполнит свою задачу, он освободит блокировку,
проводя атомарное увеличение на единицу и тестирование и проверяя результат, чтобы
увидеть, есть ли процессы, заблокированные на очереди ожидания в пространстве
ядра. Если таковые имеются, он даст ядру понять, что оно может разблокировать один
или несколько таких процессов. Если же конкуренция отсутствует, ядро вовлекаться
в работу вообще не будет.
Мьютексы в пакете Pthreads
Пакет Pthreads предоставляет ряд функций, которые могут быть использованы для
синхронизации потоков. Основным механизмом является использование переменных
— мьютексов, предназначенных для защиты каждой критической области. Каждая
такая переменная может быть в заблокированном или незаблокированном состоянии.
Поток, которому необходимо войти в критическую область, сначала пытается заблокировать
соответствующий мьютекс. Если мьютекс не заблокирован, поток может войти
в критическую область беспрепятственно и заблокировать мьютекс в одном неделимом
действии, не позволяя войти в нее другим потокам. Если мьютекс уже заблокирован,
вызывающий поток блокируется до тех пор, пока не разблокируется мьютекс. Если
разблокировки одного и того же мьютекса ожидают несколько потоков, возможность
возобновить работу и заново заблокировать мьютекс предоставляется только одному
из них. Эти блокировки не являются обязательными. Соблюдение порядка их использования
потоками всецело возложено на программиста.
Основные вызовы, связанные с мьютексами, показаны в табл. 2.6. Как и ожидалось,
мьютексы могут создаваться и уничтожаться. Вызовы, осуществляющие эти операции,
называются, соответственно, pthread_mutex_init и pthread_mutex_destroy. Мьютексы
также могут быть заблокированы вызовом pthread_mutex_lock, который пытается завладеть
блокировкой и блокирует выполнение потока, если мьютекс уже заблокирован.
Есть также вызов, используемый для попытки заблокировать мьютекс и безуспешного
выхода с кодом ошибки, если мьютекс уже был заблокирован. Этот вызов называется
pthread_mutex_trylock. Он позволяет потоку организовать эффективное активное
ожидание, если в таковом возникнет необходимость. И наконец, вызов pthread_mutex_
unlock разблокирует мьютекс и возобновляет работу только одного потока, если имеется
один или более потоков, ожидающих разблокирования. Мьютексы могут иметь
также атрибуты, но они используются только для решения специализированных задач.
Таблица 2.6. Ряд вызовов пакета Pthreads, имеющих отношение к мьютексам
Вызов из потока Описание
pthread_mutex_init Создание мьютекса
pthread_mutex_destroy Уничтожение существующего мьютекса
pthread_mutex_lock Овладение блокировкой или блокирование потока
pthread_mutex_trylock Овладение блокировкой или выход с ошибкой
pthread_mutex_unlock Разблокирование
В дополнение к мьютексам пакет Pthreads предлагает второй механизм синхронизации
— условные переменные. Мьютексы хороши для разрешения или блокирования
доступа к критической области. Условные переменные позволяют потокам блокироваться
до выполнения конкретных условий. Эти два метода практически всегда
используются вместе. Теперь давайте более пристально взглянем на взаимодействие
потоков, мьютексов и условных переменных.
В качестве простого примера еще раз рассмотрим сценарий производителя-потребителя:
один поток что-то помещает в буфер, а другой это что-то из него извлекает.
Если производитель обнаружил отсутствие в буфере свободных мест, он вынужден
блокироваться до тех пор, пока они не появятся. Мьютексы предоставляют возможность
производить проверку атомарно, без вмешательства со стороны других потоков,
но обнаружив, что буфер заполнен, производитель нуждается в способе блокировки
с последующей активизацией. Именно этот способ и предоставляется условными
переменными.
Наиболее важные вызовы, связанные с условными переменными, показаны в табл. 2.7.
Согласно вашим возможным ожиданиям, в ней представлены вызовы, предназначенные
для создания и уничтожения условных переменных. У них могут быть атрибуты,
для управления которыми существует ряд других (не показанных в таблице) вызовов.
Первичные операции над условными переменными осуществляются с помощью вызовов
pthread_cond_wait и pthread_cond_signal. Первый из них блокирует вызывающий
поток до тех пор, пока не будет получен сигнал от другого потока (использующего
второй вызов). Разумеется, основания для блокирования и ожидания не являются
частью протокола ожиданий и отправки сигналов. Заблокированный поток зачастую
ожидает, пока сигнализирующий поток не совершит определенную работу, не освободит
какие-то ресурсы или не выполнит какие-нибудь другие действия. Только после
этого заблокированный поток продолжает свою работу. Условные переменные позволяют
осуществлять это ожидание и блокирование как неделимые операции. Вызов
pthread_cond_broadcast используется в том случае, если есть потенциальная возможность
находиться в заблокированном состоянии и ожидании одного и того же сигнала
сразу нескольким потокам.
Таблица 2.7. Ряд вызовов пакета Pthreads, имеющих отношение
к условным переменным
Вызов из потока Описание
pthread_cond_init Создание условной переменной
pthread_cond_destroy Уничтожение условной переменной
pthread_cond_wait Блокировка в ожидании сигнала
pthread_cond_signal Сигнализирование другому потоку и его активизация
pthread_cond_broadcast Сигнализирование нескольким потокам и активизация всех этих
потоков
Условные переменные и мьютексы всегда используются вместе. Схема для одного потока
состоит в блокировании мьютекса, а затем в ожидании на основе значения условной
переменной, если поток не может получить то, что ему требуется. Со временем другой
поток подаст ему сигнал, и он сможет продолжить работу. Вызов pthread_cond_wait
осуществляется неделимо и выполняет разблокирование удерживаемого мьютекса
как одну неделимую и непрерываемую операцию. По этой причине мьютекс является
одним из его аргументов.
Также стоит заметить, что условные переменные (в отличие от семафоров) не запоминаются.
Если сигнал отправлен условной переменной, изменения значения которой не
ожидает ни один из потоков, сигнал теряется. Чтобы не потерять сигнал, программисты
должны обращать особое внимание.
В качестве примера использования мьютексов и условных переменных в листинге 2.8
показана очень простая задача производителя-потребителя, в которой используется одинединственный
буфер. Когда производитель заполняет буфер, то перед тем как произвести
следующую запись, он должен ждать, пока потребитель не опустошит этот буфер. Точно
так же, когда потребитель извлечет запись, он должен ждать, пока производитель не произведет
другую запись. При всей своей предельной простоте этот пример иллюстрирует
работу основного механизма. Оператор, приостанавливающий работу потока, прежде
чем продолжить его работу, должен убедиться в выполнении условия, поскольку поток
может быть активирован в результате поступления сигнала UNIX или по другой причине.
Листинг 2.8. Использование потоков для решения задачи производителяпотребителя

#include <stdio.h>
#include <pthread.h>
#define MAX 1000000000 /* Количество производимого */
pthread_mutex_t the_mutex;
pthread_cond_t condc, condp; /* используется для сигнализации */
int buffer = 0; /* буфер, используемый между производителем и
потребителем */
void *producer(void *ptr) /* производство данных */
{ int i;
for (i= 1; i <= MAX; i++) {
pthread_mutex_lock(&the mutex); /* получение исключительного
доступа к буферу */
while (buffer != 0) pthread_cond_wait(&condp, &the_mutex);
buffer = i; /* помещение записи в буфер */
pthread_cond_signal(&condc); /* активизация потребителя */
pthread_mutex_unlock(&the mutex); /* освобождение доступа к буферу */
}
pthread exit(0);
}
void *consumer(void *ptr) /* потребление данных */
{ int i;
for (i = 1; i <= MAX; i++) {
pthread_mutex_lock(&the_mutex); /* получение исключительного
доступа к буферу */
while (buffer ==0 ) pthread_cond_wait(&condc, &the_mutex);
buffer = 0; /* извлечение записи из буфера */
pthread_cond_signal(&condp); /* активизация производителя */
pthread_mutex_unlock(&the_mutex); /* освобождение доступа к буферу */
}
pthread exit(0);
}
int main(int argc, char **argv)
{
pthread_t pro, con;
pthread_mutex_init(&the mutex, 0);
pthread_cond_init(&condc, 0);
pthread_cond_init(&condp, 0);
pthread_create(&con, 0, consumer, 0);
pthread_create(&pro, 0, producer, 0);
pthread_join(pro, 0);
pthread_join(con, 0);
pthread_cond_destroy(&condc);
pthread_cond_destroy(&condp);
pthread_mutex_destroy(&the mutex);
}
2.3.7. Мониторы
Если вы думаете, что благодаря семафорам и мьютексам организация взаимодействия
процессов кажется весьма простой задачей, то выкиньте это из головы. Присмотритесь
к порядку выполнения операций down перед вставкой записей в буфер
или удалением записей из буфера, показанному в листинге 2.6. Допустим, что две
процедуры down в коде производителя были переставлены местами, чтобы значение
mutex было уменьшено до уменьшения значения empty, а не после него. Если бы
буфер был заполнен под завязку, производитель был бы заблокирован, а значение
mutex было бы установлено в 0. Следовательно, при следующей попытке доступа
производителя к буферу он осуществлял бы down в отношении mutex, который теперь
имеет значение 0, и также блокировал бы его. Оба процесса находились бы в заблокированном
состоянии бесконечно долго, не позволяя что-либо сделать. Такая неприятная
ситуация называется взаимной блокировкой, к ее детальному рассмотрению
мы вернемся в главе 6.
О существовании этой проблемы было упомянуто, чтобы показать, насколько аккуратно
нужно относиться к использованию семафоров. Одна малозаметная ошибка —
и все будет остановлено. Это напоминает программирование на ассемблере, но здесь
ситуация еще хуже, поскольку ошибки касаются состязательных ситуаций, взаимных
блокировок и иных форм непредсказуемого и невоспроизводимого поведения.
Чтобы облегчить написание безошибочных программ, Бринч Хансен (Brinch Hansen)
в 1973 году и Хоар (Hoare) в 1974 году предложили высокоуровневый синхронизационный
примитив, названный монитором. Их предложения, как мы увидим дальше,
мало отличались друг от друга. Монитор представляет собой коллекцию переменных
и структур данных, сгруппированных вместе в специальную разновидность модуля
или пакета процедур. Процессы могут вызывать любые необходимые им процедуры,
имеющиеся в мониторе, но не могут получить непосредственный доступ к внутренним
структурам данных монитора из процедур, объявленных за пределами монитора.
В листинге 2.9 показан монитор, написанный на воображаемом языке Pidgin Pascal.
Язык C здесь не подойдет, поскольку мониторы являются понятиями языка, а C такими
понятиями не обладает.
Листинг 2.9. Монитор
monitor example
integer i;
condition c;
procedure producer();
.
.
.
end;
procedure consumer();
. . .
end;
end monitor;
У мониторов имеется весьма важное свойство, позволяющее успешно справляться со
взаимными исключениями: в любой момент времени в мониторе может быть активен
только один процесс. Мониторы являются конструкцией языка программирования,
поэтому компилятор осведомлен об их особенностях и способен обрабатывать вызовы
процедур монитора не так, как вызовы всех остальных процедур. Обычно при вызове
процессом процедуры монитора первые несколько команд процедуры осуществляют
проверку на текущее присутствие активности других процессов внутри монитора. Если
какой-нибудь другой процесс будет активен, вызывающий процесс будет приостановлен
до тех пор, пока другой процесс не освободит монитор. Если монитор никаким другим
процессом не используется, вызывающий процесс может в него войти.
Реализация взаимного исключения при входе в монитор возлагается на компилятор,
но чаще всего для этого используется мьютекс или двоичный семафор. Поскольку
обеспечением взаимного исключения занимается компилятор, а не программист,
вероятность того, что будут допущены какие-то неправильные действия, становится
гораздо меньше. В любом случае тот, кто создает монитор, не должен знать, как именно
компилятор обеспечивает взаимное исключение. Достаточно лишь знать, что после
превращения всех критических областей в процедуры монитора никакие два процесса
не будут выполнять код своих критических областей в одно и то же время.
Хотя мониторы и обеспечивают простой способ достижения взаимного исключения,
как мы видели ранее, этого недостаточно. Нам также нужен способ, позволяющий
заблокировать процессы, которые не в состоянии продолжить свою работу. В случае
с решением задачи производителя-потребителя проще всего поместить все тесты на
заполненность и опустошенность буфера в процедуры монитора, но как тогда производитель
должен заблокироваться, обнаружив, что буфер заполнен до отказа?
Для решения этой проблемы нужно ввести условные переменные, а также две проводимые
над ними операции — wait и signal. Когда процедура монитора обнаруживает
невозможность продолжения своей работы (например, производитель обнаружил, что
буфер заполнен), она осуществляет операцию wait в отношении какой-нибудь условной
переменной, скажем, full. Это действие призывает процесс к блокированию. Оно
также позволяет войти в монитор другому процессу, которому ранее этот вход был запрещен.
Мы уже встречались с условными переменными и с этими операциями, когда
рассматривали пакет Pthreads.
Этот другой процесс, например потребитель, может активизировать работу своего
приостановленного партнера, осуществив операцию signal в отношении условной переменной,
изменения значения которой ожидает его партнер. Чтобы в мониторе в одно
и то же время не находились сразу два активных процесса, нам необходимо правило,
предписывающее дальнейшее развитие событий после осуществления операции signal.
Хоар предложил позволить только что активизированному процессу приостановить
работу другого процесса. Бринч Хансен предложил разрешить проблему, потребовав
обязательного и немедленного выхода из монитора того процесса, который осуществил
операцию signal. Иными словами, операция signal должна фигурировать только в качестве
завершающей операции в процедуре монитора. Мы воспользуемся предложением
Бринча Хансена, поскольку оно проще по замыслу и реализации. Если операция signal
осуществляется в отношении условной переменной, изменения которой ожидают
сразу несколько процессов, активизирован будет лишь один из них, определяемый
системным планировщиком.
В резерве есть еще одно, третье решение, которое не было предложено ни Хоаром, ни
Бринчем Хансеном. Суть его в том, чтобы позволить сигнализирующему процессу продолжить
свою работу и позволить ожидающему процессу возобновить работу только
после того, как сигнализирующий процесс покинет монитор.
Условные переменные не являются счетчиками. Они не аккумулируют сигналы для
последующего использования, как это делают семафоры. Поэтому, если сигнал обрабатывает
условную переменную, изменения которой никто не ожидает, этот сигнал
теряется навсегда. Иными словами, операция wait должна предшествовать операции
signal. Это правило значительно упрощает реализацию. На практике проблем не возникает,
поскольку куда проще, если понадобится, отследить состояние каждого процесса
с переменными. Процесс, который мог бы при других условиях осуществить операцию
signal, может увидеть, взглянув на переменные, что в ней нет необходимости.
Схема решения задачи производителя-потребителя с использованием мониторов
показана на воображаемом языке Pidgin Pascal в листинге 2.10. Здесь преимущества
использования Pidgin Pascal проявляются в его простоте и точном следовании модели
Хоара — Бринча Хансена.
Листинг 2.10. Набросок решения задачи производителя-потребителя с помощью
мониторов. В любой момент времени может быть активна только одна процедура
монитора. В буфере содержится N мест
monitor ProducerConsumer
condition full, empty;
integer count;
procedure insert(item: integer);
begin
if count = N then wait(full);
insert item(item);
count := count + 1;
if count =1 then signal(empty)
end;
function remove : integer;
begin
if count =0 then wait(empty);
remove = remove item;
count := count ? 1;
if count = N? 1 then signal(full)
end;
count := 0;
end monitor;
procedure producer;
begin
while true do
begin
item = produce item;
ProducerConsumer.insert(item)
End
end;
procedure consumer;
begin
while true do
begin
item = ProducerConsumer.remove;
consume item(item)
end
end;
Может создаться впечатление, что операции wait и signal похожи на операции sleep
и wakeup, которые, как мы видели ранее, приводят к фатальному состоянию состязательности.
Конечно же, они очень похожи, но с одной весьма существенной разницей: sleep
и wakeup терпели неудачу, когда один процесс пытался заблокироваться, а другой — его
активизировать. При использовании мониторов такая ситуация исключена. Автоматическая
организация взаимного исключения в отношении процедур монитора гарантирует
следующее: если, скажем, производитель, выполняя процедуру внутри монитора,
обнаружит, что буфер полон, он будет иметь возможность завершить операцию wait, не
испытывая волнений о том, что планировщик может переключиться на выполнение процесса
потребителя еще до того, как операция wait будет завершена. Потребителю вообще
не будет позволено войти в монитор, пока не завершится операция wait и производитель
не будет помечен как неспособный к дальнейшему продолжению работы.
Хотя Pidgin Pascal является воображаемым языком, некоторые реально существующие
языки программирования также поддерживают мониторы, быть может, и не
всегда в форме, разработанной Хоаром и Бринчем Хансеном. Одним из таких языков
является Java — объектно-ориентированный язык, поддерживающий потоки на уровне
пользователя, а также разрешающий группировать методы (процедуры) в классы.
При добавлении к объявлению метода ключевого слова synchronized Java гарантирует
следующее: как только один поток приступает к выполнению этого метода, ни одному
другому потоку не будет позволено приступить к выполнению любого другого метода
этого объекта с ключевым словом synchronized. Без использования ключевого слова
synchronized гарантии чередования отсутствуют.
В листинге 2.11 приведено решение задачи производителя-потребителя с использованием
мониторов, реализованное на языке Java. Решение включает в себя четыре класса.
Самый первый класс, ProducerConsumer, создает и запускает два потока — p и c. Второй
и третий классы — producer и consumer — содержат код для производителя и потребителя
соответственно. И наконец, класс our_monitor представляет собой монитор. Он состоит
из двух синхронизированных потоков, которые используются для фактического
помещения записей в общий буфер и извлечения их оттуда. В отличие от предыдущего
примера, здесь мы наконец-то приводим полный код методов insert и remove.
Потоки производителя и потребителя функционально идентичны своим двойникам
во всех предыдущих примерах. У производителя имеется бесконечный цикл, генерирующий
данные и помещающий их в общий буфер. У потребителя есть аналогичный
бесконечный цикл, извлекающий данные из общего буфера и производящий над ними
некие полезные действия.
Интересующей нас частью этой программы является класс our_monitor, который содержит
буфер, управляющие переменные и два синхронизированных метода. Когда
производитель активен внутри метода insert, он знает наверняка, что потребитель
не может быть активен внутри метода remove, что позволяет обновлять переменные
и буфер без опасений создать условия для состояния состязательности. В переменной
count отслеживается количество записей, находящихся в буфере. Она может принимать
любые значения от 0 и до N ? 1 включительно. Переменная lo является индексом места
в буфере, откуда будет извлечена следующая запись. Аналогично этому переменная hi
является индексом места в буфере, куда будет помещена следующая запись. Допустимо
равенство lo = hi, которое означает, что в буфере находится либо 0, либо N записей.
Значение count указывает на суть создавшейся ситуации.
Синхронизированные методы в Java существенно отличаются от классических мониторов:
в Java отсутствуют встроенные условные переменные. Вместо них этот
язык предлагает две процедуры, wait и notify, которые являются эквивалентами sleep
и wakeup, за исключением того, что при использовании внутри синхронизированных
методов они не могут попасть в состязательную ситуацию. Теоретически метод wait
может быть прерван, для чего, собственно, и предназначен весь окружающий его код.
Java требует, чтобы обработка исключений проводилась в явном виде. В нашем случае
нужно просто представить, что использование метода go_to_sleep — это всего лишь
способ приостановки работы.
Благодаря автоматизации взаимного исключения входа в критические области мониторы
(по сравнению с семафорами) позволяют снизить уровень ошибок при параллельном
программировании. Тем не менее у них тоже имеется ряд недостатков. Недаром оба
наших примера мониторов приведены на языке Pidgin Pascal, а не на C, как все другие
примеры в этой книге. Как уже упоминалось, мониторы являются понятием языка
программирования. Компилятор должен их распознать и каким-то образом устроить
взаимное исключение. C, Pascal и большинство других языков не имеют мониторов,
поэтому не имеет смысла ожидать от их компиляторов реализации каких-нибудь правил
взаимного исключения. И действительно, как компилятор сможет узнать, какие
процедуры были в мониторах, а какие нет?
В этих языках нет и семафоров, но их легко добавить: нужно всего лишь дополнить
библиотеку двумя короткими подпрограммами на ассемблере, чтобы получить системные
вызовы up и down. Компиляторам даже не нужно знать, что они существуют.
Разумеется, операционная система должна знать о семафорах, но во всяком случае,
если у вас операционная система, использующая семафоры, вы можете создавать
пользовательские программы для нее на C или С++ (или даже на ассемблере, если
вам настолько нечем больше заняться). Для использования мониторов нужен язык,
в который они встроены.
Другая особенность, присущая мониторам и семафорам, состоит в том, что они разработаны
для решения проблем взаимного исключения при работе с одним или несколькими
центральными процессорами, имеющими доступ к общей памяти. Помещая
семафоры в общую память и защищая их командами TSL или XCHG, мы можем избежать
состязательной ситуации. При переходе к распределенной системе, состоящей
из связанных по локальной сети нескольких центральных процессоров, у каждого из
которых имеется собственная память, эти примитивы становятся непригодными. Следует
сделать вывод, что семафоры имеют слишком низкоуровневую природу, а мониторы
бесполезны, за исключением небольшого количества языков программирования.
К тому же ни один из примитивов не позволяет осуществлять информационный обмен
между машинами. Здесь нужно что-то иное.
2.3.8. Передача сообщений
Этим другим средством является передача сообщений. Этот метод взаимодействия
процессов использует два примитива, send и receive, которые, подобно семафорам и в
отличие от мониторов, являются системными вызовами, а не конструкциями языка.
Как таковые они легко могут быть помещены в библиотечные процедуры, например:
send(destination, &message);
или
receive(source, &message);
Первый вызов отправляет сообщение заданному получателю, а второй получает сообщение
из заданного источника (или из любого источника, если получателю все
равно). Если доступные сообщения отсутствуют, получатель может заблокироваться
до их поступления. Или же он может немедленно вернуть управление с кодом ошибки.
Проблемы разработки систем передачи сообщений
Системы передачи сообщений имеют массу сложных проблем разработки, которых не
возникает при использовании семафоров или мониторов, особенно если взаимодействующие
процессы проходят на различных машинах, связанных между собой по сети.
К примеру, сообщение может быть утрачено при передаче по сети. Чтобы застраховаться
от утраты сообщений, отправитель и получатель должны договориться о том, что как
только сообщение будет получено, получатель должен отправить в ответ специальное
подтверждение. Если по истечении определенного интервала времени отправитель не
получит подтверждение, он отправляет сообщение повторно.
Листинг 2.11. Решение задачи производителя-потребителя на языке Java
public class ProducerConsumer {
static final int N = 100; // константа, задающая размер буфера
static producer p = new producer( ); // создание экземпляра потока
// производителя
static consumer c = new consumer( ); // создание экземпляра потока
// потребителя
static our monitor mon = new our monitor( ); // создание экземпляра
// монитора
public static void main(String args[ ]) {
p.start( ); // запуск потока производителя
c.start( ); // запуск потока потребителя
}
static class producer extends Thread {
public void run( ) { // код потока содержится в методе run
int item;
while (true) { // цикл производителя
item = produce item( );
mon.insert(item);
}
}
private int produce_item( ) { ... } // производство записей
}
static class consumer extends Thread {
public void run( ) { // код потока содержится в методе run
int item;
while (true) { // цикл потребителя
item = mon.remove( );
consume_item(item);
}
}
private void consume_item(int item) { ... } // потребление записи
}
static class our_monitor { // монитор
private int buffer[ ] = new int[N];
private int count = 0, lo = 0, hi = 0; // счетчики и индексы
public synchronized void insert(int val) {
if (count == N) go_to_sleep( ); // если буфер полон, приостановка
buffer [hi] = val; // помещение записи в буфер
hi = (hi + 1) %N; // место для следующей записи
count = count + 1; // теперь в буфере появилась еще одна запись
if (count == 1) notify( ); // если потребитель был приостановлен,
// его нужно активизировать
}
public synchronized int remove( ) {
int val;
if (count == 0) go_to_sleep( ); // если буфер пуст, приостановка
val = buffer [lo]; // извлечение записи из буфера
lo = (lo + 1) %N; // место извлечения следующей записи from
count = count ? 1; // в буфере стало на одну запись меньше
buffer
if (count == N ? 1) notify( ); // если производитель был приостановлен,
// его нужно активизировать
return val;
}
private void go_to_sleep() { try{wait();} catch(InterruptedException exc) {};}
}
}
Теперь рассмотрим, что получится, если сообщение было успешно получено, а подтверждение,
возвращенное отправителю, утрачено. Отправитель заново передаст сообщение,
и оно придет к получателю повторно. Важно, чтобы получатель мог отличить
новое сообщение от повторно переданного старого. Обычно эта проблема решается за
счет присвоения всем оригинальным сообщениям последовательно идущих номеров.
Если получателю приходит сообщение, несущее тот же самый серийный номер, что
и предыдущее, он знает, что это дубликат, который можно проигнорировать. Организация
успешной передачи информации в условиях ненадежной передачи сообщений
является основной частью учебного курса по компьютерным сетям.
Системе передачи сообщений приходится также решать вопрос о том, как именовать
процессы, чтобы однозначно указывать процесс в вызовах отправки — send или
получения — receive. Для системы передачи сообщений важна и проблема аутентификации:
как клиент может отличить связь с реальным файловым сервером от
связи с самозванцем?
На другой стороне этого спектра, где отправитель и получатель находятся на одной
и той же машине, конструирование также не обходится без серьезных проблем. Одна
из них касается производительности. Копирование сообщений из одного процесса
в другой всегда проводится медленнее, чем операции с семафорами или вход в монитор.
На повышение эффективности передачи сообщений было затрачено немало усилий.
Решение задачи производителя-потребителя
с помощью передачи сообщений
Теперь давайте рассмотрим, как с помощью передачи сообщений и без использования
общей памяти может решаться задача производителя-потребителя. Решение этой
задачи показано в листинге 2.12. Будем исходить из предположения, что все сообщения
имеют один и тот же размер и что переданные, но еще не полученные сообщения
буферизуются автоматически средствами операционной системы. В этом решении
всего используется N сообщений, что аналогично N местам в буфере, организованном
в общей памяти. Потребитель начинает с того, что посылает N пустых сообщений
производителю. Как только у производителя появится запись для передачи потребителю,
он берет пустое сообщение и отправляет его назад в заполненном виде. При
этом общее количество сообщений в системе остается постоянным, поэтому они могут
быть сохранены в заданном, заранее известном объеме памяти.
Листинг 2.12. Решение задачи производителя-потребителя с помощью
N сообщений
#define N 100 /* количество мест в буфере */
void producer(void)
{
int item;
message m; /* буфер сообщений */
while (TRUE) {
item = produce_item( ); /* генерация информации для помещения в буфер
*/
receive(consumer, &m); /* ожидание поступления пустого сообщения */
build_message(&m, item); /* создание сообщения на отправку */
send(consumer, &m); /* отправка записи потребителю */
}
}
void consumer(void)
{
int item, i;
message m;
for (i = 0; i < N; i++) send(producer, &m); /* отправка N пустых
сообщений */
while (TRUE) {
receive(producer, &m); /* получение сообщения с записью */
item = extract_item(&m); /* извлечение записи из сообщения */
send(producer, &m); /* возвращение пустого ответа */
consume_item(item); /* обработка записи */
}
}
Если производитель работает быстрее потребителя, все сообщения в конце концов становятся
заполненными, ожидая потребителя; производитель должен будет заблокироваться,
ожидая возвращения пустого сообщения. Если потребитель работает быстрее, то
получается обратный эффект: все сообщения опустошатся, ожидая, пока производитель
их заполнит, и потребитель заблокируется в ожидании заполненного сообщения.
Доступно множество вариантов передачи сообщений. Для начала рассмотрим способ
адресации сообщений. Можно присвоить каждому процессу уникальный адрес и адресовать
сообщения процессам. Можно также изобрести новую структуру данных, называемую
почтовым ящиком. Этот ящик представляет собой место для буферизации
конкретного количества сообщений, которое обычно указывается при его создании.
При использовании почтовых ящиков в качестве параметров адреса в вызовах send
и receive указываются почтовые ящики, а не процессы. Когда процесс пытается послать
сообщение заполненному почтовому ящику, он приостанавливается до тех пор, пока
из этого почтового ящика не будет извлечено сообщение, освобождая пространство
для нового сообщения.
При решении задачи производителя-потребителя оба они, и производитель и потребитель,
создадут почтовые ящики, достаточные для размещения N сообщений. Производитель
станет отправлять сообщения, содержащие реальные данные, в потребительский
почтовый ящик. При использовании почтовых ящиков механизм буферизации вполне
понятен: в почтовом ящике получателя содержатся сообщения, посланные процессуполучателю,
но еще не принятые им.
Другой крайностью при использовании почтовых ящиков является полный отказ от
буферизации. При этом подходе, если операция send проводится до операции receive,
процесс-отправитель блокируется до завершения операции receive, в это время сообщение
может быть непосредственно скопировано с отправителя получателю без использования
промежуточной буферизации. А если первой проводится операция receive,
получатель блокируется до осуществления операции send. Такую стратегию обычно
называют рандеву. Она проще в реализации, чем схема с буферизацией сообщений, но
является менее гибкой, поскольку отправитель и получатель должны работать в строго
предопределенном режиме.
Передача сообщений широко используется в системах параллельного программирования.
В качестве примера можно привести общеизвестную систему передачи сообщений
MPI (Message-Passing Interface). Она нашла широкое применение в научных
вычислениях. Более подробные сведения об этой системе изложены в трудах Gropp et
al., 1994; Snir et al., 1996.
2.3.9. Барьеры
Последний из рассматриваемых нами механизмов синхронизации предназначен для
групп процессов, в отличие от задачи производителя-потребителя, в которой задействованы
всего два процесса. Некоторые приложения разбиты на фазы и следуют правилу,
согласно которому ни один из процессов не может перейти к следующей фазе, пока
все процессы не будут готовы перейти к следующей фазе. Добиться выполнения этого
правила можно с помощью барьеров, поставленных в конце каждой фазы. Когда процесс
достигает барьера, он блокируется до тех пор, пока этого барьера не достигнут все
остальные процессы. Это позволяет синхронизировать группы процессов. Действие
барьера представлено на рис. 2.18.
На рис. 2.18, а показаны четыре процесса, приближающихся к барьеру. Это означает,
что они еще заняты вычислениями и не достигли завершения текущей фазы. Через некоторое
время первый процесс заканчивает все вычисления, необходимые для завершения
первой фазы работы. Он выполняет примитив barrier, вызывая обычно библиотечную
процедуру. Затем этот процесс приостанавливается. Чуть позже первую фазу своей
работы завершают второй и третий процессы, которые также выполняют примитив
barrier. Эта ситуация показана на рис. 2.18, б. И наконец, как показано на рис. 2.18, в,
когда последний процесс, C, достигает барьера, все процессы освобождаются.
Рис. 2.18. Использование барьера: а — процесс достигает барьера; б — все процессы, кроме
одного, заблокированы на барьере; в — последний процесс достигает барьера, и все процессы
преодолевают этот барьер
В качестве примера задачи, для решения которой нужны барьеры, рассмотрим обычную
в физике или в машиностроении задачу затухания. Обычно это матрица, содержащая
некоторые исходные значения. Эти значения могут представлять собой температуру
в разных точках листа металла. Замысел может состоять в определении скорости распространения
разогрева от пламени, воздействующего на один из его углов.
Начиная с текущих значений, к матрице для получения ее следующей версии применяется
преобразование, соответствующее, к примеру, законам термодинамики, чтобы
посмотреть все температурные показания через время ?T. Затем процесс повторяется
снова и снова, представляя температурные значения в виде функции, зависящей от
времени нагревания листа. Со временем алгоритм производит серию матриц, каждая
из которых соответствует заданной отметке времени.
Теперь представим, что матрица имеет слишком большие размеры (скажем, миллион
на миллион) и для ускорения ее вычисления требуется использование параллельных
процессов (возможно, на многопроцессорной машине). Разные процессы работают над
разными частями матрицы, вычисляя новые элементы матрицы на основе прежних
значений в соответствии с законами физики. Но ни один процесс не может приступить
к итерации n + 1, пока не завершится итерация n, то есть пока все процессы не завершат
текущую работу. Способ достижения этой цели — запрограммировать каждый процесс
на выполнение операции barrier после того, как он завершит свою часть текущей
итерации. Когда все процессы справятся со своей работой, новая матрица (предоставляющая
входные данные для следующей итерации) будет завершена и все процессы
будут освобождены для начала следующей итерации.
2.3.10. Работа без блокировок:
чтение — копирование — обновление
Самые быстрые блокировки — это отсутствие всяких блокировок. Вопрос в том, можно
ли разрешить одновременный доступ для чтения и записи к общим структурам данных
без блокировки. Если говорить в общем смысле, то ответ, конечно же, будет отрицательный.
Представим себе, что процесс А сортирует числовой массив, в то же время
процесс Б вычисляет среднее значение. Поскольку A перемещает значения по массиву,
процессу Б некоторые значения могут попасться несколько раз, а некоторые не встретиться
вообще. Результат может быть каким угодно, но, скорее всего, неправильным.
И тем не менее в некоторых случаях можно позволить процессу, ведущему запись, обновить
структуру данных, даже если ею пользуются другие процессы. Здесь важно обеспечить,
чтобы каждый считывающий процесс читал либо старую, либо новую версию
данных, но не некую непонятную комбинацию из старой и новой версий. В качестве
иллюстрации рассмотрим дерево, показанное на рис. 2.19. Читатели обходят дерево от
корня до листьев. В верхней половине рисунка добавлен новый узел X. Перед тем как
сделать этот узел видимым в дереве, мы доводим его до полной готовности: инициализируем
все значения в узле X, включая его дочерние указатели. Затем с помощью
одной атомарной записи превращаем X в дочерний элемент узла A. Несогласованную
версию не сможет считать ни один читатель. В нижней части рисунка последовательно
удаляются узлы B и D. Сначала мы перенацеливаем левый дочерний указатель узла A
на узел C. Все читатели, попавшие в A, продолжат считывание с узла C и никогда не
увидят узел B или D. Иными словами, они увидят только новую версию. В то же время
все читатели, находящиеся в этот момент в узле B или D, продолжат чтение, следуя
указателям исходной структуры данных, и увидят старую версию. Все будет хорошо,
и блокировка вообще не понадобится. Удаление B и D работает без блокировки структуры
данных в основном потому, что RCU (Read — Copy — Update, чтение — копирование
— обновление) отделяет фазу удаления от фазы восстановления обновления.
Но есть и проблема. Пока нет уверенности в полном отсутствии читателей в B или D,
мы не можем фактически от них избавиться. Но сколько же должно продлиться ожидание?
Одну минуту? Десять минут? Мы вынуждены ждать до тех пор, пока эти узлы
не оставит последний читатель. RCU обязательно определяет максимальное время,
в течение которого читатель может удерживать ссылку на структуру данных. По истечении
этого срока память может быть безопасно освобождена. Точнее говоря, читатели
получают доступ к структуре данных в области, которая известна как критический
раздел чтения (read-side critical section), где может содержаться любой код, поскольку
он не заблокирован или не пребывает в режиме ожидания. В этом случае известно
максимальное время вынужденного ожидания. А именно нами определяется отсрочка
(grace period) в виде любого периода времени, в течение которого известно, что каждый
(a) enoiaiia aa?aai (a) eieoeaeecaoey ocea X
e iiaee??aiea E e X.
Ia e?auo ?eoaoaeae,
iaoiayueony a A e E,
yoi ia iiaeeyao
X
A
B
E D C
D D C C
D D C C
A
B
E
(a) iinea iieiie eieoeaeecaoee X
iiaee??aiea X e A. ?eoaoaee,
iaoiayueany a yoi a?aiy a E,
i?i?eoa?o noa?o? aa?ne? aa?aaa,
a ?eoaoaee, iaoiayueany a A,
iieo?ao iiao? aa?ne?
X
A
B
E
(a) ioniaaeiaiea B io A.
Caiaouoa, ?oi a B ana aua
iiaoo auou ?eoaoaee. Ana
?eoaoaee a B aoaoo aeaaou
noa?o? aa?ne?, a ana
?eoaoaee, iaoiayueany
a yoi a?aiy a A, oaeayo
iiao? aa?ne?
X
A
B
E
(a) i?eaaiea iieiie
oaa?aiiinoe a oii, ?oi
ana ?eoaoaee iieeioee B e C.
Aieuoa ainooia e yoei oceai
ia aoaao
X
A
B
E C E
(a) oaia?u B e D ii?ii
niieieii oaaeeou
X
A
Aiaaaeaiea ocea:
Oaaeaiea oceia:
Рис. 2.19. RCU: вставка узла в дерево с последующим удалением ветви,
и все это без блокировок
поток будет вне критического раздела для чтения по крайней мере однократно. Если
период ожидания перед восстановлением будет как минимум равен отсрочке, все будет
хорошо. Поскольку код в критическом разделе для чтения не разрешено блокировать
или переводить в режим ожидания, простым критерием будет ожидание до тех пор,
пока все потоки не выполнят контекстное переключение.
2.4. Планирование
Когда компьютер работает в многозадачном режиме, на нем зачастую запускается сразу
несколько процессов или потоков, претендующих на использование центрального
процессора. Такая ситуация складывается в том случае, если в состоянии готовности
одновременно находятся два или более процесса или потока. Если доступен только
один центральный процессор, необходимо выбрать, какой из этих процессов будет
выполняться следующим. Та часть операционной системы, на которую возложен этот
выбор, называется планировщиком, а алгоритм, который ею используется, называется
алгоритмом планирования. Именно эта тема и станет предметом рассмотрения в следующих
разделах.
Многие однотипные вопросы, применяемые к планированию процессов, могут применяться
и к планированию потоков, хотя существуют и некоторые различия. Когда ядро
управляет потоками, планирование обычно касается каждого из потоков, практически
не различая, какому именно процессу они принадлежат (или все же делая небольшие
различия). Сначала мы сконцентрируемся на вопросах планирования, применимых как
к процессам, так и к потокам. После этого рассмотрим исключительно планирование
потоков и ряд возникающих при этом уникальных вопросов. А многоядерные процессоры
будут рассмотрены в главе 8.
2.4.1. Введение в планирование
Если вернуться к прежним временам пакетных систем, где ввод данных осуществлялся
в форме образов перфокарт, перенесенных на магнитную ленту, то алгоритм планирования
был довольно прост: требовалось всего лишь запустить следующее задание.
С появлением многозадачных систем алгоритм планирования усложнился, поскольку
в этом случае обычно фигурировали сразу несколько пользователей, ожидавших
обслуживания. На некоторых универсальных машинах до сих пор пакетные задачи
сочетаются с задачами в режиме разделения времени, и планировщику нужно решать,
какой должна быть очередная работа: выполнение пакетного задания или обеспечение
интерактивного общения с пользователем, сидящим за терминалом. (Между прочим,
в пакетном задании мог содержаться запрос на последовательный запуск нескольких
программ, но в данном разделе мы будем придерживаться предположения, что запрос
касается запуска только одной программы.) Поскольку на таких машинах процессорное
время является дефицитным ресурсом, хороший планировщик может существенно
повлиять на ощущаемую производительность машины и удовлетворенность пользователя.
Поэтому на изобретение искусного и эффективного алгоритма планирования
было потрачено немало усилий.
С появлением персональных компьютеров ситуация изменилась в двух направлениях.
Во-первых, основная часть времени отводилась лишь одному активному процессу. Вряд
ли случалось такое, что пользователь, вводивший документ в текстовый процессор,
одновременно с этим компилировал программу в фоновом режиме. Когда пользователь
набирал команду для текстового процессора, планировщику не приходилось
напрягаться, определяя, какой процесс нужно запустить, — текстовый процессор был
единственным кандидатом.
Во-вторых, с годами компьютеры стали работать настолько быстрее, что центральный
процессор практически перестал быть дефицитным ресурсом. Большинство программ
для персонального компьютера ограничены скоростью предоставления пользователем
входящей информации (путем набора текста или щелчками мыши), а не скоростью,
с которой центральный процессор способен ее обработать. Даже задачи компиляции
программ, в прошлом главный потребитель процессорного времени, теперь в большинстве
случаев занимают всего несколько секунд. Даже при одновременной работе двух
программ, например текстового процессора и электронной таблицы, вряд ли имеет
значение, которую из них нужно пропустить вперед, поскольку пользователь, скорее
всего, ждет результатов от обеих. Поэтому на простых персональных компьютерах
планирование не играет особой роли. Конечно, существуют приложения, которые поглощают
практически все ресурсы центрального процессора: например, визуализация
одночасового видео высокого разрешения при корректировке цветовой гаммы каждого
из 107 892 кадров (в NTSC) или 90 000 кад ров (в PAL) требует вычислительной
мощности промышленной компьютерной системы, но подобные приложения скорее
являются исключением из правил.
Когда же дело касается сетевых служб, ситуация существенно изменяется. Здесь в конкурентную
борьбу за процессорное время вступают уже несколько процессов, поэтому
планирование снова приобретает значение. Например, когда центральному процессору
нужно выбирать между запущенным процессом, собирающим ежедневную статистику,
и одним из процессов, обслуживающих запросы пользователя, если приоритет будет
сразу же отдан последнему из процессов, пользователь будет чувствовать себя намного
лучше. Многие мобильные устройства, такие как смартфоны (за исключением разве что
самых мощных моделей), и узлы сенсорных сетей «обилием ресурсов» также похвастаться
не могут. У них все еще может быть маломощный центральный процессор и небольшой
объем памяти. Более того, поскольку одним из наиболее важных ограничений на
этих устройствах является ресурс аккумуляторов, некоторые планировщики стараются
оптимизировать потребление электроэнергии.
Планировщик наряду с выбором «правильного» процесса должен заботиться также об
эффективной загрузке центрального процессора, поскольку переключение процессов
является весьма дорогостоящим занятием. Сначала должно произойти переключение
из пользовательского режима в режим ядра, затем сохранено состояние текущего процесса,
включая сохранение его регистров в таблице процессов для их последующей
повторной загрузки. На некоторых системах должна быть сохранена также карта
памяти (например, признаки обращения к страницам памяти). После этого запускается
алгоритм планирования для выбора следующего процесса. Затем в соответствии
с картой памяти нового процесса должен быть перезагружен блок управления памятью.
И наконец, новый процесс должен быть запущен. Вдобавок ко всему перечисленному
переключение процессов обесценивает весь кэш памяти, заставляя его дважды динамически
перезагружаться из оперативной памяти (после входа в ядро и после выхода
из него). В итоге слишком частое переключение может поглотить существенную долю
процессорного времени, что наводит на мысль: этого нужно избегать.
Поведение процесса
На рис. 2.19 показано, что практически у всех процессов пики вычислительной активности
чередуются с запросами (дискового или сетевого) ввода-вывода. Зачастую
центральный процессор некоторое время работает без остановок, затем происходит
системный вызов для чтения данных из файла или для их записи в файл. Когда системный
вызов завершается, центральный процессор возобновляет вычисления до тех
пор, пока ему не понадобятся дополнительные данные или не потребуется записать
дополнительные данные на диск и т. д. Следует заметить, что некоторые операции
ввода-вывода считаются вычислениями. Например, когда центральный процессор копирует
биты в видеопамять, чтобы обновить изображение на экране, то он занимается
вычислением, а не вводом-выводом, поскольку при этом задействован он сам. В этом
смысле ввод-вывод происходит в том случае, когда процесс входит в заблокированное
состояние, ожидая, пока внешнее устройство завершит свою работу.
По поводу изображения на рис. 2.19 следует заметить, что некоторые процессы, как тот,
что показан на рис. 2.19, а, проводят основную часть своего времени за вычислениями,
а другие, как тот, что показан на рис. 2.19, б, основную часть своего времени ожидают
завершения операций ввода-вывода. Первые процессы называются процессами,
Рис. 2.20. Пики активного использования центрального процессора чередуются с периодами
ожидания завершения операций ввода-вывода: а — процесс, ограниченный скоростью
вычислений; б — процесс, ограниченный скоростью работы устройств ввода-вывода
ограниченными скоростью вычислений, а вторые — процессами, ограниченными
скоростью работы устройств ввода-вывода. Процессы, ограниченные скоростью
вычислений, обычно имеют продолжительные пики вычислительной активности и,
соответственно, нечастые периоды ожидания ввода-вывода, а процессы, ограниченные
скоростью работы устройств ввода-вывода, имеют короткие периоды активности
центрального процессора и, соответственно, довольно частые периоды ожидания ввода-вывода.
Следует заметить, что ключевым фактором здесь является период пиковой
активности центрального процессора, а не продолжительность активности устройств
ввода-вывода. Процессы, ограниченные скоростью работы устройств ввода-вывода,
считаются таковыми только потому, что не занимаются продолжительными вычислениями
в промежутках между запросами ввода-вывода, а не потому, что они главным
образом заняты продолжительными запросами ввода-вывода. Запрос на чтение блока
данных с диска занимает одно и то же время независимо от того, много или мало времени
уходит на их обработку после получения.
Стоит заметить, что чем быстрее становятся центральные процессоры, тем больше
процессы ограничиваются скоростью работы устройств ввода-вывода. Это связано
с более быстрым совершенствованием центральных процессоров по сравнению с совершенствованием
дисковых устройств. Поэтому планирование процессов, ограниченных
скоростью работы устройств ввода-вывода, в будущем, скорее всего, приобретет более
важную роль. Основной замысел будет заключаться в немедленном предоставлении
шанса готовому к возобновлению работы процессу, ограниченному скоростью работы
устройств ввода-вывода, с тем, чтобы он мог выдать запрос к дисковому устройству
и поддержать его загруженность. На рис. 2.4 мы видели, что далеко не многим процессам,
ограниченным скоростью работы устройств ввода-вывода, удается полностью
занять время центрального процессора.
Когда планировать?
Ключевым вопросом планирования является момент принятия решения. Оказывается,
существуют разнообразные ситуации, требующие вмешательства планировщика.
Во-первых, при создании нового процесса необходимо принять решение, какой из
процессов выполнять, родительский или дочерний. Поскольку оба процесса находятся
в состоянии готовности, вполне естественно, что планировщик должен принять
решение, то есть вполне обоснованно выбрать выполнение либо родительского, либо
дочернего процесса.
Во-вторых, планировщик должен принять решение, когда процесс завершает работу.
Процесс больше не может выполняться (поскольку он уже не существует), поэтому
нужно выбрать какой-нибудь процесс из числа готовых к выполнению. Если готовые
к выполнению процессы отсутствуют, обычно запускается предоставляемый системой
холостой процесс.
В-третьих, когда процесс блокируется в ожидании завершения операции ввода-вывода,
на семафоре или по какой-нибудь другой причине, для выполнения должен быть выбран
какой-то другой процесс. Иногда в этом выборе играет роль причина блокирования.
Например, если процесс A играет важную роль и ожидает, пока процесс Б не выйдет из
критической области, то предоставление очередности выполнения процессу Б позволит
этому процессу выйти из его критической области, что даст возможность продолжить
работу процессу А. Но сложность в том, что планировщик обычно не обладает необходимой
информацией, позволяющей учесть данную зависимость.
В-четвертых, планировщик должен принять решение при возникновении прерывания
ввода-вывода. Если прерывание пришло от устройства ввода-вывода, завершившего
свою работу, то какой-то процесс, который был заблокирован в ожидании завершения
операции ввода-вывода, теперь может быть готов к возобновлению работы. Планировщик
должен решить, какой процесс ему запускать: тот, что только что перешел
в состояние готовности, тот, который был запущен за время прерывания, или какойнибудь
третий процесс.
Если аппаратный таймер обеспечивает периодические прерывания с частотой 50 или
60 Гц или с какой-нибудь другой частотой, планировщик должен принимать решения
при каждом прерывании по таймеру или при каждом k-м прерывании. По реакции на
прерывания по таймеру алгоритмы планирования можно разделить на две категории.
Неприоритетный алгоритм планирования выбирает запускаемый процесс, а затем просто
дает ему возможность выполняться до тех пор, пока он не заблокируется (в ожидании
либо завершения операции ввода-вывода, либо другого процесса), или до тех
пор, пока он добровольно не освободит центральный процессор. Даже если процесс
будет работать в течение многих часов, он не будет приостановлен в принудительном
порядке. В результате во время прерываний по таймеру решения приниматься не будут.
После завершения обработки прерывания по таймеру работу возобновит ранее запущенный
процесс, если только какой-нибудь процесс более высокого уровня не ожидал
только что истекшей задержки по времени.
В отличие от этого приоритетный алгоритм планирования предусматривает выбор
процесса и предоставление ему возможности работать до истечения некоторого строго
определенного периода времени. Если до окончания этого периода он все еще будет
работать, планировщик приостанавливает его работу и выбирает для запуска другой
процесс (если есть доступный для этого процесс). Осуществление приоритетного
алгоритма планирования требует наличия прерываний по таймеру, возникающих по
окончании определенного периода времени, чтобы вернуть управление центральным
процессором планировщику. Если прерывания по таймеру недоступны, остается лишь
использовать неприоритетное планирование.
Категории алгоритмов планирования
Неудивительно, что в различных условиях окружающей среды требуются разные
алгоритмы планирования. Это обусловлено тем, что различные сферы приложений
(и разные типы операционных систем) предназначены для решения разных задач.
Иными словами, предмет оптимизации для планировщика не может совпадать во всех
системах. При этом стоит различать три среды:
? пакетную;
? интерактивную;
? реального времени.
В пакетных системах не бывает пользователей, терпеливо ожидающих за своими
терминалами быстрого ответа на свой короткий запрос. Поэтому для них зачастую
приемлемы неприоритетные алгоритмы или приоритетные алгоритмы с длительными
периодами для каждого процесса. Такой подход сокращает количество переключений
между процессами, повышая при этом производительность работы системы. Пакетные
алгоритмы носят весьма общий характер и часто находят применение и в других ситуациях,
поэтому их стоит изучить даже тем, кто не работает в сфере корпоративных
вычислений с использованием универсальных машин.
В среде с пользователями, работающими в интерактивном режиме, приобретает важность
приоритетность, удерживающая отдельный процесс от захвата центрального
процессора, лишающего при этом доступа к службе всех других процессов. Даже при
отсутствии процессов, склонных к бесконечной работе, один из процессов в случае
программной ошибки мог бы навсегда закрыть доступ к работе всем остальным процессам.
Для предупреждения такого поведения необходимо использование приоритетного
алгоритма. Под эту категорию подпадают и серверы, поскольку они, как правило,
обслуживают нескольких вечно спешащих (удаленных) пользователей. Пользователи
компьютеров постоянно пребывают в состоянии дикой спешки.
В системах, ограниченных условиями реального времени, как ни странно, приоритетность
иногда не требуется, поскольку процессы знают, что они могут запускаться
только на непродолжительные периоды времени, и зачастую выполняют свою работу
довольно быстро, а затем блокируются. В отличие от интерактивных систем в системах
реального времени запускаются лишь те программы, которые предназначены для содействия
определенной прикладной задаче. Интерактивные системы имеют универсальный
характер и могут запускать произвольные программы, которые не выполняют
совместную задачу или даже, возможно, вредят друг другу.
Задачи алгоритма планирования
Чтобы создать алгоритм планирования, нужно иметь некое представление о том, с чем
должен справиться толковый алгоритм. Некоторые задачи зависят от среды окружения
(пакетная, интерактивная или реального времени), но есть и такие задачи, которые
желательно выполнить в любом случае. Вот некоторые задачи алгоритма планирования,
которых следует придерживаться при различных обстоятельствах и которые нам
вскоре предстоит рассмотреть:
? Все системы:
• равнодоступность — предоставление каждому процессу справедливой доли
времени центрального процессора;
• принуждение к определенной политике — наблюдение за выполнением установленной
политики;
• баланс — поддержка загруженности всех составных частей системы.
? Пакетные системы:
• производительность — выполнение максимального количества заданий в час;
• оборотное время — минимизация времени между представлением задачи и ее
завершением;
• использование центрального процессора — поддержка постоянной загруженности
процессора.
? Интерактивные системы:
• время отклика — быстрый ответ на запросы;
• пропорциональность — оправдание пользовательских надежд.
? Системы реального времени:
• соблюдение предельных сроков — предотвращение потери данных;
• предсказуемость — предотвращение ухудшения качества в мультимедийных
системах.
Равнодоступность важна при любых обстоятельствах. Сопоставимые процессы должны
получать сопоставимый уровень обслуживания. Несправедливо предоставлять одному
процессу больше времени центрального процессора, чем другому, эквивалентному
ему процессу. Разумеется, различные категории процессов могут обрабатываться
по-разному. Сравните, к примеру, управление системами безопасности и выполнение
расчетов по заработной плате в компьютерном центре атомной электростанции.
К равнодоступности имеет некоторое отношение и принуждение к системной политике.
Если локальная политика заключается в том, что процессы, контролирующие безопасность,
должны получать возможность возобновления своей работы сразу же, как только
в этом возникнет необходимость, даже если при этом расчет заработной платы задержится
на полминуты, планировщик должен обеспечить осуществление этой политики.
Другой общей задачей является поддержание максимально возможной задействованности
всех составных частей системы. Если центральный процессор и все устройства
ввода-вывода смогут быть постоянно задействованы, то будет произведен больший
объем работы в секунду, чем при простое каких-нибудь компонентов. К примеру,
в пакетной системе планировщик управляет тем, чье задание поместить в память для
выполнения. Одновременное размещение в памяти части процессов, ограниченных
скоростью вычислений, и части процессов, ограниченных скоростью работы устройств
ввода-вывода, будет более разумным решением, чем загрузка и выполнение сначала
всех заданий, ограниченных скоростью вычислений, а затем, когда их выполнение
завершится, загрузка и выполнение всех заданий, ограниченных скоростью работы
устройств ввода-вывода. Если используется последняя из этих стратегий, то при запуске
процессов, ограниченных скоростью вычислений, они будут состязаться за использование
центрального процессора, а дисковое устройство будет простаивать. Затем,
когда дело дойдет до выполнения заданий, ограниченных скоростью работы устройств
ввода-вывода, они вступят в борьбу за дисковое устройство, а центральный процессор
будет простаивать. Лучше за счет разумного сочетания процессов поддерживать в работающем
состоянии сразу всю систему.
Руководители крупных вычислительных центров, в которых запускается множество
пакетных заданий, при оценке производительности своей системы обычно берут в расчет
три показателя: производительность, оборотное время и степень задействования
центрального процессора. Производительность — это количество заданий, выполненных
за один час. С учетом всех обстоятельств выполнение 50 заданий в час считается
лучшим показателем, чем выполнение 40 заданий в час. Оборотное время — это
среднестатистическое время от момента передачи задания на выполнение до момента
завершения его выполнения. Им измеряется время, затрачиваемое среднестатистическим
пользователем на вынужденное ожидание выходных данных. Здесь действует
правило: чем меньше, тем лучше.
Алгоритм планирования, доводящий до максимума производительность, не обязательно
будет сводить к минимуму оборотное время. Например, если взять сочетание коротких
и длинных заданий, то планировщик, который всегда запускал короткие задания
и никогда не работал с длинными, может достичь великолепной производительности
(выполнить множество коротких заданий за один час), но за счет крайне низкого показателя
оборотного времени для длинных заданий. При выдерживании достаточно
высокой скорости поступления коротких заданий запуск длинных заданий может
вообще никогда не состояться, доводя среднее оборотное время до бесконечности при
достижении высокого показателя производительности.
В качестве показателя в пакетных системах часто используется степень задействования
центрального процессора, но это не самый лучший показатель. В действительности
значение имеет то, сколько заданий в час выполняет система (производительность)
и сколько времени занимает получение результатов задания (оборотное время). Использование
в качестве показателя степени задействованности процессора напоминает
оценку машин по показателю, сколько оборотов в час делают их двигатели. В то же
время информация о том, когда задействованность центрального процессора достигает
100 %, пригодится для определения момента наращивания его вычислительной
мощности.
Для интерактивных систем большее значение имеют другие задачи. Наиболее важной
из них является сведение к минимуму времени отклика, то есть времени между выдачей
команды и получением результата. На персональных компьютерах, имеющих
запущенные фоновые процессы (например, чтение из сети электронной почты и ее сохранение),
пользовательский запрос на запуск программы или открытие файла должен
иметь приоритет над фоновой работой. Первоочередной запуск всех интерактивных
запросов будет восприниматься как хороший уровень обслуживания.
В определенной степени к этим системам относится и задача, которую можно назвать
пропорциональностью. Пользователям свойственно прикидывать (и зачастую неверно)
продолжительность тех или иных событий. Когда запрос, рассматриваемый как
сложный, занимает довольно продолжительное время, пользователь воспринимает это
как должное, но когда запрос, считающийся простым, также занимает немало времени,
пользователь выражает недовольство. Например, если по щелчку на значке инициируется
выкладывание видео объемом 500 Мбайт на облачный сервер, что занимает 60 с,
пользователь, наверное, воспримет это как должное, поскольку он не ожидает, что видео
будет передано за 5 с, и знает, что для этого нужно время.
Но когда пользователь щелкает на значке, который инициирует разрыв соединения
с облачным сервером после отправки видео, у него совершенно иные ожидания. Если
операция не завершается после 30 с, пользователь вряд ли смолчит, а после 60 с он
будет просто взбешен. Такое поведение будет соответствовать обычным пользовательским
представлениям о том, что на отправку большого объема данных предполагается
затратить намного больше времени, чем на разрыв соединения. В некоторых случаях
(как и в этом) планировщик не может повлиять на время отклика, но в других случаях
он может это сделать, особенно если задержка обусловлена неверным выбором очередности
выполнения процессов.
В отличие от интерактивных систем системы реального времени имеют другие свойства,
а значит, и другие задачи планирования. Они характеризуются наличием крайних
сроков выполнения, которые обязательно или по крайней мере желательно выдерживать.
Например, если компьютер управляет устройством, которое выдает данные
с определенной скоростью, отказ от запуска процесса сбора данных может привести
к потере информации. Поэтому главным требованием в системах реального времени
является соблюдение всех (или большей части) крайних сроков.
В некоторых системах реального времени, особенно в мультимедийных системах,
существенную роль играет предсказуемость. Редкие случаи несоблюдения крайних
сроков не приводят к сбоям, но если аудиопроцесс прерывается довольно часто, то
качество звука резко ухудшается. Это относится и к видеопроцессам, но человеческое
ухо более чувствительно к случайным искажениям, чем глаз. Чтобы избежать подобной
проблемы, планирование процессов должно быть исключительно предсказуемым и постоянным.
В этой главе мы рассмотрим алгоритмы планирования процессов в пакетных
и интерактивных системах. Планирование процессов реального времени в этой книге
не рассматривается, но дополнительный материал, касающийся мультимедийных операционных
систем, можно найти на веб-сайте книги.
2.4.2. Планирование в пакетных системах
Теперь давайте перейдем от общих вопросов планирования к специализированным
алгоритмам. В этом разделе будут рассмотрены алгоритмы, используемые в пакетных
системах, а в следующих разделах мы рассмотрим алгоритмы, используемые в интерактивных
системах и системах реального времени. Следует заметить, что некоторые
алгоритмы используются как в пакетных, так и в интерактивных системах. Мы рассмотрим
их чуть позже.
Первым пришел — первым обслужен
Наверное, наипростейшим из всех алгоритмов планирования будет неприоритетный
алгоритм, следующий принципу «первым пришел — первым обслужен». При использовании
этого алгоритма центральный процессор выделяется процессам в порядке
поступления их запросов. По сути, используется одна очередь процессов, находящихся
в состоянии готовности. Когда рано утром в систему извне попадает первое задание,
оно тут же запускается на выполнение и получает возможность выполняться как угодно
долго. Оно не прерывается по причине слишком продолжительного выполнения.
Другие задания по мере поступления помещаются в конец очереди. При блокировке
выполняемого процесса следующим запускается первый процесс, стоящий в очереди.
Когда заблокированный процесс переходит в состояние готовности, он, подобно только
что поступившему заданию, помещается в конец очереди, после всех ожидающих
процессов.
Сильной стороной этого алгоритма является простота его понимания и такая же
простота его программирования. Его справедливость сродни справедливости распределения
дефицитных билетов на спортивные или концертные зрелища или мест
в очереди на новые айфоны тем людям, которые заняли очередь с двух часов ночи.
При использовании этого алгоритма отслеживание готовых процессов осуществляется
с помощью единого связанного списка. Выбор следующего выполняемого процесса
сводится к извлечению одного процесса из начала очереди. Добавление нового задания
или разблокированного процесса сводится к присоединению его к концу очереди. Что
может быть проще для восприятия и реализации?
К сожалению, принцип «первым пришел — первым обслужен» страдает и существенными
недостатками. Предположим, что используются один процесс, ограниченный
скоростью вычислений, который всякий раз запускается на 1 с, и множество процессов,
ограниченных скоростью работы устройств ввода-вывода, незначительно использующих
время центрального процессора, но каждый из которых должен осуществить
1000 считываний с диска, прежде чем завершить свою работу. Процесс, ограниченный
скоростью вычислений, работает в течение 1 с, а затем переходит к чтению блока данных
с диска. Теперь запускаются все процессы ввода-вывода и приступают к чтению
данных с диска. Когда процесс, ограниченный скоростью вычислений, получает свой
блок данных с диска, он запускается еще на 1 с, а за ним непрерывной чередой следуют
все процессы, ограниченные скоростью работы устройств ввода-вывода.
В итоге каждый процесс, ограниченный скоростью работы устройств ввода-вывода,
считывает один блок в секунду, и завершение его работы займет 1000 с. Если используется
алгоритм планирования, выгружающий процесс, ограниченный скоростью
вычислений, каждые 10 мс, то процессы, ограниченные скоростью работы устройств
ввода-вывода, завершаются за 10 с вместо 1000 с, при этом особо не замедляя работу
процесса, ограниченного скоростью вычислений.
Сначала самое короткое задание
Теперь рассмотрим другой неприоритетный алгоритм для пакетных систем, в котором
предполагается, что сроки выполнения заданий известны заранее. К примеру, в страховой
компании люди могут довольно точно предсказать, сколько времени займет
выполнение пакета из 1000 исковых заявлений, поскольку подобная работа выполняется
ежедневно. Когда в ожидании запуска во входящей очереди находится несколько
равнозначных по важности заданий, планировщик выбирает сначала самое короткое
задание. Рассмотрим изображение, приведенное на рис. 2.21. Здесь представлены
четыре задания: A, B, C и D со сроками выполнения 8, 4, 4 и 4 минуты соответственно.
Если их запустить в этом порядке, оборотное время для задания A составит 8 мин, для
B — 12 мин, для C — 16 мин и для D — 20 мин при среднем времени 14 мин.
Рис. 2.21. Пример планирования, когда первым выполняется самое короткое задание:
а — запуск четырех заданий в исходном порядке; б — запуск этих заданий в порядке,
когда самое короткое из них выполняется первым
Теперь рассмотрим запуск этих четырех заданий, когда первым запускается самое короткое
из них (рис. 2.21, б). Теперь показатели оборотного времени составляют 4, 8, 12
и 20 мин при среднем времени 11 мин. Оптимальность алгоритма, при котором первым
выполняется самое короткое задание, можно доказать. Рассмотрим пример с четырьмя
заданиями, выполняемыми за время a, b, c и d соответственно. Первое задание будет
выполнено за время a, второе — за время a + b и т. д. Среднее оборотное время составит
(4a + 3b + 2c + d)/4. Очевидно, что время a оказывает наибольшее влияние на средний
показатель по сравнению со всеми остальными временными показателями, поэтому это
должно быть самое короткое задание. Затем по нарастающей должны идти b, c и наконец
d как самое продолжительное, которое оказывает влияние лишь за счет своего
собственного оборотного времени. Аналогичные аргументы точно так же применимы
к любому количеству заданий.
Следует заметить, что алгоритм, основанный на выполнении первым самого короткого
задания, оптимален только в том случае, если все задания доступны одновременно.
В качестве примера противоположной ситуации рассмотрим пять заданий от A до E
со сроками выполнения 2, 4, 1, 1 и 1 соответственно. Время их поступления 0, 0, 3, 3
и 3. Первоначально может быть выбрано только задание A или задание B, а остальные
три задания к тому времени еще не поступят. Используя правило, по которому первым
выполняется самое короткое задание, мы будем выполнять задания в следующей очередности:
A, B, C, D, E — при среднем времени ожидания, равном 4,6. Разумеется, их
запуск в следующем порядке: B, C, D, E, A — привел бы к среднему времени ожидания,
равному 4,4.
Приоритет наименьшему времени выполнения
Приоритетной версией алгоритма выполнения первым самого короткого задания
является алгоритм первоочередного выполнения задания с наименьшим оставшимся
временем выполнения. При использовании этого алгоритма планировщик всегда выбирает
процесс с самым коротким оставшимся временем выполнения. Здесь, так же
как и прежде, время выполнения заданий нужно знать заранее. При поступлении
нового задания выполняется сравнение общего времени его выполнения с оставшимися
сроками выполнения текущих процессов. Если для выполнения нового задания
требуется меньше времени, чем для завершения текущего процесса, этот процесс приостанавливается
и запускается новое здание. Эта схема позволяет быстро обслужить
новое короткое задание.
2.4.3. Планирование в интерактивных системах
Теперь давайте рассмотрим некоторые алгоритмы, которые могут быть использованы
в интерактивных системах. Они часто применяются на персональных компьютерах,
серверах и в других разновидностях систем.
Циклическое планирование
Одним из самых старых, простых, справедливых и наиболее часто используемых
считается алгоритм циклического планирования. Каждому процессу назначается
определенный интервал времени, называемый его квантом, в течение которого ему
предоставляется возможность выполнения. Если процесс к завершению кванта времени
все еще выполняется, то ресурс центрального процессора у него отбирается
и передается другому процессу. Разумеется, если процесс переходит в заблокированное
состояние или завершает свою работу до истечения кванта времени, то переключение
центрального процессора на другой процесс происходит именно в этот момент.
Алгоритм циклического планирования не представляет сложности в реализации. На
рис. 2.22, а показано, что от планировщика требуется всего лишь вести список процессов,
готовых к выполнению. Когда процесс исчерпает свой квант времени, он, как
показано на рис. 2.22, б, помещается в конец списка.
Рис. 2.22. Циклическое планирование: а — список процессов, находящихся в состоянии
готовности; б — тот же список после того, как процесс B исчерпал свой квант времени
Единственное, что по-настоящему представляет интерес в циклическом планировании,
— это продолжительность кванта времени. Переключение с одного процесса на
другой требует определенного количества времени для выполнения задач администрирования
— сохранения и загрузки регистров и карт памяти, обновления различных
таблиц и списков, сброса на диск и перезагрузки кэша памяти и т. д. Предположим,
что переключение процесса, или переключение контекста, как его иногда называют,
занимает 1 мс, включая переключение карт памяти, сброс на диск и перезагрузку кэша
и т. д. Также предположим, что значение кванта времени установлено на 4 мс. При
таких параметрах настройки после 4 мс полезной работы центральному процессору
придется затратить (то есть потерять) 1 мс на переключение процесса. Таким образом,
20 % процессорного времени будет выброшено на административные издержки, а это,
вне всякого сомнения, слишком много.
Чтобы повысить эффективность использования центрального процессора, мы можем
установить значение кванта времени равным, скажем, 100 мс. Теперь теряется всего 1 %
времени. Но посмотрим, что получится на серверной системе, если за очень короткое
время к ней поступит 50 запросов, имеющих широкий разброс степени востребованности
центрального процессора. В список готовых к запуску процессов будет помещено
50 процессов. Если центральный процессор простаивает, первый из них будет запущен
немедленно, второй не сможет запуститься, пока не истекут 100 мс, и т. д. Если предположить,
что все процессы полностью воспользуются своими квантами времени, то
самый невезучий последний процесс может пребывать в ожидании в течение 5 с, прежде
чем получит шанс на запуск. Многим пользователям работа системы при пятисекундном
ожидании ответа на короткую команду покажется слишком медленной. Эта
ситуация получит особо негативную окраску, если некоторые из запросов, размещенные
ближе к концу очереди, требуют всего лишь несколько миллисекунд процессорного
времени. Если квант времени будет короче, качество их обслуживания улучшится.
Другая особенность состоит в том, что если значение кванта времени установлено большим,
чем среднее время задействованности центрального процессора, переключение
процесса не будет происходить слишком часто. Вместо этого большинство процессов
будут выполнять операцию блокировки перед истечением кванта времени, вызывающим
переключение процессов. Исключение принудительного прерывания повышает производительность,
поскольку переключение процессов происходит только при логической
необходимости, то есть когда процесс блокируется и не может продолжить работу.
Из этого следует, что установка слишком короткого кванта времени приводит к слишком
частым переключениям процессов и снижает эффективность использования центрального
процессора, но установка слишком длинного кванта времени может привести
к слишком вялой реакции на короткие интерактивные запросы. Зачастую разумным
компромиссом считается квант времени в 20–50 мс.
Приоритетное планирование
В циклическом планировании явно прослеживается предположение о равнозначности
всех процессов. Зачастую люди, обладающие многопользовательскими компьютерами
и работающие на них, имеют на этот счет совершенно иное мнение. К примеру,
в университете иерархия приоритетности должна нисходить от декана к факультетам,
затем к профессорам, секретарям, техническим работникам, а уже потом к студентам.
Необходимость учета внешних факторов приводит к приоритетному планированию.
Основная идея проста: каждому процессу присваивается значение приоритетности
и запускается тот процесс, который находится в состоянии готовности и имеет наивысший
приоритет.
Даже если у персонального компьютера один владелец, на нем могут выполняться
несколько процессов разной степени важности. Например, фоновому процессу, отправляющему
электронную почту, должен быть назначен более низкий приоритет, чем
процессу, воспроизводящему на экране видеофильм в реальном времени.
Чтобы предотвратить бесконечное выполнение высокоприоритетных процессов, планировщик
должен понижать уровень приоритета текущего выполняемого процесса
с каждым сигналом таймера (то есть с каждым его прерыванием). Если это действие
приведет к тому, что его приоритет упадет ниже приоритета следующего по этому показателю
процесса, произойдет переключение процессов. Можно выбрать и другую
альтернативу: каждому процессу может быть выделен максимальный квант допустимого
времени выполнения. Когда квант времени будет исчерпан, шанс запуска будет
предоставлен другому процессу, имеющему наивысший приоритет.
Приоритеты могут присваиваться процессам в статическом или в динамическом режиме.
Например, на военных компьютерах процессы, инициированные генералами,
могут начинать свою работу с приоритетом, равным 100, процессы, инициированными
полковниками, — с приоритетом, равным 90, майорами — с приоритетом 80, капитанами
— 70, лейтенантами — 60 и так далее вниз по табели о рангах. А в коммерческом
компьютерном центре высокоприоритетные задания могут стоить 100 долларов в час,
задания со средним приоритетом — 75, а задания с низким приоритетом — 50. В UNIXсистемах
есть команда nice, позволяющая пользователю добровольно снизить приоритет
своего процесса, чтобы угодить другим пользователям, но ею никто никогда
не пользуется.
Приоритеты также могут присваиваться системой в динамическом режиме с целью достижения
определенных системных задач. К примеру, некоторые процессы испытывают
существенные ограничения по скорости работы устройств ввода-вывода и проводят
большую часть своего времени в ожидании завершения операций ввода-вывода. Как
только такому процессу понадобится центральный процессор, он должен быть предоставлен
немедленно, чтобы процесс мог приступить к обработке следующего запроса
на ввод-вывод данных, который затем может выполняться параллельно с другим процессом,
занятым вычислениями. Если заставить процесс, ограниченный скоростью
работы устройств ввода-вывода, долго ждать предоставления центрального процессора,
это будет означать, что он занимает оперативную память неоправданно долго. Простой
алгоритм успешного обслуживания процессов, ограниченных скоростью работы
устройств ввода-вывода, предусматривает установку значения приоритета в 1/f, где
f — это часть последнего кванта времени, использованного этим процессом. Процесс,
использовавший только 1 мс из отпущенных ему 50 мс кванта времени, должен получить
приоритет 50, в то время как процесс, проработавший до блокировки 25 мс, получит
приоритет, равный 2, а процесс, использовавший весь квант времени, получит
приоритет, равный 1.
Зачастую бывает удобно группировать процессы по классам приоритетности и использовать
приоритетное планирование применительно к этим классам, а внутри
каждого класса использовать циклическое планирование. На рис. 2.23 показана система
с четырьмя классами приоритетности. Алгоритм планирования выглядит следующим
образом: если есть готовые к запуску процессы с классом приоритетности 4, следует
запустить каждый из них на один квант времени по принципу циклического планирования,
при этом вовсе не беспокоясь о классах с более низким приоритетом. Когда
класс с уровнем приоритета 4 опустеет, в циклическом режиме запускаются процессы
с классом приоритетности 3. Если опустеют оба класса, 4 и 3, в циклическом режиме
запускаются процессы с классом приоритетности 2 и т. д. Если приоритеты каким-то
образом не будут уточняться, то все классы с более низким уровнем приоритета могут
«умереть голодной смертью».
Рис. 2.23. Алгоритм планирования для четырех классов приоритетности
Использование нескольких очередей
Одной из самых ранних систем приоритетного планирования была CTSS (Compatible
Time Sharing System — совместимая система разделения времени), разработанная
в Массачусетском технологическом институте, которая работала на машине IBM 7094
(Corbato et al., 1962). CTSS страдала от проблемы очень медленного переключения процессов,
поскольку машина 7094 была способна содержать в оперативной памяти лишь
один процесс. Каждое переключение означало сброс текущего процесса на диск и считывание
нового процесса с диска. Разработчики CTSS быстро поняли, что эффективнее
было бы время от времени выделять процессам, ограниченным скоростью вычислений,
более существенные кванты времени, вместо того чтобы слишком часто выделять им
небольшие кванты времени (чтобы сократить обмен данными с диском). В то же время
предоставление всем процессам больших квантов времени обернется увеличением времени
отклика, о чем мы уже упоминали. Разработчики приняли решение учредить классы
приоритетов. Процессы, относящиеся к наивысшему классу, запускались на 1 квант
времени, процессы следующего по нисходящей класса — на 2 кванта времени, процессы
следующего класса — на 4 кванта времени и т. д. Как только процесс использовал все
выделенные ему кванты времени, его класс понижался.
В качестве примера рассмотрим процесс, который нужен для вычислений продолжительностью
в 100 квантов времени. Сначала ему будет выделен 1 квант времени,
после чего он будет выгружен на диск. В следующий раз ему перед выгрузкой на диск
будут выделены 2 кванта времени. При последующих запусках он будет получать 4,
8, 16, 32 и 64 кванта времени, хотя из финальных 64 квантов он для завершения своей
работы использует лишь 3 обменов данными с диском, которые потребовались
бы при использовании циклического алгоритма, потребуется только 7 (включая
начальную загрузку). Более того, по мере погружения процесса в очередь приоритетов
он будет запускаться все реже и реже, сберегая время центрального процессора для
коротких интерактивных процессов.
Чтобы уберечь процесс, нуждающийся в длительной работе при первом запуске, но
потом ставший интерактивным, от постоянных «наказаний», была выбрана следующая
политика: когда на терминале набирался символ возврата каретки (нажималась клавиша
 Enter ), процесс, принадлежащий терминалу, перемещался в класс с более высоким
приоритетом, поскольку предполагалось, что он собирался стать интерактивным.
В один прекрасный день некий пользователь, в чьих интересах работал процесс, сильно
ограниченный скоростью вычислений, обнаружил, что, бездумно просиживая время
за терминалом и беспорядочно набирая символ возврата каретки каждые несколько
секунд, можно буквально творить чудеса со временем отклика. Он рассказал об этом
своим друзьям. А они рассказали своим друзьям. Мораль этой истории такова: понять,
что получится из задуманного, на практике куда сложнее, чем усвоить сам принцип
идеи.
Выбор следующим самого короткого процесса
Поскольку предоставление первоочередного запуска самым коротким заданиям приводит
к минимизации среднего времени отклика для пакетных систем, было бы неплохо
воспользоваться этим же принципом и для интерактивных процессов. И отчасти это
возможно. Обычно интерактивные процессы следуют схеме, при которой ожидается
ввод команды, затем она выполняется, ожидается ввод следующей команды, затем
выполняется эта команда и т. д. Если выполнение каждой команды рассматривать как
отдельное «задание», то мы можем минимизировать общее время отклика, запустив
первой выполнение самой короткой команды. Проблема состоит в определении того,
какой из находящихся в состоянии готовности процессов является самым коротким.
Один из методов заключается в оценке предыдущего поведения и запуске процесса
с самым коротким вычисленным временем выполнения. Предположим, что для какогото
терминала оценка времени выполнения одной команды составляет T 0 . Теперь предположим,
что следующая оценка этого времени составляет T 1 . Мы можем обновить
наш расчет, взяв взвешенную сумму этих двух чисел, то есть aT 0 + (1 ? a)T 1 . Выбирая
значение a, мы можем решить, стоит ли при оценке процесса быстро забывать его
предыдущие запуски или нужно запоминать их надолго. При a = 1/2 мы получаем
следующую последовательность вычислений:
T 0 ; T 0 /2 + T 1 /2; T 0 /4 + T 1 /4 + T 2 /2; T 0 /8 + T 1 /8 + T 2 /4 + T 3 /2.
После трех новых запусков значимость T 0 при новой оценке снижается до 1/8.
Технология вычисления следующего значения в серии путем расчета взвешенной
суммы текущего измеренного значения и предыдущих вычислений иногда называется
распределением по срокам давности. Она применяется во многих ситуациях, где на
основе предыдущих значений нужно выдавать какие-нибудь предсказания. Распределение
по срокам давности особенно просто реализуется при a = 1/2. Все, что при этом
нужно, — добавить новое значение к текущей оценке и разделить сумму на 2 (за счет
сдвига вправо на один бит).
Гарантированное планирование
Совершенно иной подход к планированию заключается в предоставлении пользователям
реальных обещаний относительно производительности, а затем в выполнении этих
обещаний. Одно из обещаний, которое можно дать и просто выполнить, заключается
в следующем: если в процессе работы в системе зарегистрированы n пользователей, то
вы получите 1/n от мощности центрального процессора. Аналогично этому в однопользовательской
системе, имеющей n работающих процессов, при прочих равных условиях
каждый из них получит 1/n от общего числа процессорных циклов. Это представляется
вполне справедливым решением.
Чтобы выполнить это обещание, система должна отслеживать, сколько процессорного
времени затрачено на каждый процесс с момента его создания. Затем она вычисляет количество
процессорного времени, на которое каждый из них имел право, а именно время
с момента его создания, деленное на n. Поскольку также известно и количество времени
центрального процессора, уже полученное каждым процессом, нетрудно подсчитать
соотношение израсходованного и отпущенного времени центрального процессора. Соотношение
0,5 означает, что процесс получил только половину от того, что должен был
получить, а соотношение 2,0 означает, что процесс получил вдвое больше времени, чем
то, на которое он имел право. Согласно алгоритму, после этого будет запущен процесс
с самым низким соотношением, который будет работать до тех пор, пока его соотношение
не превысит соотношение его ближайшего конкурента. Затем для запуска в следующую
очередь выбирается этот процесс.
Лотерейное планирование
Выдача пользователям обещаний с последующим их выполнением — идея неплохая, но
реализовать ее все же нелегко. Но есть и другой, более простой в реализации алгоритм,
который можно использовать для получения столь же предсказуемых результатов. Он
называется лотерейным планированием (Waldspurger and Weihl, 1994).
Основная идея состоит в раздаче процессам лотерейных билетов на доступ к различным
системным ресурсам, в том числе к процессорному времени. Когда планировщику нужно
принимать решение, в случайном порядке выбирается лотерейный билет, и ресурс
отдается процессу, обладающему этим билетом. Применительно к планированию процессорного
времени система может проводить лотерейный розыгрыш 50 раз в секунду,
и каждый победитель будет получать в качестве приза 20 мс процессорного времени.
Перефразируя Джорджа Оруэлла, можно сказать: «Все процессы равны, но некоторые
из них равнее остальных». Более важным процессам, чтобы повысить их шансы на
выигрыш, могут выдаваться дополнительные билеты. Если есть 100 неразыгранных
билетов и один из процессов обладает двадцатью из них, то он будет иметь 20 %-ную вероятность
выигрыша в каждой лотерее. В конечном счете он получит около 20 %
процессорного времени. В отличие от приоритетного планирования, где очень трудно
сказать, что на самом деле означает приоритет со значением 40, здесь действует вполне
определенное правило: процесс, имеющий долю из f билетов, получит примерно f долей
рассматриваемого ресурса.
У лотерейного планирования есть ряд интересных свойств. Например, если появится
новый процесс и ему будет выделено несколько билетов, то уже при следующем лотерейном
розыгрыше он получит шанс на выигрыш, пропорциональный количеству
полученных билетов. Иными словами, лотерейное планирование очень быстро реагирует
на изменение обстановки.
Взаимодействующие процессы могут по желанию обмениваться билетами. Например,
когда клиентский процесс отправляет сообщение серверному процессу, а затем блокируется,
он может передать все свои билеты серверному процессу, чтобы повысить его
шансы быть запущенным следующим. Когда сервер завершит свою работу, он возвращает
билеты, чтобы клиент мог возобновить свою работу. Фактически при отсутствии
клиентов серверам билеты вообще не нужны.
Лотерейное планирование может быть использовано для решения проблем, с которыми
трудно справиться другими методами. В качестве одного из примеров можно привести
видеосервер, в котором несколько процессов предоставляют своим клиентам видеопотоки,
имеющие разную частоту кадров. Предположим, что процессам нужны скорости
10, 20 и 25 кадров в секунду. Распределяя этим процессам 10, 20 и 25 билетов соответственно,
можно автоматически разделить процессорное время примерно в нужной
пропорции, то есть 10 : 20 : 25.
Справедливое планирование
До сих пор мы предполагали, что каждый процесс фигурирует в планировании сам по
себе, безотносительно своего владельца. В результате, если пользователь 1 запускает
9 процессов, а пользователь 2 запускает 1 процесс, то при циклическом планировании
или при равных приоритетах пользователь 1 получит 90 % процессорного времени,
а пользователь 2 — только 10 %.
Чтобы избежать подобной ситуации, некоторые системы перед планированием работы
процесса берут в расчет, кто является его владельцем. В этой модели каждому
пользователю распределяется некоторая доля процессорного времени и планировщик
выбирает процессы, соблюдая это распределение. Таким образом, если каждому из
двух пользователей было обещано по 50 % процессорного времени, то они его получат,
независимо от количества имеющихся у них процессов.
В качестве примера рассмотрим систему с двумя пользователями, каждому из которых
обещано 50 % процессорного времени. У первого пользователя четыре процесса, A, B,
C и D, а у второго пользователя только один процесс — E. Если используется циклическое
планирование, то возможная последовательность планируемых процессов,
соответствующая всем ограничениям, будет иметь следующий вид:
AEBECEDEAEBECEDE...
Но если первому пользователю предоставлено вдвое большее время, чем второму, то
мы можем получить следующую последовательность:
ABECDEABECDE…
Разумеется, существует масса других возможностей, используемых в зависимости от
применяемых понятий справедливости.
2.4.4. Планирование в системах реального времени
Системы реального времени относятся к тому разряду систем, в которых время играет
очень важную роль. Обычно одно или несколько физических устройств, не имеющих
отношения к компьютеру, генерируют входные сигналы, а компьютер в определенный
промежуток времени должен соответствующим образом на них реагировать. К примеру,
компьютер в проигрывателе компакт-дисков получает биты от привода и должен
превращать их в музыку за очень короткий промежуток времени. Если вычисления
занимают слишком много времени, музыка приобретет довольно странное звучание.
Другими системами реального времени являются система отслеживания параметров
пациента в палате интенсивной терапии, автопилот воздушного судна, устройство
управления промышленными роботами на автоматизированном предприятии. Во всех
этих случаях получение верного результата, но с запозданием, зачастую так же неприемлемо,
как и неполучение его вообще.
Системы реального времени обычно делятся на жесткие системы реального времени
(системы жесткого реального времени), в которых соблюдение крайних сроков обязательно,
и гибкие системы реального времени (системы мягкого реального времени),
в которых нерегулярные несоблюдения крайних сроков нежелательны, но вполне
допустимы. В обоих случаях режим реального времени достигается за счет разделения
программы на несколько процессов, поведение каждого из которых вполне предсказуемо
и заранее известно. Эти процессы являются, как правило, быстротечными
и способными успешно завершить свою работу за секунду. При обнаружении внешнего
события планировщик должен так спланировать работу процессов, чтобы были соблюдены
все крайние сроки.
События, на которые должна реагировать система реального времени, могут быть
определены как периодические (происходящие регулярно) или апериодические (происходящие
непредсказуемо). Возможно, системе придется реагировать на несколько
периодических потоковых событий. В зависимости от времени, необходимого на обработку
каждого события, с обработкой всех событий система может даже не справиться.
Например, если происходит m периодических событий, событие i возникает с периодом
P i и для обработки каждого события требуется C i секунд процессорного времени, то
поступающая информация может быть обработана только в том случае, если
Система реального времени, отвечающая этому критерию, называется планируемой.
Это означает, что такая система фактически может быть реализована. Процесс, не отвечающий
этому тесту, не может быть планируемым, поскольку общее время центрального
процессора, требуемое процессу, в совокупности больше того времени, которое
этот центральный процессор может предоставить.
В качестве примера рассмотрим гибкую систему реального времени с тремя периодическими
событиями с периодами 100, 200 и 500 мс соответственно. Если на обработку
каждого из этих событий требуется, соответственно, 50, 30 и 100 мс процессорного
времени, работа системы может быть спланирована, поскольку 0,5 + 0,15 + 0,2 < 1.
Если будет добавлено четвертое событие с периодом 1 с, то система будет сохранять
планируемость до тех пор, пока на обработку этого события не потребуется более
150 мс процессорного времени. В этом вычислении подразумевается, что издержки на
переключение контекста настолько малы, что ими можно пренебречь.
Алгоритмы планирования работы систем реального времени могут быть статическими
или динамическими. Первый из них предусматривает принятие решений по
планированию еще до запуска системы, а второй — их принятие в реальном времени,
после того как начнется выполнение программы. Статическое планирование работает
только при условии предварительного обладания достоверной информацией
о выполняемой работе и о крайних сроках, которые нужно соблюсти. Алгоритмы
динамического планирования подобных ограничений не имеют. Изучение конкретных
алгоритмов мы отложим до главы 7, где будут рассмотрены мультимедийные
системы реального времени.
2.4.5. Политика и механизмы
До сих пор негласно подразумевалось, что все процессы в системе принадлежат разным
пользователям и поэтому конкурируют в борьбе за процессорное время. Хотя зачастую
это и соответствует действительности, иногда бывает так, что у одного процесса есть
множество дочерних процессов, запущенных под его управлением. Например, процесс
системы управления базой данных может иметь множество дочерних процессов.
Каждый из них может работать над своим запросом или обладать специфическими
выполняемыми функциями (разбор запроса, доступ к диску и т. д.). Вполне возможно,
что основной процесс великолепно разбирается в том, какой из его дочерних процессов
наиболее важен (или критичен по времени выполнения), а какой — наименее важен.
К сожалению, ни один из ранее рассмотренных планировщиков не воспринимает
никаких входных данных от пользовательских процессов, касающихся принятия решений
по планированию. В результате этого планировщик довольно редко принимает
наилучшие решения.
Решение этой проблемы заключается в укоренившемся принципе разделения механизма
и политики планирования (Levin et al., 1975). Это означает наличие какого-нибудь
способа параметризации алгоритма планирования, предусматривающего возможность
пополнения параметров со стороны пользовательских процессов. Рассмотрим еще раз
пример использования базы данных. Предположим, что ядро применяет алгоритм приоритетного
планирования, но предоставляет системный вызов, с помощью которого
процесс может установить (или изменить) приоритеты своих дочерних процессов. Таким
образом родительский процесс может всесторонне управлять порядком планирования
работы дочерних процессов, даже если сам планированием не занимается. Здесь мы
видим, что механизм находится в ядре, а политика устанавливается пользовательским
процессом. Ключевой идеей здесь является отделение политики от механизма.
2.4.6. Планирование потоков
Когда есть несколько процессов и у каждого — несколько потоков, у нас появляется
два уровня параллелизма: процессы и потоки. Планирование в таких системах в значительной
степени зависит от того, на каком уровне поддерживаются потоки — на
пользовательском, на уровне ядра или на обоих уровнях.
Сначала рассмотрим потоки на уровне пользователя. Поскольку ядро о существовании
потоков не знает, оно работает в обычном режиме, выбирая процесс, скажем, A, и передает
процессу A управление до истечения его кванта времени. Планировщик потоков
внутри процесса A решает, какой поток запустить, — скажем, A1. Из-за отсутствия
таймерных прерываний для многозадачных потоков этот поток может продолжать
работу, сколько ему понадобится. Если он полностью израсходует весь квант времени,
отведенный процессу, ядро выберет для запуска другой процесс.
Когда процесс A будет наконец-то снова запущен, поток A1 также возобновит работу.
Он продолжит расходовать все отведенное процессу A время, пока не закончит работу.
Но его недружелюбное поведение никак не отразится на других процессах. Они
получат то, что планировщик посчитает их долей, независимо от того, что происходит
внутри процесса A.
Теперь рассмотрим случай, когда потоки процесса A выполняют непродолжительную
относительно доли выделенного процессорного времени работу, например работу
продолжительностью 5 мс при кванте времени 50 мс. Следовательно, каждый из них
запускается на небольшой период времени, возвращая затем центральный процессор
планировщику потоков. При этом, перед тем как ядро переключится на процесс B,
может получиться следующая последовательность: A1, A2, A3, A1, A2, A3, A1, A2, A3,
A1. Эта ситуация показана на рис. 2.24, а.
Рис. 2.24. Возможный вариант планирования потоков: а — на уровне пользователя с квантом
времени 50 мс и потоками, работающими по 5 мс при работе центрального процессора
в пределах этого кванта; б — на уровне ядра с теми же характеристиками
Алгоритм планирования, используемый системой поддержки исполнения программ,
может быть любым из ранее рассмотренных. На практике наиболее широко распространены
циклическое и приоритетное планирование. Единственным ограничением будет
отсутствие таймерного прерывания в отношении потока, выполняемого слишком долго.
Но поскольку потоки взаимодействуют, обычно это не вызывает проблем.
Теперь рассмотрим ситуацию с потоками, реализованными на уровне ядра. Здесь
конкретный запускаемый поток выбирается ядром. Ему не нужно учитывать принадлежность
этого потока конкретному процессу, но если понадобится, то он может это
сделать. Потоку выделяется квант времени, по истечении которого его работа приостанавливается.
Если выделен квант 50 мс, а запущен поток, который блокируется
через 5 мс, то очередность потоков на период продолжительностью 30 мс может быть
следующей: A1, B1, A2, B2, A3, B3, что невозможно получить при таких параметрах на
пользовательском уровне. Эта ситуация частично показана на рис. 2.24, б.
Потоки на уровне пользователя и потоки на уровне ядра различаются в основном производительностью
работы. Для переключения потоков, реализованных на уровне пользователя,
требуется лишь небольшое количество машинных команд, а для потоков на уровне
ядра требуется полное контекстное переключение, смена карты памяти и аннулирование
кэша, что выполняется на несколько порядков медленнее. В то же время поток на уровне
ядра, заблокированный на операции ввода-вывода, не вызывает приостановку всего процесса,
как поток на уровне пользователя. Поскольку ядру известно, что на переключение
с потока из процесса A на поток из процесса B затрачивается больше времени, чем на
запуск второго потока из процесса A (из-за необходимости изменения карты памяти
и обесценивания кэша памяти), то оно может учесть эти сведения при принятии решения.
К примеру, если взять два равнозначных во всем остальном потока, один из которых принадлежит
тому процессу, чей поток был только что заблокирован, а второй принадлежит
другому процессу, предпочтение может быть отдано первому потоку.
Другой важный фактор заключается в том, что потоки, реализованные на уровне пользователя,
могут использовать планировщик потоков, учитывающий особенности приложения.
Рассмотрим, к примеру, веб-сервер, показанный на рис. 2.6. Предположим, что
рабочий поток был только что заблокирован, а поток диспетчера и два рабочих потока
находятся в состоянии готовности. Какой из потоков должен быть запущен следующим?
Система поддержки исполнения программ, владеющая информацией о том, чем занимаются
все потоки, может без труда выбрать следующим для запуска диспетчер, чтобы
тот запустил следующий рабочий процесс. Эта стратегия доводит до максимума степень
параллелизма в среде, где рабочие потоки часто блокируются на дисковых операциях
ввода-вывода. Когда потоки реализованы на уровне ядра, само ядро никогда не будет
обладать информацией, чем занимается каждый поток (хотя им могут быть присвоены
разные приоритеты). Но в целом планировщики потоков, учитывающие особенности
приложений, могут лучше подстроиться под приложение, чем ядро.
2.5. Классические задачи
взаимодействия процессов
В литературе по операционным системам можно встретить множество интересных
проблем использования различных методов синхронизации, ставших предметом
широких дискуссий и анализа. В данном разделе мы рассмотрим наиболее известные
проблемы.
 году Дейкстра сформулировал, а затем решил проблему синхронизации, названную
им задачей обедающих философов. С тех пор все изобретатели очередного
примитива синхронизации считали своим долгом продемонстрировать его наилучшие
качества, показав, насколько элегантно с его помощью решается задача обедающих
философов. Суть задачи довольно проста. Пять философов сидят за круглым столом,
и у каждого из них есть тарелка спагетти. Эти спагетти настолько скользкие, что есть
их можно только двумя вилками. Между каждыми двумя тарелками лежит одна вилка.
Внешний вид стола показан на рис. 2.25.
Рис. 2.25. Обед на факультете философии
Жизнь философа состоит из чередующихся периодов приема пищи и размышлений.
(Это положение из разряда абстракций даже в отношении философов, но вся их
остальная деятельность к задаче не относится.) Когда философ становится голоден,
он старается поочередно в любом порядке завладеть правой и левой вилками. Если
ему удастся взять две вилки, он на некоторое время приступает к еде, затем кладет обе
вилки на стол и продолжает размышления. Основной вопрос состоит в следующем:
можно ли написать программу для каждого философа, который действует предполагаемым
образом и никогда при этом не попадает в состояние зависания? (Можно
заметить, что потребность в двух вилках выглядит несколько искусственно. Может
быть, стоит переключиться с итальянской на китайскую кухню, заменив спагетти рисом,
а вилки — палочками для еды?)
В листинге 2.13 показано самое простое решение этой задачи. Процедура take_fork
ждет, пока вилка не освободится, и берет ее. К сожалению, это решение ошибочно.
Допустим, что все пять философов одновременно берут левую от себя вилку. Тогда
никто из них не сможет взять правую вилку, что приведет к взаимной блокировке.
Листинг 2.13. Ошибочное решение задачи обедающих философов
#define N 5 /* количество философов */
void philosopher(int i) /* i: номер философа (от 0 до 4) */
{
while (TRUE) {
think( ); /* философ размышляет */
take_fork(i); /* берет левую вилку */
take_fork((i+1) % N); /* берет правую вилку; */
/* % - оператор деления по модулю */
eat(); /* ест спагетти */
put_fork(i); /* кладет на стол левую вилку */
put_fork((i+1) % N); /* кладет на стол правую вилку */
}
}
Можно без особого труда изменить программу так, чтобы после получения левой вилки
программа проверяла доступность правой вилки. Если эта вилка недоступна, философ
кладет на место левую вилку, ожидает какое-то время, а затем повторяет весь процесс.
Это предложение также ошибочно, но уже по другой причине. При некоторой доле невезения
все философы могут приступить к выполнению алгоритма одновременно и, взяв
левые вилки и увидев, что правые вилки недоступны, опять одновременно положить
на место левые вилки, и так до бесконечности. Подобная ситуация, при которой все
программы бесконечно работают, но не могут добиться никакого прогресса, называется
голоданием, или зависанием процесса. (Эта ситуация называется голоданием даже
в том случае, если проблема возникает вне стен итальянского или китайского ресторана.)
Можно подумать, что стоит только заменить одинаковое для всех философов время
ожидания после неудачной попытки взять правую вилку на случайное, и вероятность,
что все они будут топтаться на месте хотя бы в течение часа, будет очень мала. Это
правильное рассуждение, и практически для всех приложений повторная попытка через
некоторое время не вызывает проблемы. К примеру, если в популярной локальной
сети Ethernet два компьютера одновременно отправляют пакет данных, каждый из них
выжидает случайный отрезок времени, а затем повторяет попытку. И на практике это
решение неплохо работает. Но в некоторых приложениях может отдаваться предпочтение
решению, которое срабатывает всегда и не может привести к отказу по причине
неудачной череды случайных чисел. Вспомним о системе управления безопасностью
атомной электростанции.
В программу, показанную в листинге 2.13, можно внести улучшение, позволяющее
избежать взаимной блокировки и зависания. Для этого нужно защитить пять операторов,
следующих за вызовом think, двоичным семафором. Перед тем как брать вилки,
философ должен выполнить в отношении переменной mutex операцию down. А после
того как он положит вилки на место, он должен выполнить в отношении переменной
mutex операцию up. С теоретической точки зрения это вполне достаточное решение.
Но с практической — в нем не учтен вопрос производительности: в каждый момент
времени может есть спагетти только один философ. А при наличии пяти вилок одновременно
могут есть спагетти два философа.
Решение, представленное в листинге 2.14, не вызывает взаимной блокировки и допускает
максимум параллелизма для произвольного числа философов. В нем используется
массив state, в котором отслеживается, чем занимается философ: ест, размышляет
или пытается поесть (пытается взять вилки). Перейти в состояние приема пищи философ
может, только если в этом состоянии не находится ни один из его соседей. Соседи
философа с номером i определяются макросами LEFT и RIGHT. Иными словами, если
i равен 2, то LEFT равен 1, а RIGHT равен 3.
Листинг 2.14. Решение задачи обедающих философов
#define N 5 /* количество философов */
#define LEFT (i+N?1) %N /* номер левого соседа для i-го философа */
#define RIGHT (i+1) %N /* номер правого соседа для i-го
философа */
#define THINKING 0 /* философ размышляет */
#define HUNGRY 1 /* философ пытается взять вилки */
#define EATING 2 /* философ ест спагетти */
typedef int semaphore; /* Семафоры — особый вид целочисленных
переменных */
int state[N]; /* массив для отслеживания состояния
каждого философа */
semaphore mutex = 1; /* Взаимное исключение входа в
критическую область */
semaphore s[N]; /* по одному семафору на каждого
философа */
void philosopher(int i) /* i – номер философа (от 0 до N?1) */
{
while (TRUE) { /* бесконечный цикл */
think(); /* философ размышляет */
take_forks(i); /* берет две вилки или блокируется */
eat(); /* ест спагетти */
put_forks(i); /* кладет обе вилки на стол */
}
}
void take_forks(int i) /* i – номер философа (от 0 до N?1) */
{
down(&mutex); /* вход в критическую область */
state[i] = HUNGRY; /* запись факта стремления философа
поесть */
test(i); /* попытка взять две вилки */
up(&mutex); /* выход из критической области */
down(&s[i]); /* блокирование, если вилки взять не
удалось */
}
void put_forks(i) /* i – номер философа (от 0 до N?1) */
{
down(&mutex); /* вход в критическую область */
state[i] = THINKING; /* философ наелся */
test(LEFT); /* проверка готовности к еде соседа
слева */
test(RIGHT); /* проверка готовности к еде соседа
справа */
up(&mutex); /* выход из критической области */
}
void test(i) /* i – номер философа (от 0 до N?1) */
{
if (state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] != EATING) {
state[i] = EATING;
up(&s[i]);
}
}
В программе используется массив семафоров, по одному семафору на каждого философа,
поэтому голодный философ может блокироваться, если нужная ему вилка занята.
Обратите внимание на то, что каждый процесс в качестве своей основной программы
запускает процедуру philosopher, но остальные процедуры: take_forks, put_ forks и test —
это обычные процедуры, а не отдельные процессы.
2.5.2. Задача читателей и писателей
Задача обедающих философов хороша для моделирования процессов, которые соревнуются
за исключительный доступ к ограниченному количеству ресурсов, например
к устройствам ввода-вывода. Другая общеизвестная задача касается читателей и писателей
(Courtois et al., 1971). В ней моделируется доступ к базе данных. Представим,
к примеру, систему бронирования авиабилетов, в которой есть множество соревнующихся
процессов, желающих обратиться к ней для чтения и записи. Вполне допустимо
наличие нескольких процессов, одновременно считывающих информацию из базы
данных, но если один процесс обновляет базу данных (проводит операцию записи),
никакой другой процесс не может получить доступ к базе данных даже для чтения
информации. Вопрос в том, как создать программу для читателей и писателей? Одно
из решений показано в листинге 2.15.
В этом решении первый читатель для получения доступа к базе данных выполняет в отношении
семафора db операцию down. А все следующие читатели просто увеличивают
значение счетчика rc. Как только читатели прекращают свою работу, они уменьшают
значение счетчика, а последний из них выполняет в отношении семафора операцию
up, позволяя заблокированному писателю, если таковой имеется, приступить к работе.
В представленном здесь решении есть одна достойная упоминания недостаточно очевидная
особенность. Допустим, что какой-то читатель уже использует базу данных
и тут появляется еще один читатель. Поскольку одновременная работа двух читателей
разрешена, второй читатель допускается к базе данных. По мере появления к ней могут
быть допущены и другие дополнительные читатели.
Теперь допустим, что появился писатель. Он может не получить доступа к базе данных,
поскольку писатели должны иметь к ней исключительный доступ, поэтому писатель
приостанавливает свою работу. Позже появляются и другие читатели. Доступ дополнительным
читателям будет открыт до тех пор, пока будет активен хотя бы один
читатель. Вследствие этой стратегии, пока продолжается наплыв читателей, все они
будут получать доступ к базе по мере своего прибытия. Писатель будет приостановлен
до тех пор, пока не останется ни одного читателя. Если новый читатель будет прибывать,
скажем, каждые 2 с и каждый читатель затратит на свою работу по 5 с, писатель
доступа никогда не дождется.
2.6. Исследования, посвященные процессам и потокам 203
Чтобы предотвратить такую ситуацию, программу можно слегка изменить: когда писатель
находится в состоянии ожидания, то вновь прибывающий читатель не получает
немедленного доступа, а приостанавливает свою работу и встает в очередь за писателем.
При этом писатель должен дождаться окончания работы тех читателей, которые были
активны при его прибытии, и не должен пережидать тех читателей, которые прибывают
после него. Недостаток этого решения заключается в снижении производительности
за счет меньших показателей параллельности в работе. Куртуа с соавторами (Courtois
et al., 1971) представили решение, дающее приоритет писателям. Подробности этого
решения можно узнать из их статьи.
Листинг 2.15. Решение задачи читателей и писателей
typedef int semaphore; /* напрягите свое воображение */
semaphore mutex = 1; /* управляет доступом к 'rc' */
semaphore db = 1; /* управляет доступом к базе данных */
int rc = 0; /* количество читающих или желающих
читать процессов */
void reader(void)
{
while (TRUE) { /* бесконечный цикл */
down(&mutex); /* получение исключительного доступа к ‘rc’ */
rc = rc + 1; /* теперь на одного читателя больше */
if (rc == 1) down(&db); /* если это первый читатель... */
up(&mutex); /* завершение исключительного доступа
к ‘rc’ */
read_data_base( ); /* доступ к данным */
down(&mutex); /* получение исключительного доступа к ‘rc’ */
rc = rc ? 1; /* теперь на одного читателя меньше */
if (rc == 0) up(&db); /* если это последний читатель... */
up(&mutex); /* завершение исключительного доступа к ‘rc’
*/
use_data_read(); /* некритическая область */
}
}
void writer(void)
{
while (TRUE) { /* бесконечный цикл */
think_up_data( ); /* некритическая область */
down(&db); /* получение исключительного доступа */
write_data_base( ); /* обновление данных */
up(&db); /* завершение исключительного доступа */
}
}
2.6. Исследования, посвященные
процессам и потокам
В главе 1 мы рассмотрели ряд текущих исследований, посвященных структуре операционных
систем. В этой и последующих главах рассмотрим более узконаправленные
исследования, начинающиеся с процессов. Со временем станет понятно, что некоторые
предметы исследований лучше разработаны по сравнению с другими. Большинство исследований
обычно направлены на изучение новых тем и не относятся к темам, которые
исследуются уже не один десяток лет.
Понятие процесса являет собой пример довольно хорошо разработанной темы. Практически
каждая система обладает неким понятием процесса как контейнера, предназначенного
для группировки взаимосвязанных ресурсов, таких как адресное пространство,
потоки, открытые файлы, права доступа к защищенным ресурсам и т. д. Группировка
осуществляется в различных системах немного по-разному, но эти различия носят чисто
технический характер. Основная идея уже практически не вызывает споров, и новых
исследований по теме процессов проводится совсем немного.
По сравнению с процессами потоки являются более новой идеей, но они тоже уже
довольно долго рассматриваются. Тем не менее время от времени все еще появляются
статьи, посвященные потокам, к примеру о кластеризации потоков на мультипроцессорных
системах (Tam et al., 2007) или о том, как хорошо современные операционные
системы вроде Linux масштабируются при наличии множества потоков и множества
ядер (Boyd-Wickizer, 2010).
Одна из конкретных областей исследований относится к записи и воспроизведению
выполнения процесса (Viennot et al., 2013). Воспроизведение позволяет разработчикам
выполнять обратное отслеживание трудно обнаруживаемых ошибок, а специалистам
по безопасности — расследовать инциденты.
Аналогичным образом многие современные исследования в сообществе разработчиков
операционных систем сфокусированы на вопросах безопасности. Многочисленные
инциденты показали, что пользователи нуждаются в более надежной защите от злоумышленников
(а иногда и от самих себя). Один из подходов заключается в отслеживании
и тщательном разграничении в операционной системе информационных потоков
(Giffin et al., 2012).
Планирование (как в однопроцессорной, так и в мультипроцессорной системе) попрежнему
является темой, близкой и дорогой сердцу некоторых исследователей. Некоторые
исследованные темы затрагивают энергосберегающее планирование на мобильных
устройствах (Yuan and Nahrstedt, 2006), планирование с учетом гиперпоточности (Bulpin
and Pratt, 2005) и планирование с известным смещением (Koufaty, 2010). С увеличением
количества вычислений на недостаточно мощных, ограниченных по электропитанию
смартфонах некоторые исследователи предлагают при любом удобном случае переносить
процесс на более мощный облачный сервер (Gordon et al., 2012). Однако немногие
современные системные разработчики бесцельно слоняются целыми днями, заламывая
руки из-за отсутствия подходящего алгоритма планирования потоков, поэтому данный
тип исследований больше проталкивается самими исследователями, чем вызывается
интенсивностью спроса. В целом процессы, потоки и планирование уже не являются,
как прежде, актуальными темами исследований. Времена активных исследований уже
прошли 1 , и исследователи переключились на такие темы, как управление электропитанием,
виртуализация, облачные вычисления и безопасность.
1 Однако это совершенно не означает, что данные темы не смогут снова стать актуальными,
например из-за каких-либо значимых изобретений в аппаратном обеспечении, появления
новых структур процессоров или обнаружения каких-либо еще не рассматривавшихся
с должным уровнем детализации частных задач. — Примеч. ред.
2.7. Краткие выводы
Чтобы сгладить влияние прерываний, операционные системы предоставляют концептуальную
модель, состоящую из параллельно запускаемых последовательных процессов.
Процессы могут создаваться и уничтожаться в динамическом режиме. У каждого
процесса есть собственное адресное пространство.
Некоторым приложениям выгодно в рамках одного процесса иметь несколько потоков
управления. Эти потоки имеют независимое планирование, и каждый из них имеет
собственный стек, но все потоки, принадлежащие одному процессу, используют общее
адресное пространство. Потоки могут быть реализованы в пространстве пользователя
или в пространстве ядра.
Процессы могут взаимодействовать друг с другом, используя соответствующие примитивы,
к которым относятся семафоры, мониторы или сообщения. Эти примитивы
используют, чтобы исключить одновременное пребывание двух процессов в их критических
областях, то есть для предотвращения ситуации, приводящей к хаосу. Процесс
может находиться в работающем, готовом к работе или заблокированном состоянии
и может изменять состояние, когда он сам или другие процессы задействуют один
из примитивов взаимодействия процессов. Взаимодействие потоков имеет сходный
характер.
Примитивы взаимодействия процессов могут использоваться для решения таких задач,
как «производитель — потребитель», «обедающие философы» и «читатель — писатель».
Но даже при использовании этих примитивов нужно соблюдать особую осторожность
во избежание ошибок и взаимных блокировок.
Было изучено множество алгоритмов планирования. Некоторые из них, например
алгоритм первоочередного выполнения самого короткого задания, используются
преимущественно в пакетных системах. Другие же получили распространение как
в пакетных, так и в интерактивных системах. В числе этих алгоритмов циклическое
и приоритетное планирование, многоуровневые очереди, гарантированное, лотерейное
и справедливое планирование. Некоторые системы проводят четкую грань между
механизмом и политикой планирования, что позволяет пользователям управлять
алгоритмом планирования.
