Глава 3.
Управление памятью
Память представляет собой очень важный ресурс, требующий четкого управления.
Несмотря на то что в наши дни объем памяти среднего домашнего компьютера в десятки
тысяч раз превышает ресурсы IBM 7094, бывшего в начале 1960-х годов самым
большим компьютером в мире, размер компьютерных программ растет быстрее, чем
объем памяти. Закон Паркинсона можно перефразировать следующим образом:
«Программы увеличиваются в размерах, стремясь заполнить всю память, доступную
для их размещения». В этой главе мы рассмотрим, как операционные системы создают
из памяти абстракции и как они этими абстракциями управляют.
В идеале каждому программисту хотелось бы иметь предоставленную только ему неограниченную
по объему и скорости работы память, которая к тому же не теряет своего
содержимого при отключении питания. Раз уж мы так размечтались, то почему бы не
сделать память еще и совсем дешевой? К сожалению, существующие технологии пока
не могут дать нам желаемого. Может быть, способ создания такой памяти удастся изобрести
именно вам.
Тогда чем же нам придется довольствоваться? Со временем была разработана концепция
иерархии памяти, согласно которой компьютеры обладают несколькими
мегабайтами очень быстродействующей, дорогой и энергозависимой кэш-памяти,
несколькими гигабайтами памяти, средней как по скорости, так и по цене, а также
несколькими терабайтами памяти на довольно медленных, сравнительно дешевых
дисковых накопителях, не говоря уже о сменных накопителях, таких как
DVD и флеш-устройства USB. Превратить эту иерархию в абстракцию, то есть
в удобную модель, а затем управлять этой абстракцией — и есть задача операционной
системы.
Та часть операционной системы, которая управляет иерархией памяти (или ее частью),
называется менеджером, или диспетчером, памяти. Он предназначен для действенного
управления памятью и должен следить за тем, какие части памяти используются,
выделять память процессам, которые в ней нуждаются, и освобождать память, когда
процессы завершат свою работу.
В этой главе будут рассмотрены несколько разных моделей управления памятью,
начиная с очень простых и заканчивая весьма изощренными. Поскольку управление
кэш-памятью самого нижнего уровня обычно осуществляется на аппаратном уровне,
основное внимание будет уделено программистской модели оперативной памяти и способам
эффективного управления ее использованием. Все, что касается абстракций,
создаваемых для энергонезависимого запоминающего устройства — диска, и управления
этими абстракциями, будет темой следующей главы. Начнем с истоков и в первую
очередь рассмотрим самую простую из возможных схем, а затем постепенно будем
переходить к изучению все более сложных.
3.1. Память без использования абстракций
Простейшей абстракцией памяти можно считать полное отсутствие какой-либо абстракции.
Ранние универсальные машины (до 1960 года), ранние мини-компьютеры
(до 1970 года) и ранние персональные компьютеры (до 1980 года) не использовали
абстракции памяти. Каждая программа просто видела физическую память. Когда программа
выполняла команду
MOV REGISTER1,1000
компьютер просто перемещал содержимое физической ячейки памяти 1000
в REGISTER1. Таким образом, модель памяти, предоставляемая программисту, была
простой физической памятью, набором адресов от 0 до некоторого максимального
значения, где каждый адрес соответствовал ячейке, содержащей какое-то количество
бит (обычно 8).
При таких условиях содержание в памяти сразу двух работающих программ не представлялось
возможным. Если первая программа, к примеру, записывала новое значение
в ячейку 2000, то она тем самым стирала то значение, которое сохраняла там вторая
программа. Работа становилась невозможной, и обе программы практически сразу же
давали сбой.
Даже в условиях, когда в качестве модели памяти выступает сама физическая память,
возможны несколько вариантов использования памяти. Три из них показаны
на рис. 3.1. Операционная система может (рис. 3.1, а) размещаться в нижней части
адресов, в оперативном запоминающем устройстве (ОЗУ), или, по-другому, в памяти
с произвольным доступом — RAM (Random Access Memory). Она может размещаться
также в постоянном запоминающем устройстве (ПЗУ), или, иначе, в ROM (ReadOnly
Memory), в верхних адресах памяти (рис. 3.1, б). Или же драйверы устройств
могут быть в верхних адресах памяти, в ПЗУ, а остальная часть системы — в ОЗУ,
в самом низу (рис. 3.1, в). Первая модель прежде использовалась на универсальных
машинах и мини-компьютерах, а на других машинах — довольно редко. Вторая модель
использовалась на некоторых КПК и встроенных системах. Третья модель использовалась
на ранних персональных компьютерах (например, на тех, которые работали
под управлением MS-DOS), где часть системы, размещавшаяся в ПЗУ, называлась
базовой системой ввода-вывода — BIOS (Basic Input Output System). Недостаток
моделей, изображенных на рис. 3.1, а и в, заключается в том, что ошибка в программе
пользователя может затереть операционную систему, и, возможно, с весьма пагубными
последствиями.
Единственный способ добиться хоть какой-то параллельности в системе, не имеющей
абстракций памяти, — это запустить программу с несколькими потоками. Поскольку
предполагается, что все имеющиеся в процессе потоки видят один и тот же образ памяти,
их принудительное применение проблемы не составляет. Хотя эта идея вполне работоспособна,
она не нашла широкого применения, поскольку людям зачастую необходим
одновременный запуск не связанных друг с другом программ, а этого абстракция потоков
не обеспечивает. Более того, столь примитивные системы, не обеспечивающие абстракций
памяти, вряд ли могут предоставить абстракцию потоков.
Тем не менее даже в отсутствие абстракций памяти одновременный запуск нескольких
программ вполне возможен. Для этого операционная система должна сохранить
все содержимое памяти в файле на диске, а затем загрузить и запустить следующую
Рис. 3.1. Три простых способа организации памяти при наличии операционной системы и одного
пользовательского процесса (существуют и другие варианты). При таком устройстве системы
памяти процессы, как правило, могут запускаться только по одному. Как только пользователь наберет
команду, операционная система копирует запрошенную программу с диска в память, после
чего выполняет эту программу. Когда процесс завершает свою работу, операционная система
отображает символ приглашения и ожидает ввода новой команды. По получении команды она
загружает в память новую программу, записывая ее поверх первой программы
программу. Поскольку одновременно в памяти присутствует только одна программа,
конфликтов не возникает. Эта концепция называется заменой данных (или свопингом)
и будет рассмотрена чуть позже.
При наличии некоторого специального дополнительного оборудования появляется
возможность параллельного запуска нескольких программ даже без использования
свопинга. На ранних моделях IBM 360 эта проблема решалась следующим образом:
память делилась на блоки по 2 Кбайт, каждому из которых присваивался 4-битный
защитный ключ, содержащийся в специальных регистрах за пределами центрального
процессора. Машине с объемом памяти 1 Мбайт нужно было иметь лишь 512 таких
4-битных регистров, и все хранилище ключей занимало в итоге 256 байт памяти. Слово
состояния программы (Program Status Word (PSW)) также содержало 4-битный
ключ. Аппаратное обеспечение IBM 360 перехватывало любую попытку запущенного
процесса получить доступ к памяти с ключом защиты, отличающимся от ключа PSW.
Поскольку изменить ключи защиты могла только операционная система, пользовательские
процессы были защищены от вмешательства в работу друг друга и в работу
самой операционной системы.
Тем не менее это решение имело серьезный недостаток, показанный на рис. 3.2. Здесь
изображены две программы, каждая из которых имеет объем 16 Кбайт. Они показаны
на рис. 3.2, а и б. Первая из них закрашена, чтобы показать, что у нее иной ключ
памяти, нежели у второй. Первая программа начинается с перехода на ячейку памяти
с адресом 24, в которой содержится команда MOV. Вторая программа начинается с перехода
на ячейку памяти с адресом 28, в которой содержится команда CMP. Команды,
не имеющие отношения к рассматриваемому вопросу, на рисунке не показаны. Когда
две программы загружаются друг за другом в память, начиная с ячейки с адресом 0,
мы получаем ситуацию, показанную на рис. 3.2, в. В этом примере мы предполагаем,
что операционная система находится в верхних адресах памяти и поэтому не показана.
Рис. 3.2. Иллюстрация проблемы перемещения: а — программа объемом 16 Кбайт;
б — еще одна программа объемом 16 Кбайт; в — две программы, последовательно
загруженные в память
После загрузки программы могут быть запущены на выполнение. Поскольку у них
разные ключи памяти, ни одна из них не может навредить другой. Но проблема имеет
иную природу. При запуске первой программы будет выполнена команда JMP 24 и, как
и ожидалось, осуществлен переход к другой команде. Эта программа будет успешно
работать.
Но после того как первая программа проработает достаточно долго, операционная система
может принять решение на запуск второй программы, которая была загружена
над первой программой, начиная с адреса 16 384. Первой исполняемой командой будет
JMP 28, осуществляющая переход к команде ADD первой программы вместо того, чтобы
перейти к предполагаемой команде CMP. Скорее всего, это приведет к сбою программы
на первой же секунде.
В данном случае суть проблемы состоит в том, что обе программы ссылаются на абсолютный
адрес физической памяти, что совершенно не соответствует нашим желаниям.
Нам нужно, чтобы каждая программа ссылалась на занимаемый ею набор адресов.
Давайте вкратце рассмотрим, как это достигается. На IBM 360, например, в процессе
загрузки буквально на лету осуществлялась модификация второй программы, при этом
использовалась технология, известная как статическое перемещение. Она работала
следующим образом: когда программа загружалась с адреса 16 384, в процессе загрузки
к каждому адресу в программе прибавлялось постоянное значение 16 384 (следовательно,
инструкция «JMP 28» становилась инструкцией «JMP 16412» и т. д.). При
всей исправности работы этого механизма он был не самым универсальным решением,
и к тому же замедлял загрузку. Более того, это решение требовало дополнительной
информации обо всех исполняемых программах, сообщающей, в каких словах содержатся,
а в каких не содержатся перемещаемые адреса. В результате чего 28 на рис. 3.2, б
должно было подвергнуться перемещению, а инструкция вроде
MOV REGISTER1,28
которая помещает число 28 в REGISTER1, должна была остаться нетронутой. Нужен
был какой-нибудь способ, позволяющий сообщить загрузчику, какое из чисел относится
к адресу, а какое — к константе.
И наконец, как отмечалось в главе 1, в компьютерном мире истории свойственно
повторяться. Хотя прямая адресация физической памяти, к сожалению, осталась
в прошлом, в устаревших устройствах памяти универсальных компьютеров, миникомпьютеров,
настольных компьютеров, ноутбуков и смартфонов дефицит абстракций
памяти — вполне обычное явление во встроенных системах и смарт-картах. В наши дни
устройства вроде радиоприемников, стиральных машин и микроволновых печей заполнены
программным обеспечением (в ПЗУ), и в большинстве случаев их программы
используют адресацию к абсолютной памяти. Все это неплохо работает, поскольку все
программы известны заранее, и пользователи не могут запускать на бытовых устройствах
какие-нибудь собственные программы.
Сложные операционные системы присутствуют только в высокотехнологичных встроенных
устройствах (например, в смартфонах), а более простые устройства их не имеют.
В некоторых случаях у них тоже есть операционная система, но это всего лишь
библиотека, связанная с прикладной программой, которая предоставляет системные
вызовы для выполнения операций ввода-вывода и других общих задач. Простым примером
популярной операционной системы, представляющей собой библиотеку, может
послужить e-cos.
3.2. Абстракция памяти: адресные пространства
В конечном счете предоставление физической памяти процессам имеет ряд серьезных
недостатков. Во-первых, если пользовательские программы будут обращаться
к каждому байту памяти, они легко могут преднамеренно или случайно испортить
операционную систему, раздробить ее код и довести до остановки работы (в отсутствие
специального аппаратного обеспечения наподобие ключевых схем и блокировок на
IBM 360). Эта проблема присутствует даже при запуске всего лишь одной пользовательской
программы (приложения). Во-вторых, при использовании этой модели довольно
сложно организовать одновременную (поочередную, если имеется лишь один
центральный процессор) работу нескольких программ. На персональных компьютерах
вполне естественно наличие нескольких одновременно открытых программ (текстовый
процессор, программа электронной почты, веб-браузер), с одной из которых в данный
момент взаимодействует пользователь, а работа других возобновляется щелчком мыши.
Так как этого трудно достичь при отсутствии абстракций на основе физической памяти,
нужно что-то предпринимать.
3.2.1. Понятие адресного пространства
Чтобы допустить одновременное размещение в памяти нескольких приложений без
создания взаимных помех, нужно решить две проблемы, относящиеся к защите и перемещению.
Примитивное решение первой из этих проблем мы уже рассматривали на
3.2. Абстракция памяти: адресные пространства 219
примере IBM 360: участки памяти помечались защитным ключом, и ключ выполняемого
процесса сличался с ключом каждого выбранного слова памяти. Этот подход не
решал второй проблемы, хотя она могла быть решена путем перемещения программ
в процессе их загрузки, но это было слишком медленным и сложным решением.
Более подходящее решение — придумать для памяти новую абстракцию: адресное
пространство. Так же как понятие процесса создает своеобразный абстрактный центральный
процессор для запуска программ, понятие адресного пространства создает
своеобразную абстрактную память, в которой существуют программы. Адресное
пространство — это набор адресов, который может быть использован процессом для
обращения к памяти. У каждого процесса имеется собственное адресное пространство,
независимое от того адресного пространства, которое принадлежит другим процессам
(за исключением тех особых обстоятельств, при которых процессам требуется совместное
использование их адресных пространств).
Понятие адресного пространства имеет весьма универсальный характер и появляется
во множестве контекстов. Возьмем телефонные номера. В США и многих других
странах местный телефонный номер состоит обычно из семизначного числа. Поэтому
адресное пространство телефонных номеров простирается от 0000000 до 9999999, хотя
некоторые номера, к примеру те, что начинаются с 000, не используются. С ростом
количества смартфонов, модемов и факсов это пространство стало слишком тесным,
а в этом случае необходимо использовать больше цифр. Адресное пространство портов
ввода-вывода процессора x86 простирается от 0 до 16 383. Протокол IPv4 обращается
к 32-разрядным номерам, поэтому его адресное пространство простирается от 0 до
2 32 − 1 (опять-таки с некоторым количеством зарезервированных номеров).
Адресное пространство не обязательно должно быть числовым. Набор интернет-доменов
 .com также является адресным пространством. Это адресное пространство состоит
из всех строк длиной от 2 до 63 символов, которые могут быть составлены из букв,
цифр и дефисов, за которыми следует название домена —  .com . Теперь вам должна
стать понятной сама идея, в которой нет ничего сложного.
Немного сложнее понять, как каждой программе можно выделить собственное адресное
пространство, поскольку адрес 28 в одной программе означает иное физическое место,
чем адрес 28 в другой программе. Далее мы рассмотрим простой способ, который ранее
был распространен, но вышел из употребления с появлением возможностей размещения
на современных центральных процессорах более сложных (и более совершенных)
схем.
Базовый и ограничительный регистры
В простом решении используется весьма примитивная версия динамического перераспределения
памяти. При этом адресное пространство каждого процесса просто
проецируется на различные части физической памяти. Классическое решение, примененное
на машинах от CDC 6600 (первого в мире суперкомпьютера) до Intel 8088
(сердца первой модели IBM PC), заключается в оснащении каждого центрального
процессора двумя специальными аппаратными регистрами, которые обычно называются
базовым и ограничительным регистрами. При использовании этих регистров
программы загружаются в последовательно расположенные свободные области памяти
без модификации адресов в процессе загрузки (см. рис. 3.2, в). При запуске процесса
в базовый регистр загружается физический адрес, с которого начинается размещение
программы в памяти, а в ограничительный регистр загружается длина программы. На
рис. 3.2, в при запуске первой программы базовыми и ограничительными значениями,
загружаемыми в эти аппаратные регистры, будут соответственно 0 и 16 384. При запуске
второй программы будут использованы значения 16 384 и 32 768 соответственно.
Если непосредственно над второй будет загружена и запущена третья программа,
имеющая объем 16 Кбайт, значениями базового и ограничительного регистров будут
32 768 и 16 384 соответственно.
При каждой ссылке процесса на память с целью извлечения команды или записи слова
данных аппаратура центрального процессора перед выставлением адреса на шине
памяти добавляет к адресу, сгенерированному процессом, значение базового регистра.
Одновременно аппаратура проверяет, не равен ли предлагаемый адрес значению ограничительного
регистра или не превышает ли он это значение (в этом случае генерируется
отказ и доступ прерывается). Если взять первую команду второй программы (см.
рис. 3.2, в), то процесс выполняет команду
JMP 28
но аппаратура рассматривает ее как команду
JMP 16412
поэтому переход осуществляется, как и ожидалось, на команду CMP. Значения базовых
и ограничительных регистров при выполнении второй программы на рис. 3.2, в
показаны на рис. 3.3.
Рис. 3.3. Для предоставления каждому процессу отдельного адресного пространства
могут использоваться базовый и ограничительный регистры
Использование базового и ограничительного регистров — это простой способ предоставления
каждому процессу собственного закрытого адресного пространства, поскольку
3.2. Абстракция памяти: адресные пространства 221
перед обращением к памяти к каждому автоматически сгенерированному адресу добавляется
значение базового регистра. Многие реализации предусматривают такую защиту
базового и ограничительного регистров, при которой изменить их значения может только
операционная система. Именно так был устроен компьютер CDC 6600, в отличие от компьютеров
на основе Intel 8088, у которых не было даже ограничительного регистра. Но
у последних было несколько базовых регистров, позволяющих, к примеру, реализовать
независимое перемещение текста и данных программы, но не предлагающих какой-либо
защиты от ссылок за пределы выделенной памяти.
Недостатком перемещений с использованием базовых и ограничительных регистров
является необходимость применения операций сложения и сравнения к каждой ссылке
на ячейку памяти. Сравнение может осуществляться довольно быстро, но сложение
является слишком медленной операцией из-за затрат времени на вспомогательный
сигнал переноса, если, конечно, не используются специальные сумматоры.
3.2.2. Свопинг
Если у компьютера объем памяти достаточен для размещения всех процессов, то все
рассмотренные до сих пор схемы будут в той или иной степени работоспособны. Но на
практике суммарный объем оперативной памяти, необходимый для размещения всех
процессов, зачастую значительно превышает имеющийся объем ОЗУ. На обычных
Windows-, OS X- или Linux-системах при запуске компьютера могут быть запущены
50–100 или более процессов. Например, при установке приложения Windows зачастую
выдаются команды, чтобы при последующих запусках системы запускался процесс,
единственной задачей которого была бы проверка наличия обновлений для этого приложения.
Такой процесс запросто может занять 5–10 Мбайт памяти. Остальные фоновые
процессы проверяют наличие входящей почты, входящих сетевых подключений
и многое другое. И все это еще до того, как будет запущена первая пользовательская
программа. Современные солидные пользовательские прикладные программы вроде
Photoshop могут запросто требовать просто для запуска 500 Мбайт памяти, а при начале
обработки данных занимать множество гигабайт. Следовательно, постоянное
содержание всех процессов в памяти требует огромных объемов и не может быть осуществлено
при дефиците памяти.
С годами для преодоления перегрузки памяти были выработаны два основных подхода.
Самый простой из них, называемый свопингом, заключается в размещении
в памяти всего процесса целиком, его запуске на некоторое время, а затем сбросе на
диск. Бездействующие процессы большую часть времени хранятся на диске и в нерабочем
состоянии не занимают пространство оперативной памяти (хотя некоторые
из них периодически активизируются, чтобы проделать свою работу, после чего опять
приостанавливаются). Второй подход называется виртуальной памятью, он позволяет
программам запускаться даже в том случае, если они находятся в оперативной памяти
лишь частично. Далее в этом разделе мы рассмотрим свопинг, а в последующих разделах
будет рассмотрена и виртуальная память.
Работа системы с использованием свопинга показана на рис. 3.4. Изначально в памяти
присутствует только процесс A. Затем создаются или появляются в памяти путем
свопинга с диска процессы B и C. На рис. 3.4, г процесс A за счет свопинга выгружается
на диск. Затем появляется процесс D и выгружается из памяти процесс B. И наконец,
снова появляется в памяти процесс A. Поскольку теперь процесс A находится в другом
месте, содержащиеся в нем адреса должны быть перестроены либо программным путем,
при загрузке в процессе свопинга, либо (скорее всего) аппаратным путем в процессе
выполнения программы. К примеру, для этого случая хорошо подойдут механизмы
базового и ограничительного регистров.
Рис. 3.4. Изменения в выделении памяти по мере появления процессов в памяти
и выгрузки их из нее (неиспользованные области памяти заштрихованы)
Когда в результате свопинга в памяти создаются несколько свободных областей, их
можно объединить в одну большую за счет перемещения при первой же возможности
всех процессов в нижние адреса. Эта технология известна как уплотнение памяти. Но
зачастую она не выполняется, поскольку отнимает довольно много процессорного
времени. К примеру, на машине, оснащенной 16 Гбайт памяти, способной скопировать
8 байт за 8 нс, на уплотнение всего объема памяти может уйти около 16 с.
Стоит побеспокоиться о том, какой объем памяти нужно выделить процессу при его
создании или загрузке в процессе свопинга. Если создаваемый процесс имеет вполне
3.2. Абстракция памяти: адресные пространства 223
определенный неизменный объем, то выделение упрощается: операционная система
предоставляет процессу строго необходимый объем памяти, ни больше ни меньше.
Но если сегмент данных процесса может разрастаться, к примеру, за счет динамического
распределения памяти, как во многих языках программирования, то каждая
попытка разрастания процесса вызывает проблему. Если к выделенному пространству
памяти примыкает свободное место, то оно может быть распределено процессу и он
сможет расширяться в пределах этого свободного пространства. В то же время, если
память, выделенная процессу, примыкает к памяти другого процесса, то либо разрастающийся
процесс должен быть перемещен на свободное пространство памяти,
достаточное для его размещения, либо один или более процессов сброшены на диск
путем свопинга, чтобы образовалось достаточно свободного пространства. Если процесс
не может разрастаться в памяти и область свопинга на диске уже заполнена, то
процессу придется приостановить свою работу до тех пор, пока не освободится некоторое
пространство памяти (или же этот процесс может быть уничтожен).
Если предполагается, что большинство процессов по мере выполнения будут разрастаться,
то, наверное, будет лучше распределять небольшой объем дополнительной
памяти при каждой загрузке из области свопинга на диске в память или перемещении
процесса, чтобы сократить потери, связанные со свопингом или перемещением процессов,
которые больше не помещаются в отведенной им памяти. Но свопингу на диск
должна подвергаться только реально задействованная память, копировать при этом
еще и дополнительно выделенную память будет слишком расточительно. На рис. 3.5, а
показана конфигурация памяти, в которой пространства для разрастания были выделены
двум процессам.
Рис. 3.5. Выделение памяти: а — под разрастающийся сегмент данных;
б — под разрастающийся стек и сегмент данных
Если процессы могут иметь два разрастающихся сегмента, к примеру сегмент данных,
используемый в качестве динамически выделяемой и освобождаемой памяти для переменных,
и сегмент стека для обычных локальных переменных и адресов возврата, то
предлагается альтернативная структура распределения памяти (рис. 3.5, б). На этом
рисунке видно, что у каждого изображенного процесса в верхних адресах выделенной
ему памяти имеется стек, растущий вниз, и сразу над текстом программы — сегмент
данных, растущий вверх. Разделяющая их память может использоваться обоими сегментами.
Если она иссякнет, процесс должен быть перемещен в свободное пространство
достаточного размера (или же перемещен из памяти в область свопинга) до тех пор,
пока не будет создано достаточное по размеру свободное пространство, либо он должен
быть уничтожен.
3.2.3. Управление свободной памятью
Если память распределяется в динамическом режиме, то управлять этим должна операционная
система. В общих чертах, существуют два способа отслеживания использования
памяти: битовые матрицы и списки свободного пространства. Мы рассмотрим
эти два метода в этом и следующем разделах. В главе 10 распределители памяти buddy
и slab, используемые в Linux, будут рассмотрены более подробно.
Управление памятью с помощью битовых матриц
При использовании битовых матриц память делится на единичные блоки размером от
нескольких слов до нескольких килобайт. С каждым единичным блоком соотносится
один бит в битовой матрице, который содержит 0, если единичный блок свободен, и 1,
если он занят (или наоборот). На рис. 3.6 показаны часть памяти и соответствующая
ей битовая матрица.
Важным вопросом для разработчика является размер единичного блока памяти. Чем
меньше блок, тем больше битовая матрица. Но даже с таким небольшим единичным
блоком памяти, размер которого равен 4 байта, для 32 бит памяти понадобится 1 бит
матрицы. Память, состоящая из 32n бит, будет использовать n бит матрицы, таким
Рис. 3.6. Часть памяти с пятью процессами и тремя свободными пространствами, единичные
блоки памяти разделены вертикальными штрихами: а — заштрихованные области
(которым соответствует 0 в битовой матрице) являются свободными; б — соответствующая
битовая матрица; в — та же самая информация в виде списка
3.2. Абстракция памяти: адресные пространства 225
образом, битовая матрица займет лишь 1/32 памяти. Если выбран более объемный
единичный блок памяти, битовая матрица будет меньше, но тогда в последнем блоке
процесса, если он не будет в точности кратен размеру единичного блока, будет впустую
теряться довольно существенный объем памяти.
Битовая матрица предоставляет довольно простой способ отслеживания слов памяти
в фиксированном объеме памяти, поскольку ее размер зависит только от размера памяти
и размера единичного блока памяти. Основная проблема заключается в том, что
при решении поместить в память процесс, занимающий k единичных блоков, диспетчер
памяти должен искать в битовой матрице непрерывную последовательность нулевых
битов. Поиск в битовой матрице последовательности заданной длины — довольно медленная
операция (поскольку последовательность может пересекать границы слов в матрице),
и это обстоятельство служит аргументом против применения битовых матриц.
Управление памятью с помощью связанных списков
Другим способом отслеживания памяти является ведение связанных списков распределенных
и свободных сегментов памяти, где сегмент либо содержит процесс,
либо является пустым пространством между двумя процессами. Участок памяти, изображенный
на рис. 3.6, а, представлен на рис. 3.6, в, как связанный список сегментов.
Каждая запись в списке хранит обозначение, содержит сегмент «дыру» — hole (H) или
процесс — process (P), адрес, с которого сегмент начинается, его длину и указатель на
следующую запись.
В этом примере список сегментов составлен отсортированным по адресам. Преимущество
такой сортировки заключается в том, что при завершении процесса или его
свопинге на диск упрощается обновление списка. У завершившегося процесса есть,
как правило, два соседа (за исключением тех случаев, когда он находился в верхних
или нижних адресах памяти). Этими соседями могут быть либо процессы, либо пустые
пространства, из чего можно составить четыре комбинации, показанные на рис. 3.7.
На рис. 3.7, а обновление списка требует замены P на H. На рис. 3.7, б и в две записи
объединяются в одну, и список становится на одну запись короче. На рис. 3.7, г объединяются
три записи, и из списка удаляются уже две записи.
Поскольку запись в таблице процессов, относящаяся к завершающемуся процессу, будет,
как правило, указывать на запись в списке именно для этого процесса, возможно,
удобнее будет вести не односвязный список, как показано на рис. 3.6, в, а двусвязный
список. Такая структура облегчит поиск предыдущей записи и определение возможности
объединения.
Рис. 3.7. Четыре комбинации соседей для завершающегося процесса X
Когда процессы и пустые пространства содержатся в списке отсортированными по
адресам, то для выделения памяти создаваемому процессу (или существующему
процессу, загружаемому в результате свопинга с диска) могут быть использованы
несколько алгоритмов. Предположим, что диспетчер памяти знает, сколько памяти
нужно выделить. Простейший алгоритм называется «первое подходящее». Диспетчер
памяти сканирует список сегментов до тех пор, пока не найдет пустое пространство
подходящего размера. Затем пустое пространство разбивается на две части: одна для
процесса и одна для неиспользуемой памяти, за исключением того статистически
маловероятного случая, когда процесс в точности помещается в пус тое пространство.
«Первое подходящее» — это быстрый алгоритм, поскольку поиск ведется с наименьшими
затратами времени.
Незначительной вариацией алгоритма «первое подходящее» является алгоритм «следующее
подходящее». Он работает так же, как и «первое подходящее», за исключением
того, что отслеживает свое местоположение, как только находит подходящее пустое
пространство. При следующем вызове для поиска пустого пространства он начинает
поиск в списке с того места, на котором остановился в прошлый раз, а не приступает
к поиску с самого начала, как при работе алгоритма «первое подходящее». Моделирование
работы алгоритма «следующее подходящее», выполненное Бэйсом (Bays,
1977), показало, что его производительность несколько хуже, чем алгоритма «первое
подходящее».
Другой хорошо известный и широко используемый алгоритм — «наиболее подходящее».
При нем поиск ведется по всему списку, от начала до конца, и выбирается наименьшее
соответствующее пустое пространство. Вместо того чтобы разбивать большое
пустое пространство, которое может пригодиться чуть позже, алгоритм «наиболее
подходящее» пытается подыскать пустое пространство, близкое по размеру к необходимому,
чтобы наилучшим образом соответствовать запросу и имеющимся пустым
пространствам.
В качестве примера алгоритмов «первое подходящее» и «наиболее подходящее» вернемся
к рис. 3.6. Если необходимо пространство в два единичных блока, то, согласно
алгоритму «первое подходящее», будет выделено пустое пространство, начинающееся
с адреса 5, а согласно алгоритму «наиболее подходящее», будет выделено пустое пространство,
начинающееся с адреса 18.
Алгоритм «наиболее подходящее» работает медленнее, чем «первое подходящее», поскольку
при каждом вызове он должен вести поиск по всему списку. Как ни странно,
но его применение приводит к более расточительному использованию памяти, чем использование
алгоритмов «первое подходящее» и «следующее подходящее», поскольку
он стремится заполнить память, оставляя небольшие бесполезные пустые пространства.
В среднем при использовании алгоритма «первое подходящее» образуются более протяженные
пустые пространства.
При попытке обойти проблему разбиения практически точно подходящих пространств
памяти на память, отводимую под процесс, и небольшие пустые пространства можно
прийти к идее алгоритма «наименее подходящее», то есть к неизменному выбору самого
большого подходящего пустого пространства, чтобы вновь образующееся пустое
пространство было достаточно большим для дальнейшего использования. Моделирование
показало, что применение алгоритма «наименее подходящее» также далеко не
самая лучшая идея.
Работа всех четырех алгоритмов может быть ускорена за счет ведения отдельных
списков для процессов и пустых пространств. При этом все усилия этих алгоритмов
сосредоточиваются на просмотре списков пустых пространств, а не списков процессов.
Неизбежной ценой за это ускорение распределения памяти становится дополнительное
усложнение и замедление процедуры ее освобождения, поскольку освободившийся сегмент
должен быть удален из списка процессов и внесен в список пустых пространств.
Если для процессов и пустых пространств ведутся разные списки, то для более быстрого
обнаружения наиболее подходящих свободных мест список пустых пространств
должен сортироваться по размеру. Когда при работе алгоритма «наиболее подходящее»
поиск пустых пространств ведется от самых маленьких до самых больших, то при обнаружении
подходящего пространства становится понятно, что найденное пространство
является наименьшим, в котором может быть выполнено задание, следовательно, оно
и есть наиболее подходящее. Дальнейший поиск, как при системе, использующей один
список, уже не потребуется. При использовании списка пустых пространств, отсортированного
по размеру, алгоритмы «первое подходящее» и «наиболее подходящее»
работают с одинаковой скоростью, а алгоритм «следующее подходящее» теряет смысл.
Когда список пустых пространств ведется отдельно от списка процессов, можно провести
небольшую оптимизацию. Вместо того чтобы создавать отдельный набор структур
данных для обслуживания списка пустых пространств, как это сделано на рис. 3.6, в,
можно хранить информацию в самих пустых пространствах. В первом слове каждого
пустого пространства может содержаться размер этого пространства, а второе слово
может служить указателем на следующую запись. Элементы списка, показанного на
рис. 3.6, в, для которых требуются три слова и один бит (P/H), больше не нужны.
Еще один алгоритм распределения памяти называется «быстро искомое подходящее».
Его использование предусматривает ведение отдельных списков для некоторых наиболее
востребованных искомых размеров. К примеру, у него может быть таблица из
n записей, в которой первая запись является указателем на вершину списка пустых
пространств размером 4 Кбайт, вторая — указателем на список пустых пространств размером
8 Кбайт, третья — указателем на список пустых пространств размером 12 Кбайт
и т. д. Пустые пространства размером, скажем, 21 Кбайт могут быть помещены либо
в список пустых пространств размером 20 Кбайт, либо в специальный список пустых
пространств с нечетным размером.
При использовании алгоритма «быстро искомое подходящее» поиск пустого пространства
требуемого размера выполняется исключительно быстро, но в нем имеется
недостаток, присущий всем системам, сортирующим пустые пространства по размеру,
а именно когда процесс завершается или выгружается процедурой свопинга, слишком
много времени тратится на то, чтобы определить, можно ли высвобождаемое пространство
объединить с соседними. Если не проводить объединение, то память очень быстро
окажется разбитой на большое количество небольших по размеру пустых фрагментов,
в которых не смогут поместиться процессы.
3.3. Виртуальная память
В то время как для создания абстракции адресного пространства могут быть использованы
базовые и ограничительные регистры, нужно решить еще одну проблему:
управления ресурсоемким программным обеспечением. Несмотря на быстрый рост
объемов памяти, объемы, требующиеся программному обеспечению, растут намного
быстрее. В 1980-е годы многие университеты работали на машинах VAX, имеющих память
объемом 4 Мбайт, под управлением систем с разделением времени, которые одновременно
обслуживали с десяток (более или менее удовлетворенных) пользователей.
Теперь корпорация Microsoft рекомендует использовать как минимум 2 Гбайт памяти
для 64-разрядной Windows 8. Тенденция к использованию мультимедиа предъявляет
к объему памяти еще более весомые требования.
Последствия такого развития выразились в необходимости запуска программ, объем
которых не позволяет им поместиться в памяти, при этом конечно же возникает потребность
в системах, поддерживающих несколько одновременно запущенных программ,
каждая из которых помещается в памяти, но все вместе они превышают имеющийся
объем памяти. Свопинг — не слишком привлекательный выбор, поскольку обычный
диск с интерфейсом SATA обладает пиковой скоростью передачи данных в несколько
сотен мегабайт в секунду, а это означает, что свопинг программы объемом 1 Гбайт
займет секунды, и еще столько же времени будет потрачено на загрузку другой программы
в 1 Гбайт.
Проблемы программ, превышающих по объему размер имеющейся памяти, возникли
еще на заре компьютерной эры, правда, проявились они в таких узких областях, как
решение научных и прикладных задач (существенные объемы памяти требуются
для моделирования возникновения Вселенной или даже для авиасимулятора нового
самолета). В 1960-е годы было принято решение разбивать программы на небольшие
части, называемые оверлеями. При запуске программы в память загружался только
администратор оверлейной загрузки, который тут же загружал и запускал оверлей
с порядковым номером 0. Когда этот оверлей завершал свою работу, он мог сообщить
администратору загрузки оверлеев о необходимости загрузки оверлея 1 либо выше
оверлея 0, находящегося в памяти (если для него было достаточно пространства), либо
поверх оверлея 0 (если памяти не хватало). Некоторые оверлейные системы имели довольно
сложное устройство, позволяя множеству оверлеев одновременно находиться
в памяти. Оверлеи хранились на диске, и их свопинг с диска в память и обратно осуществлялся
администратором загрузки оверлеев.
Хотя сама работа по свопингу оверлеев с диска в память и обратно выполнялась
операционной системой, разбиение программ на части выполнялось программистом
в ручном режиме. Разбиение больших программ на небольшие модульные части было
очень трудоемкой, скучной и не застрахованной от ошибок работой. Преуспеть в этом
деле удавалось далеко не всем программистам. Прошло не так много времени, и был
придуман способ, позволяющий возложить эту работу на компьютер.
Изобретенный метод (Fotheringham, 1961) стал известен как виртуальная память.
В основе виртуальной памяти лежит идея, что у каждой программы имеется собственное
адресное пространство, которое разбивается на участки, называемые страницами.
Каждая страница представляет собой непрерывный диапазон адресов. Эти страницы
отображаются на физическую память, но для запуска программы одновременное присутствие
в памяти всех страниц необязательно. Когда программа ссылается на часть
своего адресного пространства, находящегося в физической памяти, аппаратное обеспечение
осуществляет необходимое отображение на лету. Когда программа ссылается
на часть своего адресного пространства, которое не находится в физической памяти,
операционная система предупреждается о том, что необходимо получить недостающую
часть и повторно выполнить потерпевшую неудачу команду.
В некотором смысле виртуальная память является обобщением идеи базового и ограничительного
регистров. У процессора 8088 было несколько отдельных базовых регистров
(но не было ограничительных регистров) для текста и данных программы. При
использовании виртуальной памяти вместо отдельного перемещения только сегмента
текста или только сегмента данных программы на физическую память в сравнительно
небольших блоках может быть отображено все адресное пространство. Реализация
виртуальной памяти будет показана далее.
Виртуальная память неплохо работает и в многозадачных системах, когда в памяти
одновременно содержатся составные части многих программ. Пока программа ждет
считывания какой-либо собственной части, центральный процессор может быть отдан
другому процессу.
3.3.1. Страничная организация памяти
Большинство систем виртуальной памяти используют технологию под названием страничная
организация памяти (paging), к описанию которой мы сейчас и приступим. На
любом компьютере программы ссылаются на набор адресов памяти. Когда программа
выполняет команду
MOV REG,1000
она осуществляет копирование содержимого ячейки памяти с адресом 1000 в REG
(или наоборот, в зависимости от компьютера). Адреса могут генерироваться с использованием
индексной адресации, базовых регистров, сегментных регистров и другими
способами.
Такие сгенерированные программным способом адреса называются виртуальными
адресами, именно они и формируют виртуальное адресное пространство. На компьютерах,
не использующих виртуальную память, виртуальные адреса выставляются
непосредственно на шине памяти, что приводит к чтению или записи слова физической
памяти с таким же адресом. При использовании виртуальной памяти виртуальные
адреса не выставляются напрямую на шине памяти. Вместо этого они поступают в диспетчер
памяти (Memory Management Unit (MMU)), который отображает виртуальные
адреса на адреса физической памяти (рис. 3.8).
Очень простой пример работы такого отображения показан на рис. 3.9. В этом примере
у нас есть компьютер, генерирующий 16-разрядные адреса, от 0 и до 64K – 1. Это
виртуальные адреса. Но у этого компьютера есть только 32 Кбайт физической памяти.
И хотя для него можно написать программы объемом 64 Кбайт, целиком загрузить
в память и запустить такие программы не представляется возможным. Но полный дубликат
содержимого памяти всей программы, вплоть до 64 Кбайт, может размещаться
на диске, позволяя вводить ее по частям по мере надобности.
Виртуальное адресное пространство состоит из блоков фиксированного размера, называемых
страницами. Соответствующие блоки в физической памяти называются
страничными блоками. Страницы и страничные блоки имеют, как правило, одинаковые
размеры. В нашем примере их размер составляет 4 Кбайт, но в реальных системах
используются размеры страниц от 512 байт до 1 Гбайт. При наличии 64 Кбайт
виртуального адресного пространства и 32 Кбайт физической памяти мы получаем
16 виртуальных страниц и 8 страничных блоков. Перенос информации между оперативной
памятью и диском всегда осуществляется целыми страницами. Многие
Рис. 3.8. Расположение и предназначение диспетчера памяти. Здесь он показан в составе
микросхемы центрального процессора, как это чаще всего и бывает в наши дни. Но логически
он может размещаться и в отдельной микросхеме, как было в прошлом
процессоры поддерживают несколько размеров страниц, которые могут быть смешаны
и подобраны по усмотрению операционной системы. Например, архитектура x86-64
поддерживает страницы размером 4 Кбайт, 2 Мбайт и 1 Гбайт, поэтому для пользовательских
приложений можно использовать страницы размером 4 Кбайт, а для ядра —
одну страницу размером 1 Гбайт. Почему иногда лучше использовать одну большую
страницу, а не много маленьких, будет объяснено позже.
На рис. 3.9 приняты следующие обозначения. Диапазон, помеченный 0K–4K, означает,
что виртуальные или физические адреса этой страницы составляют от 0 до 4095. Диапазон
4K–8K ссылается на адреса от 4096 до 8191 и т. д. Каждая страница содержит
строго 4096 адресов, которые начинаются с чисел, кратных 4096, и заканчиваются
числами на единицу меньше чисел, кратных 4096.
К примеру, когда программа пытается получить доступ к адресу 0, используя команду
MOV REG,0
диспетчеру памяти посылается виртуальный адрес 0. Диспетчер видит, что этот виртуальный
адрес попадает в страницу 0 (от 0 до 4095), которая в соответствии со своим
отображением представлена страничным блоком 2 (от 8192 до 12 287). Соответственно,
он трансформируется в адрес 8192, который и выставляется на шину. Память вообще
не знает о существовании диспетчера и видит только запрос на чтение или запись по
адресу 8192, который и выполняет. Таким образом диспетчер памяти эффективно
справляется с отображением всех виртуальных адресов между 0 и 4095 на физические
адреса от 8192 до 12 287.
Аналогично этому команда
MOV REG,8192
эффективно преобразуется в
MOV REG,24576
поскольку виртуальный адрес 8192 (в виртуальной странице 2) отображается на
24 576 (в физической странице 6). В качестве третьего примера виртуальный адрес
20 500 отстоит на 20 байт от начала виртуальной страницы 5 (виртуальные адреса от
20 480 до 24 575) и отображается на физический адрес 12 288 + 20 = 12 308.
Рис. 3.9. Связь между виртуальными адресами и адресами физической памяти, получаемая
с помощью таблицы страниц. Каждая страница начинается с адресов, кратных 4096,
и завершается на 4095 адресов выше, поэтому 4K–8K на самом деле означает
4096–8191, а 8K–12K означает 8192–12 287
Сама по себе возможность отображения 16 виртуальных страниц на 8 страничных
блоков за счет соответствующей настройки таблиц диспетчера памяти не решает проблемы
превышения объема виртуальной памяти над объемом физической памяти.
Поскольку в нашем распоряжении только 8 физических страничных блоков, то на
физическую память могут отображаться только 8 виртуальных страниц (рис. 3.9).
Остальные, отмеченные на рисунке крестиками, в число отображаемых не попадают.
Реальное оборудование отслеживает присутствие конкретных страниц в физической
памяти за счет бита присутствия-отсутствия.
А что происходит, если, к примеру, программа ссылается на неотображаемые адреса
с помощью команды
MOV REG,32780
которая обращается к байту 12 внутри виртуальной страницы 8 (которая начинается
с адреса 32 768)? Диспетчер памяти замечает, что страница не отображена (поскольку
она на рисунке помечена крестиком), и заставляет центральный процессор передать
управление операционной системе. Это системное прерывание называется ошибкой
отсутствия страницы (page fault). Операционная система выбирает редко используемый
страничный блок и сбрасывает его содержимое на диск (если оно еще не там).
Затем она извлекает (также с диска) страницу, на которую была ссылка, и помещает ее
в только что освободившийся страничный блок, вносит изменения в таблицы и заново
запускает прерванную команду.
К примеру, если операционная система решит выселить содержимое страничного блока
1, она загрузит виртуальную страницу 8 начиная с физического адреса 4096 и внесет
два изменения в карту диспетчера памяти. Сначала в запись о виртуальной странице 1
будет внесена пометка о том, что эта страница не отображена, чтобы при любом будущем
обращении к виртуальным адресам в диапазоне от 4096 до 8191 вызывалось системное
прерывание. Затем крестик в записи, относящейся к виртуальной странице 8, будет изменен
на цифру 1, поэтому при повторном выполнении прерванной команды произойдет
отображение виртуального адреса 32 780 на физический адрес 4108 (4096 + 12).
Теперь рассмотрим внутреннее устройство диспетчера памяти, чтобы понять, как он
работает и почему мы выбрали размер страницы, кратный степени числа 2. На рис. 3.10
показан пример виртуального адреса 8196 (0010000000000100 в двоичной записи),
отображенного с использованием карты диспетчера памяти с рис. 3.9. Входящий
16-разрядный виртуальный адрес делится на 4-битный номер страницы и 12-битное
смещение. Выделяя 4 бита под номер страницы, мы можем иметь 16 страниц, а с 12 битами
под смещение можем адресовать все 4096 байт внутри страницы.
Номер страницы используется в качестве индекса внутри таблицы страниц для получения
номера страничного блока, соответствующего виртуальной странице. Если бит
Рис. 3.10. Преобразование диспетчером памяти виртуального адреса в физический
для 16 страниц по 4 Кбайт
присутствия-отсутствия установлен в 0, то вызывается системное прерывание. Если
бит установлен в 1, из таблицы страниц берется номер страничного блока, который
копируется в старшие 3 бита выходного регистра вместе с 12-битным смещением,
которое копируется в неизменном виде из входящего виртуального адреса. Вместе
они формируют 15-разрядный физический адрес. Затем значение выходного регистра
выставляется на шине памяти в качестве физического адреса.
3.3.2. Таблицы страниц
При простой реализации отображение виртуальных адресов на физические может быть
сведено к следующему: виртуальный адрес делится на номер виртуальной страницы
(старшие биты) и смещение (младшие биты). К примеру, при 16-разрядной адресации
и размере страниц 4 Кбайт старшие 4 бита могут определять одну из 16 виртуальных
страниц, а младшие 12 бит — смещение в байтах (от 0 до 4095) внутри выбранной
страницы. Но для страницы также можно выделить 3, или 5, или какое-нибудь другое
количество битов. Различные варианты выделения подразумевают различные размеры
страниц.
Номер виртуальной страницы используется в качестве индекса внутри таблицы страниц,
который нужен для поиска записи для этой виртуальной страницы. Из записи
в таблице страниц берется номер страничного блока (если таковой имеется). Номер
страничного блока присоединяется к старшим битам смещения, заменяя собой номер
виртуальной страницы, чтобы сформировать физический адрес, который может быть
послан к памяти.
Таким образом, предназначение таблицы страниц заключается в отображении виртуальных
страниц на страничные блоки. С математической точки зрения таблица страниц —
это функция, в которой в качестве аргумента выступает номер виртуальной страницы,
а результатом является номер физического блока. При использовании результата этой
функции поле виртуальной страницы в виртуальном адресе можно заменить полем
страничного блока, формируя таким образом адрес физической памяти.
В данной главе нас интересует только виртуальная память, а не полная виртуализация.
Иными словами, нам пока не до виртуальных машин. В главе 7 будет показано, что
каждая виртуальная машина требует собственной виртуальной памяти, а в результате
организация таблицы страниц становится гораздо сложнее, при этом привлекаются
теневые или вложенные таблицы страниц, и не только это. Но как мы увидим далее,
даже без таких загадочных конфигураций подкачка и виртуальная память остаются
довольно сложными технологиями.
Структура записи в таблице страниц
Давайте перейдем от общего рассмотрения структуры таблицы страниц к подробностям
отдельной записи в этой таблице. Точный формат записи сильно зависит от конструкции
машины, но вид присутствующей в ней информации примерно одинаков для всех
машин. На рис. 3.11 показан пример записи в таблице страниц. Размер варьируется от
компьютера к компьютеру, но обычно он составляет 32 бита. Наиболее важным является
поле номера страничного блока (Page frame number). В конечном счете цель страничного
отображения и состоит в выдаче этого значения. Следующим по значимости является
бит присутствия-отсутствия. Если он установлен в 1, запись имеет смысл и может быть
использована. А если он установлен в 0, то виртуальная страница, которой принадлежит
эта запись, в данный момент в памяти отсутствует. Обращение к записи таблицы страниц,
у которой этот бит установлен в 0, вызывает ошибку отсутствия страницы.
Биты защиты сообщают о том, какого рода доступ разрешен. В простейшей форме это
поле состоит из 1 бита со значением 0 для чтения-записи и значением 1 только для
чтения. При более сложном устройстве имеется 3 бита, по одному для разрешения
чтения, записи и исполнения страницы.
Биты модификации и ссылки отслеживают режим использования страницы. Когда
в страницу осуществляется запись, аппаратура автоматически устанавливает бит модификации.
Этот бит имеет значение, когда операционная система решает регенерировать
страничный блок. Если содержащаяся в нем страница подвергалась модификации (то
есть является измененной), ее нужно сбросить обратно на диск. Если же она не подвергалась
модификации (то есть является неизмененной), от нее можно отказаться,
поскольку ее дисковая копия не утратила актуальности. Этот бит иногда называется
битом изменения, поскольку он отражает состояние страницы.
Рис. 3.11. Типичная запись таблицы страниц
Бит ссылки устанавливается при обращении к странице как для чтения, так и для записи.
Он призван помочь операционной системе выбрать выселяемую страницу при возникновении
ошибки отсутствия страницы. Страницы, к которым не было обращений,
являются более предпочтительными кандидатами, чем востребуемые, и этот бит играет
важную роль в ряде алгоритмов замещения страниц, которые будут рассмотрены далее
в этой главе.
И наконец, оставшийся бит позволяет блокировать кэширование страницы. Эта возможность
актуальна для тех страниц, которые отображаются на регистры устройств,
а не на память. Если операционная система вошла в цикл ожидания отклика какогонибудь
устройства ввода-вывода на только что выданную ею команду, очень важно,
чтобы аппаратура продолжала извлечение слова из устройства, а не использовала старую
копию, попавшую в кэш. Благодаря этому биту кэширование может быть отключено. Те
машины, у которых есть отдельное пространство ввода-вывода и которые не используют
ввод-вывод с отображением данного пространства в память, в этом бите не нуждаются.
Заметьте, что адрес на диске, который используется для хранения страницы, в таблице
страниц не фигурирует. Причина проста. В таблице страниц содержится только
та информация, которая нужна оборудованию, чтобы перевести виртуальный адрес
в физический. Информация, необходимая операционной системе для обработки ошибки
отсутствия страницы, содержится в таблицах программного обеспечения внутри
операционной системы. Оборудование в них не нуждается.
Перед более глубоким погружением в вопросы реализации стоит еще раз отметить, что
в принципе виртуальная память создает новую абстракцию — адресное пространство,
которое является абстракцией физической памяти точно так же, как процесс является
абстракцией физического процессора (ЦПУ). Виртуальная память может быть реализована
за счет разбиения виртуального адресного пространства на страницы и отображения
каждой страницы на какой-нибудь страничный блок физической памяти
или содержания ее (временно) в неотображенном состоянии. Поэтому в этой главе
речь идет в основном об абстракции, созданной операционной системой, и о том, как
эта абстракция управляется.
3.3.3. Ускорение работы страничной организации памяти
После того как мы рассмотрели основы виртуальной памяти и страничной организации,
настало время углубиться в подробности возможных вариантов реализации.
В любой системе со страничной организацией памяти необходимо рассмотреть два
основных вопроса.
1. Отображение виртуального адреса на физический должно быть быстрым.
2. Если пространство виртуальных адресов слишком обширное, таблица страниц
будет иметь весьма солидный размер.
Первый пункт является следствием того, что отображение виртуальной памяти на физическую
должно осуществляться при каждом обращении к памяти. Все команды в конечном
счете должны поступать из памяти, и многие из них ссылаются на операнды,
которые также находятся в памяти. Следовательно, при выполнении каждой команды
необходимо обращаться к таблице страниц один, два или более раз. Если выполнение
команды занимает, скажем, 1 нс, то поиск в таблице страниц, чтобы не стать главным
узким местом, должен быть произведен не более чем за 0,2 нс.
Второй пункт следует из факта, что все современные компьютеры используют как
минимум 32-разрядные виртуальные адреса, но все более обычными для настольных
компьютеров и ноутбуков становятся 64-разрядные адреса. При размере страницы, скажем,
4 Кбайт 32-разрядное адресное пространство имеет 1 млн страниц, а 64-разрядное
адресное пространство имеет намного больше страниц, чем вам может понадобиться.
При 1 млн страниц в виртуальном адресном пространстве таблица страниц должна
содержать 1 млн записей. Также следует помнить, что каждому процессу требуется
собственная таблица страниц (поскольку у него собственное виртуальное адресное
пространство).
Потребность в обширном и быстром отображении страниц является весьма существенным
ограничением на пути создания компьютеров. Простейшая конструкция
(по крайней мере, концептуально) состоит в использовании одной таблицы страниц,
состоящей из массива быстродействующих аппаратных регистров, имеющей по одной
записи для каждой виртуальной страницы, проиндексированной по номеру виртуальной
страницы (см. рис. 3.10). При запуске процесса операционная система загружает
регистры таблицей страниц этого процесса, которая берется из копии, хранящейся
в оперативной памяти. Во время выполнения процесса таблице страниц не нужны
никакие дополнительные ссылки на память. Преимуществами этого метода являются
простота и отсутствие каких-либо обращений к памяти во время отображения. Его
недостаток — в чрезмерных затратах при большом размере таблицы страниц, что
зачастую просто непрактично. Еще один недостаток заключается в необходимости
загрузки всей таблицы страниц при каждом переключении контекста, что полностью
убьет производительность.
Другой крайностью является конструкция, при которой вся таблица страниц может
целиком находиться в оперативной памяти. При этом аппаратуре нужно иметь лишь
один регистр, указывающий на начало таблицы страниц. Такая конструкция позволяет
отображению виртуальной памяти на физическую меняться при переключении контекста
путем перезагрузки всего лишь одного регистра. Здесь, разумеется, есть и недостаток,
поскольку для считывания записей таблицы страниц во время выполнения
каждой команды требуется одно или несколько обращений к памяти, что существенно
замедляет работу.
Буферы быстрого преобразования адреса
Теперь рассмотрим широко используемую систему, призванную ускорить страничную
организацию памяти и обрабатывать большие виртуальные адресные пространства,
отталкиваясь от прежней схемы. Отправной точкой для большинства оптимизирующих
технологий является содержание таблицы страниц в памяти. Потенциально
такая конструкция оказывает сильное влияние на производительность. Рассмотрим,
к примеру, однобайтную команду, копирующую один регистр в другой. При отсутствии
страничной организации эта команда осуществляет лишь одно обращение к памяти
для извлечения самой команды. При страничной организации памяти понадобится
как минимум еще одно обращение к памяти для доступа к таблице страниц. Поскольку
скорость выполнения обычно ограничена скоростью, с которой центральный процессор
может извлечь инструкцию и данные из памяти, необходимость осуществления при
каждом обращении к памяти двух обращений снижает производительность вдвое. При
таких условиях использовать страничную организацию памяти никто не станет.
Разработчики компьютерных систем были знакомы с этой проблемой много лет и наконец
придумали решение, которое основывалось на том наблюдении, что большинство
программ склонны большинство своих обращений направлять к небольшому количеству
страниц, а не наоборот. Поэтому интенсивному чтению подвергается лишь небольшая
часть записей таблицы страниц, а остальная часть практически не используется.
Найденное решение состояло в оснащении компьютеров небольшим устройством для
отображения виртуальных адресов на физические без просмотра таблицы страниц.
Состояние этого устройства, названного буфером быстрого преобразования адреса
(Translation Lookaside Buffer (TLB)), которое иногда еще называют ассоциативной
памятью, показано в табл. 3.1. Зачастую это устройство находится внутри диспетчера
памяти и состоит из небольшого количества записей. В данном примере их 8, но их
количество редко превышает 64. Каждая запись содержит информацию об одной
странице, включающую номер виртуальной страницы, бит, устанавливающийся при
модификации страницы, код защиты (разрешение на чтение, запись и выполнение)
и физический страничный блок, в котором расположена страница. Эти поля имеют
точное соответствие полям в таблице страниц, за исключением номера виртуальной
страницы, который в таблице страниц не нужен. Еще один бит показывает задействованность
страницы (то есть используется она или нет).
Пример, который мог бы сформировать TLB, показанный в табл. 3.1, — это циклический
процесс, занимающий виртуальные страницы 19, 20 и 21, поэтому их записи
в TLB имеют коды защиты, разрешающие чтение и исполнение. Основные данные,
используемые в этот момент (скажем, обрабатываемый массив), занимают страницы
129 и 130. Страница 140 содержит индексы, используемые при вычислениях, производимых
с элементами массива. И наконец, стек занимает страницы 860 и 861.
Таблица 3.1. Буфер быстрого преобразования адреса, используемый для ускорения
страничного доступа к памяти
Задействована Виртуальная
страница
Изменена Защищена Страничный
блок
1 140 1 RW 31
1 20 0 R X 38
1 130 1 RW 29
1 129 1 RW 62
1 19 0 R X 50
1 21 0 R X 45
1 860 1 RW 14
1 861 1 RW 75
Теперь рассмотрим работу TLB. Когда диспетчеру памяти предоставляется для преобразования
виртуальный адрес, аппаратура сначала проверяет, не содержится ли номер
его виртуальной страницы в TLB, одновременно (то есть параллельно) сравнивая его
значение со всеми записями. Для этого потребуется специальное оборудование, имеющееся
у всех диспетчеров памяти с TLB-буферами. Если будет найдено соответствие
и биты защиты не будут препятствовать доступу, номер страничного блока будет взят
непосредственно из TLB, без обращения к таблице страниц. Если номер виртуальной
страницы присутствует в TLB, но команда пытается осуществить запись в страницу,
предназначенную только для чтения, генерируется ошибка защиты.
Нас интересует, что же произойдет, если номер виртуальной страницы не будет найден
в TLB. Диспетчер памяти обнаруживает его отсутствие и осуществляет обычный поиск
в таблице страниц. Затем он выселяет одну из записей в TLB, заменяя ее только
что найденной записью из таблицы страниц. Поэтому, если вскоре эта страница будет
востребована снова, то во второй раз она уже будет найдена в TLB. Когда запись удаляется
из TLB, бит модификации копируется обратно в таблицу страниц, находящуюся
в памяти. Другие значения, за исключением бита ссылки, там уже присутствуют. Когда
TLB загружается из таблицы страниц, все поля берутся из памяти.
Программное управление буфером TLB
До сих пор мы предполагали, что каждая машина со страничной виртуальной памятью
имеет таблицы страниц, распознаваемые аппаратурой, плюс TLB. При такой конструкции
управление TLB и обработка TLB-ошибок осуществляется исключительно оборудованием
диспетчера памяти. Прерывания, передающие управление операционной
системе, происходят, только если страница отсутствует в памяти.
В былые времена такое предположение вполне соответствовало действительности. Но
многие современные RISC-машины, включая SPARC, MIPS и (теперь уже ставшие
историей) HP PA, осуществляют практически все управление страницами программным
образом. На этих машинах записи TLB загружаются операционной системой
явным образом. Когда нужная запись в TLB отсутствует, диспетчер памяти, вместо
того чтобы обращаться к таблицам страниц для поиска и извлечения сведений о нужной
странице, просто генерирует TLB-ошибку и подбрасывает проблему операционной
системе. Система должна отыскать страницу, удалить запись из TLB, внести новую
запись и перезапустить команду, вызвавшую ошибку. И разумеется, все это должно
быть сделано с использованием минимума команд, поскольку ошибка отсутствия
записи в TLB случается намного чаще, чем ошибка отсутствия страницы в таблице.
Как ни странно, но при умеренно большом TLB (скажем, 64 записи) программное
управление этим буфером оказывается вполне эффективным средством снижения
количества ошибок отсутствия нужной записи. Основным преимуществом такого
управления является существенное упрощение диспетчера памяти, освобождающее
большую площадь микросхемы центрального процессора под кэш и другие функциональные
узлы, способные повысить производительность. Программное управление
TLB рассмотрено в работе Uhlig et al., 1994.
Для улучшения производительности на машинах, осуществляющих программное
управление TLB, в давние времена были разработаны различные стратегии. В одном
из подходов прилагались усилия как по сокращению ошибок отсутствия нужных
записей в TLB, так и по уменьшению издержек при возникновении этих ошибок
(Bala et al., 1994). Иногда для сокращения количества ошибок отсутствия нужных
записей в TLB операционная система может воспользоваться своей интуицией для
определения того, какие из страниц, скорее всего, будут востребованы в следующую
очередь, и заранее загрузить касающиеся их записи в TLB. Например, когда клиентский
процесс отправляет сообщение серверному процессу на той же самой машине,
высока вероятность того, что сервер вскоре также будет задействован. Располагая
этими сведениями во время обработки системного прерывания, занимающегося отправкой
(send), система может заодно с этим проверить, присутствуют ли в карте
отображения страницы кода, данных и стека сервера, и отобразить их до того, как
появятся предпосылки для возникновения ошибки TLB.
Обычный способ аппаратной или программной обработки ошибки TLB заключается
в переходе к таблице страниц и осуществлении операций индексации для определения
местоположения затребованной страницы. Проблема выполнения этого поиска программным
способом состоит в том, что страницы, содержащие таблицу страниц, могут
отсутствовать в TLB, что может стать причиной дополнительных TLB-ошибок в процессе
обработки. От этих ошибок можно избавиться за счет использования довольно
большого (например, 4 Кбайт) программного кэша записей TLB в фиксированном
месте, сведения о странице которого всегда содержатся в TLB. При первой проверке
программного кэша операционная система может существенно сократить количество
TLB-ошибок.
При использовании программного управления TLB важно понять разницу между различными
видами ошибок отсутствия записей. Программная ошибка отсутствия происходит,
когда страница, к которой идет обращение, отсутствует в TLB, но присутствует
в памяти. Для ее устранения требуется лишь обновление TLB и не требуется выполнение
операций ввода-вывода с обращением к диску. Обычно устранение программной
ошибки отсутствия требует 10–20 машинных команд и может быть завершено за несколько
наносекунд. В отличие от нее аппаратная ошибка отсутствия происходит, когда
сама страница отсутствует в памяти (и, разумеется, запись о ней отсутствует в TLB).
Для получения страницы требуется обращение к диску, занимающее в зависимости от
используемого диска несколько миллисекунд. Аппаратная ошибка отсутствия обрабатывается
почти в миллион раз медленнее, чем программная. Просмотр отображения
в иерархии таблиц страниц называется просмотром таблиц страниц (page table walk).
Фактически дела обстоят еще хуже. Ошибка отсутствия носит не только программный
или аппаратный характер. Некоторые ошибки отсутствия имеют по сравнению
с другими ошибками отсутствия больше программный (или больше аппаратный)
характер. Например, при просмотре таблицы страниц нужная страница в таблице
страниц процесса отсутствует, и программа, таким образом, сталкивается с ошибкой
отсутствия страницы. В данной ситуации существуют три возможности. Во-первых,
страница фактически может находиться в памяти, но отсутствовать в таблице страниц
процесса. Например, страница может быт взята с диска другим процессом. В таком
случае нужно вместо нового обращения к диску просто соответствующим образом
отобразить страницу в таблицах страниц. Это скорее программная ошибка отсутствия
страницы, известная как легкая ошибка отсутствия страницы (minor page
fault). Во-вторых, если страницу нужно брать с диска, это будет считаться серьезной
ошибкой отсутствия страницы. В-третьих, вполне возможно, что программа просто
обратилась по неверному адресу и в TLB вообще не нужно добавлять никакого отображения.
В таком случае операционная система обычно прекращает выполнение
программы с выдачей ошибки сегментации. И только в этом случае программа действительно
делает что-то неправильно. Во всех остальных случаях ценой некоторой
потери производительности все автоматически исправляется оборудованием и/или
операционной системой.
3.3.4. Таблицы страниц для больших объемов памяти
Буферы TLB могут использоваться для увеличения скорости преобразования виртуальных
адресов в физические при обычной системе хранения таблицы страниц в памяти.
Но этим проблемы не исчерпываются. Возникают проблемы обслуживания очень
больших виртуальных адресных пространств. Далее будут рассмотрены два способа,
позволяющие справиться с этими проблемами.
Многоуровневые таблицы страниц
В качестве первого подхода рассмотрим использование многоуровневой таблицы страниц,
простой пример которой показан на рис. 3.12. В его левой части (на фрагменте а)
показан 32-разрядный виртуальный адрес, разбитый на 10-битное поле PT1, 10-битное
поле PT2 и 12-битное поле смещения. Поскольку под смещение отведено 12 бит, страницы
имеют размер 4 Кбайт и их общее количество составляет 2 20 .
Секрет метода использования многоуровневой таблицы страниц заключается в отказе
от постоянного хранения всех таблиц страниц в памяти. В частности, вообще не
должны храниться те таблицы, в которых нет необходимости. Предположим, к примеру,
что процессу требуются 12 Мбайт: нижние 4 Мбайт памяти — для текста программы,
следующие 4 Мбайт — для данных и верхние 4 Мбайт — для стека. Между верхней
границей данных и дном стека образуется огромная неиспользуемая дыра.
На рис. 3.12, б показано, как работает двухуровневая таблица страниц. Слева показана
таблица страниц верхнего уровня, содержащая 1024 записи, соотносящиеся
с 10-битным полем PT1. Когда диспетчеру памяти предоставляется виртуальный
адрес, то сначала он извлекает поле PT1 и использует его значение в качестве индекса
для таблицы страниц верхнего уровня. Каждая из этих 1024 записей в таблице
страниц верхнего уровня представляет 4 Мбайт, поскольку все 4-гигабайтное (то
есть 32-разрядное) виртуальное адресное пространство было разбито на фрагменты
по 4096 байт.
Рис. 3.12. Многоуровневая таблица страниц: а — 32-разрядный адрес с двумя полями
таблиц страниц; б — двухуровневая таблица страниц
Из записи, место которой определяется путем индексирования таблицы страниц верхнего
уровня, извлекается адрес или номер страничного блока таблицы страниц второго
уровня. Запись 0 таблицы страниц верхнего уровня указывает на таблицу страниц
для текста программы, запись 1 — на таблицу страниц для данных, а запись 1023 — на
таблицу страниц для стека. Другие (закрашенные) записи не используются. Поле PT2
теперь используется в качестве индекса на выбранную таблицу страниц второго уровня,
предназначенного для поиска номера страничного блока для самой страницы.
В качестве примера рассмотрим 32-разрядный виртуальный адрес 0x00403004
(4 206 596 в десятичном формате), который соответствует 12 292-му байту внутри
области данных. Этот виртуальный адрес соответствует PT1 = 1, PT2 = 2 и смещение
равно 4. Диспетчер памяти сначала использует PT1 для обращения по индексу к таблице
верхнего уровня и извлекает запись 1, которая соответствует адресам от 4 Мбайт
до 8 Мбайт – 1. Затем он использует PT2 для обращения по индексу к таблице страниц
второго уровня, чтобы найти и извлечь запись 3, которая соответствует адресам от
12 288 до 16 383 внутри своего фрагмента размером 4 Мбайт (то есть соответствует
абсолютным адресам от 4 206 592 до 4 210 687). Эта запись содержит номер страничного
блока той страницы, которая содержит виртуальный адрес 0x00403004. Если эта
страница не присутствует в памяти, то бит присутствия-отсутствия в записи таблицы
страниц будет иметь нулевое значение, что вызовет ошибку отсутствия страницы.
Если страница присутствует в памяти, то номер страничного блока, взятый из таблицы
страниц второго уровня, объединяется со смещением (4) для построения физического
адреса. Этот адрес выставляется на шину и отправляется к блоку памяти.
В отношении изображения на рис. 3.12 следует отметить одну интересную деталь. Хотя
адресное пространство содержит более миллиона страниц, фактически востребованы
только четыре таблицы: таблица верхнего уровня и таблицы второго уровня для памяти
от 0 до 4 Мбайт – 1 (для текста программы), от 4 Мбайт до 8 Мбайт – 1 (для данных)
и для верхних 4 Мбайт (выделенных под стек). Биты присутствия-отсутствия в остальных
1021 записи таблицы страниц верхнего уровня установлены в нуль, что при любом
обращении к ним вызовет ошибку отсутствия страницы. При возникновении этой
ошибки операционная система поймет, что процесс пытается обратиться к той памяти,
обращение к которой не предполагалось, и предпримет соответствующие меры, например
пошлет ему сигнал или уничтожит этот процесс. В данном примере мы выбрали
для различных размеров округленные значения и размер поля PT1, равный размеру
поля PT2, но в реальных системах, конечно, возможны и другие значения.
Система, показанная на рис. 3.12, в которой используется двухуровневая таблица страниц,
может быть расширена до трех, четырех и более уровней. Дополнительные уровни
придают ей бˆольшую гибкость. Например, 32-разрядный процессор Intel 80386 (выпущенный
в 1985 году) способен был адресовать до 4 Гбайт памяти, используя двухуровневую
таблицу страниц, которая состоит из каталога страниц, чьи записи указывают
на таблицы страниц, которые, в свою очередь, указывают на фактические страничные
блоки размером 4 Кбайт. Как в каталоге, так и в таблицах страниц содержится по 1024
записи, что в целом, как и требуется, дает 2 10 · 2 10 · 2 12 = 2 32 адресуемых байтов.
Спустя 10 лет с выпуском процессора Pentium Pro был введен еще один уровень: таблица
указателей на каталоги страниц. Кроме всего прочего, каждая запись в каждом
уровне иерархии таблиц страниц была расширена с 32 до 64 разрядов, что позволяло
адресовать память за пределами 4-гигабайтной границы. Поскольку имелось всего
4 запи си в таблице указателей на каталоги страниц, 512 записей в каждом каталоге
страниц и 512 записей в каждой таблице страниц, общий объем возможной адресуемой
памяти был по-прежнему ограничен максимальным значением 4 Гбайт. Когда же
к семейству x86 была добавлена должная 64-разрядная поддержка (изначально это
было сделано компанией AMD), дополнительный уровень можно было бы назвать
указателем таблицы указателей на каталоги страниц. Это вполне вписалось бы в манеру
присваивания названий производителями микросхем. К счастью, этого не произошло.
И ими был выбран альтернативный вариант «страничное отображение уровня 4» (page
map level 4) — конечно, имя не самое броское, зато короткое и более понятное. В любом
случае, теперь эти процессоры используют все 512 записей во всех таблицах, выдавая
объем адресуемой памяти 2 9 · 2 9 · 2 9 · 2 9 · 2 12 = 2 48 байтов. Они могли бы добавить и еще
один уровень, но, возможно, подумали, что 256 Тбайт пока будет достаточно.
Инвертированные таблицы страниц
Альтернатива постоянно растущим уровням иерархии страничной адресации называется
инвертированными таблицами страниц. Впервые они использовались такими
процессорами, как PowerPC, UltraSPARC и Itanium (которые иногда называли Itanic,
поскольку успех, на который в связи с их выходом надеялась компания Intel, так и не был
достигнут). В данной конструкции имеется одна запись для каждого страничного блока
в реальной памяти, а не одна запись на каждую страницу в виртуальном адресном пространстве.
Например, при использовании 64-разрядных виртуальных адресов, страниц
размером 4 Кбайт и оперативной памяти размером 4 Гбайт инвертированные таблицы
требовали только 1 048 576 записей. В каждой записи отслеживается, что именно находится
в страничном блоке (процесс, виртуальная страница).
Хотя инвертированные таблицы страниц экономят значительное количество пространства,
по крайней мере в том случае, когда виртуальное адресное пространство намного
объемнее физической памяти, у них есть один серьезный недостаток: преобразование
виртуальных адресов в физические становится намного сложнее. Когда процесс n
обращается к виртуальной странице p, аппаратура уже не может найти физическую
страницу, используя p в качестве индекса внутри таблицы страниц. Вместо этого она
должна провести поиск записи (n, p) по всей инвертированной таблице страниц. Более
того, этот поиск должен быть проведен при каждом обращении к памяти, а не только
при ошибках отсутствия страницы. Вряд ли можно признать просмотр таблицы размером
256 K записей при каждом обращении к памяти способом сделать ваш компьютер
самым быстродействующим.
Решение этой дилеммы состоит в использовании TLB. Если в этом буфере можно
будет хранить информацию обо всех интенсивно используемых страницах, преобразование
может происходить так же быстро, как и при использовании обычных таблиц
страниц. Но при отсутствии нужной записи в TLB программа должна просмотреть
инвертированную таблицу страниц. Одним из приемлемых способов осуществления
этого поиска является ведение хэш-таблицы, созданной на основе виртуальных адресов.
На рис. 3.13 показано, что все находящиеся на данный момент в памяти виртуальные
Рис. 3.13. Сопоставление традиционной таблицы страниц с инвертированной
страницы, имеющие одинаковые хэш-значения, связываются в одну цепочку. Если
у хэш-таблицы столько же строк, сколько физических страниц у машины, средняя
цепочка будет длиной всего лишь в одну запись, позволяя существенно ускорить отображение.
Как только будет найден номер страничного блока, в TLB будет введена
новая пара значений (виртуального, физического).
Инвертированные таблицы страниц нашли широкое применение на 64-разрядных
машинах, поскольку даже при очень больших размерах страниц количество записей
в обычных таблицах страниц будет для них просто гигантским. К примеру, при размере
страниц 4 Мбайт и 64-разрядных виртуальных адресах понадобится 2 42 записей в таблице
страниц. Другие подходы к работе с большими объемами виртуальной памяти
можно найти в работе Таллури (Talluri et al., 1995).
3.4. Алгоритмы замещения страниц
При возникновении ошибки отсутствия страницы операционная система должна
выбрать выселяемую (удаляемую из памяти) страницу, чтобы освободить место для
загружаемой страницы. Если предназначенная для удаления страница за время своего
нахождения в памяти претерпела изменения, она должна быть переписана на диске,
чтобы привести дисковую копию в актуальное состояние. Но если страница не изменялась
(например, она содержала текст программы), дисковая копия не утратила своей
актуальности и перезапись не требуется. Тогда считываемая страница просто пишется
поверх выселяемой.
Если бы при каждой ошибке отсутствия страницы можно было выбирать для выселения
произвольную страницу, то производительность системы была бы намного выше,
если бы выбор падал на редко востребуемую страницу. При удалении интенсивно используемой
страницы высока вероятность того, что она в скором времени будет загружена
опять, что приведет к лишним издержкам. На выработку алгоритмов замещения
страниц было потрачено множество усилий как в теоретической, так и в экспериментальной
областях. Далее мы рассмотрим некоторые из наиболее важных алгоритмов.
Следует заметить, что проблема «замещения страниц» имеет место и в других областях
проектирования компьютеров. К примеру, у большинства компьютеров имеется
более одного кэша памяти, содержащих последние использованные 32- или 64-байтные
блоки памяти. При заполнении кэша нужно выбрать удаляемые блоки. Это проблема
в точности повторяет проблему замещения страниц, за исключением более короткого
времени (все должно быть сделано за несколько наносекунд, а не миллисекунд, как при
замещении страниц). Причиной необходимости более короткого времени является то,
что ненайденные блоки кэша берутся из оперативной памяти без затрат времени на
поиск и без задержек на раскрутку диска.
В качестве второго примера можно взять веб-сервер. В кэше памяти сервера может содержаться
некоторое количество часто востребуемых веб-страниц. Но при заполнении
кэша памяти и обращении к новой странице должно быть принято решение о том, какую
веб-страницу нужно выселить. Здесь используются те же принципы, что и при работе со
страницами виртуальной памяти, за исключением того, что веб-страницы, находящиеся
в кэше, никогда не подвергаются модификации, поэтому на диске всегда имеется их
свежая копия. А в системе, использующей виртуальную память, страницы, находящиеся
в оперативной памяти, могут быть как измененными, так и неизмененными.
Во всех рассматриваемых далее алгоритмах замещения страниц ставится вполне
определенный вопрос: когда возникает необходимость удаления страницы из памяти,
должна ли эта страница быть одной из тех, что принадлежат процессу, в работе которого
произошла ошибка отсутствия страницы, или это может быть страница, принадлежащая
другому процессу? В первом случае мы четко ограничиваем каждый процесс
фиксированным количеством используемых страниц, а во втором таких ограничений
не накладываем. Возможны оба варианта, а к этому вопросу мы еще вернемся.
3.4.1. Оптимальный алгоритм замещения страниц
Наилучший алгоритм замещения страниц несложно описать, но совершенно невозможно
реализовать. В нем все происходит следующим образом. На момент возникновения
ошибки отсутствия страницы в памяти находится определенный набор страниц. К некоторым
из этих страниц будет осуществляться обращение буквально из следующих
команд (эти команды содержатся на странице). К другим страницам обращения может
не быть и через 10, 100 или, возможно, даже 1000 команд. Каждая страница может
быть помечена количеством команд, которые должны быть выполнены до первого
обращения к странице.
Оптимальный алгоритм замещения страниц гласит, что должна быть удалена страница,
имеющая пометку с наибольшим значением. Если какая-то страница не будет
использоваться на протяжении 8 млн команд, а другая какая-нибудь страница не будет
использоваться на протяжении 6 млн команд, то удаление первой из них приведет
к ошибке отсутствия страницы, в результате которой она будет снова выбрана с диска
в самом отдаленном будущем. Компьютеры, как и люди, пытаются по возможности
максимально отсрочить неприятные события.
Единственной проблемой такого алгоритма является невозможность его реализации.
К тому времени, когда произойдет ошибка отсутствия страницы, у операционной системы
не будет способа узнать, когда каждая из страниц будет востребована в следующий
раз. (Подобная ситуация наблюдалась и ранее, когда мы рассматривали алгоритм
планирования, выбирающий сначала самое короткое задание, — как система может
определить, какое из заданий самое короткое?) Тем не менее при прогоне программы
на симуляторе и отслеживании всех обращений к страницам появляется возможность
реализовать оптимальный алгоритм замещения страниц при втором прогоне, воспользовавшись
информацией об обращении к страницам, собранной во время первого
прогона.
Таким образом появляется возможность сравнить производительность осуществимых
алгоритмов с наилучшим из возможных. Если операционная система достигает
производительности, скажем, на 1 % хуже, чем у оптимального алгоритма, то усилия,
затраченные на поиски более совершенного алгоритма, дадут не более 1 % улучшения.
Чтобы избежать любой возможной путаницы, следует уяснить, что подобная регистрация
обращений к страницам относится только к одной программе, прошедшей оценку,
и только при одном вполне определенном наборе входных данных. Таким образом,
полученный в результате этого алгоритм замещения страниц относится только к этой
конкретной программе и к конкретным входным данным. Хотя этот метод и применяется
для оценки алгоритмов замещения страниц, в реальных системах он бесполезен.
Далее мы будем рассматривать те алгоритмы, которые действительно полезны для
реальных систем.
3.4.2. Алгоритм исключения недавно
использовавшейся страницы
Чтобы позволить операционной системе осуществить сбор полезной статистики востребованности
страниц, большинство компьютеров, использующих виртуальную
память, имеют два бита состояния, R и M, связанных с каждой страницей. Бит R
устанавливается при каждом обращении к странице (при чтении или записи). Бит M
устанавливается, когда в страницу ведется запись (то есть когда она модифицируется).
Эти биты, как показано на рис. 3.11, присутствуют в каждой записи таблицы страниц.
Важно усвоить, что эти биты должны обновляться при каждом обращении к памяти,
поэтому необходимо, чтобы их значения устанавливались аппаратной частью. После
установки бита в 1 он сохраняет это значение до тех пор, пока не будет сброшен операционной
системой.
Если у аппаратуры нет таких битов, они должны быть созданы искусственно с помощью
механизмов операционной системы ошибки отсутствия страницы и прерывания
таймера. При запуске процесса все записи в его таблице страниц помечаются отсутствующими
в памяти. Как только произойдет обращение к странице, возникнет ошибка
отсутствия страницы. Тогда операционная система устанавливает бит R (в своих
внутренних таблицах), изменяет запись в таблице страниц, чтобы она указывала на
правильную страницу, с режимом доступа только для чтения (READ ONLY), и перезапускает
команду. Если впоследствии страница модифицируется, возникает другая
ошибка страницы, позволяющая операционной системе установить бит M и изменить
режим доступа к странице на чтение-запись (READ/WRITE).
Биты R и M могут использоваться для создания следующего простого алгоритма замещения
страниц. При запуске процесса оба страничных бита для всех его страниц устанавливаются
операционной системой в 0. Время от времени (например, при каждом
прерывании по таймеру) бит R сбрасывается, чтобы отличить те страницы, к которым
в последнее время не было обращений, от тех, к которым такие обращения были.
При возникновении ошибки отсутствия страницы операционная система просматривает
все страницы и на основе текущих значений принадлежащих им битов R и M делит
их на четыре категории:
1. Класс 0: в последнее время не было ни обращений, ни модификаций.
2. Класс 1: обращений в последнее время не было, но страница модифицирована.
3. Класс 2: в последнее время были обращения, но модификаций не было.
4. Класс 3: в последнее время были и обращения, и модификации.
Хотя на первый взгляд страниц класса 1 быть не может, но они появляются в том
случае, если у страниц класса 3 бит R сбрасывается по прерыванию от таймера. Эти
прерывания не сбрасывают бит M, поскольку содержащаяся в нем информация необходима
для того, чтобы узнать, нужно переписывать страницу, хранящуюся на диске,
или нет. Сброс бита R без сброса бита M и приводит к возникновению страниц класса 1.
Алгоритм исключения недавно использовавшейся страницы (Not Recently Used
(NRU)) удаляет произвольную страницу, относящуюся к самому низкому непустому
классу. В этот алгоритм заложена идея, суть которой в том, что лучше удалить модифицированную
страницу, к которой не было обращений по крайней мере за последний
такт системных часов (обычно это время составляет около 20 мс), чем удалить интенсивно
используемую страницу. Главная привлекательность алгоритма NRU в том, что
его нетрудно понять, сравнительно просто реализовать и добиться от него производительности,
которая, конечно, не оптимальна, но может быть вполне приемлема.
3.4.3. Алгоритм «первой пришла, первой и ушла»
Другим низкозатратным алгоритмом замещения страниц является алгоритм FIFO (First
In, First Out — «первым пришел, первым ушел»). Чтобы проиллюстрировать его работу,
рассмотрим супермаркет, у которого вполне достаточно полок для представления как раз
k различных товаров. И вот однажды какая-то компания представляет новый удобный
продукт — быстрорастворимый, полученный в результате сублимационной сушки натуральный
йогурт, который может быть восстановлен в микроволновой печи. Он сразу же
приобретает популярность, поэтому наш забитый под завязку супермаркет должен избавиться
от одного старого продукта, чтобы запастись новым.
Можно, конечно, найти самый залежалый товар (то есть что-нибудь, чем торгуют уже
лет сто двадцать) и избавиться от него на том основании, что им уже больше никто
не интересуется. В реальности супермаркет ведет связанный список всех продуктов,
имеющихся на текущий момент в продаже, в порядке их поступления. Новый продукт
попадает в конец списка, а продукт из самого начала списка удаляется.
Для алгоритма замещения страниц можно воспользоваться той же идеей. Операционная
система ведет список всех страниц, находящихся на данный момент в памяти,
причем совсем недавно поступившие находятся в хвосте, поступившие раньше всех —
в голове списка. При возникновении ошибки отсутствия страницы удаляется страница,
находящаяся в голове списка, а к его хвосту добавляется новая страница. Применительно
к магазину принцип FIFO может привести к удалению воска для эпиляции
усов, но он также может привести и к удалению муки, соли или масла. Применительно
к компьютерам может возникнуть та же проблема: самая старая страница все еще может
пригодиться. Поэтому принцип FIFO в чистом виде используется довольно редко.
3.4.4. Алгоритм «второй шанс»
Простой модификацией алгоритма FIFO, исключающей проблему удаления часто
востребуемой страницы, может стать проверка бита R самой старой страницы. Если
его значение равно нулю, значит, страница не только старая, но и невостребованная,
поэтому она тут же удаляется. Если бит R имеет значение 1, он сбрасывается, а страница
помещается в конец списка страниц и время ее загрузки обновляется, как будто
она только что поступила в память. Затем поиск продолжается.
Действие этого алгоритма, названного «второй шанс», показано на рис. 3.14. Страницы
с A по H содержатся в связанном списке отсортированными по времени их поступления
в память.
Предположим, что ошибка отсутствия страницы возникла на отметке времени 20.
Самой старой является страница A, время поступления которой соответствует началу
процесса и равно 0. Если бит R для страницы A сброшен, страница либо удаляется из
памяти с записью на диск (если она измененная), либо просто удаляется (если она неизмененная).
Но если бит R установлен, то A помещается в конец списка и ее «время
загрузки» переключается на текущее (20). Также при этом сбрасывается бит R. А поиск
подходящей страницы продолжается со страницы B.
Рис. 3.14. Действие алгоритма «второй шанс»: а — страницы, отсортированные в порядке FIFO;
б — список страниц при возникновении ошибки отсутствия страницы, показателе времени 20
и установленном в странице А бите R; числа над страницами — это время, когда они были загружены

Алгоритм «второй шанс» занимается поиском ранее загруженной в память страницы,
к которой за только что прошедший интервал времени таймера не было обращений.
Если обращения были ко всем страницам, то алгоритм «второй шанс» превращается
в простой алгоритм FIFO. Представим, в частности, что у всех страниц на рис. 3.14, а
бит R установлен. Операционная система поочередно перемещает страницы в конец
списка, очищая бит R при каждом добавлении страницы к концу списка. В конце
концов она возвращается к странице A, у которой бит R теперь уже сброшен. И тогда
страница A выселяется. Таким образом, алгоритм всегда завершает свою работу.
3.4.5. Алгоритм «часы»
При всей своей логичности алгоритм «второй шанс» слишком неэффективен, поскольку
он постоянно перемещает страницы в своем списке. Лучше содержать все
страничные блоки в циклическом списке в виде часов (рис. 3.15). Стрелка указывает
на самую старую страницу.
Рис. 3.15. Алгоритм «часы»
При возникновении ошибки отсутствия страницы проверяется та страница, на которую
указывает стрелка. Если ее бит R имеет значение 0, страница выселяется, на ее место
в «циферблате» вставляется новая страница и стрелка передвигается вперед на одну
позицию. Если значение бита R равно 1, то он сбрасывается и стрелка перемещается
на следующую страницу. Этот процесс повторяется до тех пор, пока не будет найдена
страница с R = 0. Неудивительно, что этот алгоритм называется «часы».
3.4.6. Алгоритм замещения наименее
востребованной страницы
В основе неплохого приближения к оптимальному алгоритму лежит наблюдение, что
страницы, интенсивно используемые несколькими последними командами, будут,
скорее всего, снова востребованы следующими несколькими командами. И наоборот,
долгое время не востребованные страницы наверняка еще долго так и останутся
невостребованными. Эта мысль наталкивает на вполне реализуемый алгоритм: при
возникновении ошибки отсутствия страницы нужно избавиться от той страницы, которая
длительное время не была востребована. Эта стратегия называется замещением
наименее востребованной страницы (Least Recently Used (LRU)).
Теоретически реализовать алгоритм LRU вполне возможно, но его практическая реализация
дается нелегко. Для его полной реализации необходимо вести связанный список
всех страниц, находящихся в памяти. В начале этого списка должна быть только что
востребованная страница, а в конце — наименее востребованная. Сложность в том, что
этот список должен обновляться при каждом обращении к памяти. Для поиска страницы
в списке, ее удаления из него и последующего перемещения этой страницы вперед
потребуется довольно много времени, даже если это будет возложено на аппаратное
обеспечение (если предположить, что такое оборудование можно создать).
Существуют и другие способы реализации LRU с использованием специального оборудования.
Сначала рассмотрим самый простой из них. Для его реализации аппаратное
обеспечение необходимо оснастить 64-разрядным счетчиком C, значение которого
автоматически увеличивается после каждой команды. Кроме этого каждая запись
в таблице страниц должна иметь довольно большое поле, чтобы содержать значение
этого счетчика. После каждого обращения к памяти текущее значение счетчика C сохраняется
в записи таблицы страниц, относящейся к той странице, к которой было это
обращение. При возникновении ошибки отсутствия страницы операционная система
проверяет все значения счетчика в таблице страниц, чтобы найти наименьшее из них.
Та страница, к чьей записи относится это значение, и будет наименее востребованной.
3.4.7. Моделирование LRU в программном обеспечении
При всей принципиальной возможности реализации алгоритма LRU вряд ли найдется
машина, обладающая нужным оборудованием. Скорее всего, нам понадобится
решение, которое может быть реализовано в программном обеспечении. Одно из возможных
решений называется алгоритмом нечастого востребования (Not Frequently
Used (NFU)). Для его реализации потребуется программный счетчик с начальным
нулевым значением, связанный с каждой страницей. При каждом прерывании от
таймера операционная система сканирует все находящиеся в памяти страницы. Для
каждой страницы к счетчику добавляется значение бита R, равное 0 или 1. Счетчики
позволяют приблизительно отследить частоту обращений к каждой странице. При
возникновении ошибки отсутствия страницы для замещения выбирается та страница,
чей счетчик имеет наименьшее значение.
Основная проблема при использовании алгоритма NFU заключается в том, что он
похож на слона: никогда ничего не забывает. К примеру, при многопроходной компиляции
те страницы, которые интенсивно использовались при первом проходе, могут
сохранять высокие значения счетчиков и при последующих проходах. Фактически
если на первый проход затрачивается больше времени, чем на все остальные проходы,
то страницы, содержащие код для последующих проходов, могут всегда иметь более
низкие показатели счетчиков, чем страницы, использовавшиеся при первом проходе.
Вследствие этого операционная система будет замещать нужные страницы вместо тех,
надобность в которых уже отпала.
К счастью, небольшая модификация алгоритма NFU позволяет довольно близко подойти
к имитации алгоритма LRU. Модификация состоит из двух частей. Во-первых, перед добавлением
к счетчикам значения бита R их значение сдвигается на один разряд вправо.
Во-вторых, значение бита R добавляется к самому левому, а не к самому правому биту.
На рис. 3.16 показано, как работает модифицированный алгоритм, известный как алгоритм
старения. Предположим, что после первого прерывания от таймера бит R для
страниц от 0-й до 5-й имеет значения соответственно 1, 0, 1, 0, 1 и 1 (для страницы 0 оно
равно 1, для страницы 1 — 0, для страницы 2 — 1 и т. д.). Иными словами, между прерываниями
от таймера, соответствующими тактам 0 и 1, было обращение к страницам
0, 2, 4 и 5, в результате которого их биты R были установлены в 1, а у остальных страниц
их значение осталось равным 0. После того как были смещены значения шести соответствующих
счетчиков и слева вставлено значение бита R, они приобрели значения,
показанные на рис. 3.16, а. В четырех оставшихся столбцах показаны состояния шести
счетчиков после следующих четырех прерываний от таймера.
Рис. 3.16. Алгоритм старения является программной моделью алгоритма LRU. Здесь показаны
шесть страниц в моменты пяти таймерных прерываний, обозначенных буквами от а до д
При возникновении ошибки отсутствия страницы удаляется та страница, чей счетчик
имеет наименьшее значение. Очевидно, что в счетчике страницы, к которой не было
обращений за, скажем, четыре прерывания от таймера, будет четыре ведущих нуля,
и поэтому значение ее счетчика будет меньшим, чем счетчика страницы, к которой не
было обращений в течение трех прерываний от таймера.
Этот алгоритм отличается от алгоритма LRU двумя особенностями. Рассмотрим страницы
3 и 5 на рис. 3.16, д. Ни к одной из них за два прерывания от таймера не было
ни одного обращения, но к обеим было обращение за прерывание от таймера, предшествующее
этим двум. В соответствии с алгоритмом LRU, если страница должна быть
удалена, то мы должны выбрать одну из этих двух страниц. Проблема в том, что мы
не знаем, к какой из них обращались в последнюю очередь между тактом 1 и тактом 2.
При записи только одного бита за интервал между двумя прерываниями от таймера мы
утратили возможность отличить более раннее обращение от более позднего. Все, что мы
можем сделать, — удалить страницу 3, поскольку к странице 5 также было обращение
двумя тактами ранее, а к странице 3 такого обращения не было.
Второе различие между алгоритмом LRU и алгоритмом старения заключается в том,
что в алгоритме старения счетчик имеет ограниченное количество бит (в данном примере
— 8 бит), которое сужает просматриваемый им горизонт прошлого. Предположим,
что у каждой из двух страниц значение счетчика равно нулю. Все, что мы можем сделать,
— это выбрать одну из них произвольным образом. В действительности вполне
может оказаться, что к одной из этих страниц последнее обращение было 9 тактов
назад, а ко второй — 1000 тактов назад. И это обстоятельство установить невозможно.
Но на практике 8 бит вполне достаточно, если между прерываниями от таймера проходит
примерно 20 мс. Если к странице не было обращений в течение 160 мс, то она,
наверное, уже не так важна.
3.4.8. Алгоритм «рабочий набор»
При использовании замещения страниц в простейшей форме процессы начинают свою
работу, не имея в памяти вообще никаких страниц. Как только центральный процессор
попытается извлечь первую команду, он получает ошибку отсутствия страницы, заставляющую
операционную систему ввести в память страницу, содержащую первую команду.
Обычно вскоре за этим следуют ошибки отсутствия страниц с глобальными переменными
и стеком. Через некоторое время процесс располагает большинством необходимых
ему страниц и приступает к работе, сталкиваясь с ошибками отсутствия страниц относительно
редко. Эта стратегия называется замещением страниц по требованию (demand
paging), поскольку страницы загружаются только по мере надобности, а не заранее.
Разумеется, нетрудно написать тестовую программу, систематически читающую все страницы
в огромном адресном пространстве, вызывая при этом такое количество ошибок
отсутствия страниц, что для их обработки не хватит памяти. К счастью, большинство
процессов так не работают. Они применяют локальность обращений, означающую, что
в течение любой фазы выполнения процесс обращается только к относительно небольшой
части своих страниц. К примеру, при каждом проходе многопроходного компилятора
обращение идет только к части имеющихся страниц, причем всякий раз к иной.
Набор страниц, который процесс использует в данный момент, известен как рабочий
набор (Denning, 1968а; Denning, 1980). Если в памяти находится весь рабочий набор,
процесс будет работать, не вызывая многочисленных ошибок отсутствия страниц, пока
не перейдет к другой фазе выполнения (например, к следующему проходу компилятора).
Если объем доступной памяти слишком мал для размещения всего рабочего набора,
процесс вызовет множество ошибок отсутствия страниц и будет работать медленно,
поскольку выполнение команды занимает всего несколько наносекунд, а считывание
страницы с диска — обычно 10 мс. Если он будет выполнять одну или две команды за
10 мс, то завершение его работы займет целую вечность. О программе, вызывающей
ошибку отсутствия страницы через каждые несколько команд, говорят, что она пробуксовывает
(Denning, 1968б).
В многозадачных системах процессы довольно часто сбрасываются на диск (то есть все
их страницы удаляются из памяти), чтобы дать возможность другим процессам воспользоваться
своей очередью доступа к центральному процессору. Возникает вопрос: что
делать, когда процесс возобновляет свою работу? С технической точки зрения ничего
делать не нужно. Процесс просто будет вызывать ошибки отсутствия страниц до тех пор,
пока не будет загружен его рабочий набор. Проблема в том, что наличие многочисленных
ошибок отсутствия страниц при каждой загрузке процесса замедляет работу, а также
вызывает пустую трату значительной части рабочего времени центрального процессора,
поскольку на обработку операционной системой одной ошибки отсутствия страницы
затрачивается несколько миллисекунд процессорного времени.
Поэтому многие системы замещения страниц пытаются отслеживать рабочий набор
каждого процесса и обеспечивать его присутствие в памяти, перед тем как позволить
процессу возобновить работу. Такой подход называется моделью рабочего набора
(Denning, 1970). Он был разработан для существенного сокращения количества ошибок
отсутствия страниц. Загрузка страниц до того, как процессу будет позволено возобновить
работу, называется также опережающей подкачкой страниц (prepaging). Следует
заметить, что со временем рабочий набор изменяется.
Давно подмечено, что большинство программ неравномерно обращается к своему адресному
пространству: их обращения склонны группироваться на небольшом количестве
страниц. Обращение к памяти может быть извлечением команды или данных или сохранением
данных. В любой момент времени t существует некий набор, состоящий из
всех страниц, используемый в k самых последних обращений к памяти. Этот набор,
w(k, t), и является рабочим набором. Так как все недавние обращения к памяти для
k > 1 обязательно должны были обращаться ко всем страницам, использовавшимся для
(k = 1)-го обращения к памяти, то есть к последней и, возможно, еще к некоторым страницам,
w(k, t) является монотонно неубывающей функцией от k. По мере роста значения
k значение функции w(k, t) достигает своего предела, поскольку программа не может
обращаться к количеству страниц, превышающему по объему имеющееся адресное пространство,
а каждая отдельно взятая страница будет использоваться лишь немногими
программами. На рис. 3.17 показано, что размер рабочего набора является функцией от k.
Тот факт, что большинство программ произвольно обращается к небольшому количеству
страниц, но со временем этот набор медленно изменяется, объясняет начальный
быстрый взлет кривой графика, а затем, при больших значениях k, существенное замедление
этого взлета. К примеру, программа, выполняющая цикл, при этом занимающая
две страницы и использующая данные, расположенные на четырех страницах,
может обращаться ко всем шести страницам каждые 1000 команд, но самые последние
обращения к некоторым другим страницам могут состояться за 1 млн команд до этого,
в процессе фазы инициализации. Благодаря такому асимптотическому поведению содержимое
рабочего набора нечувствительно к выбранному значению k.
Рис. 3.17. Рабочий набор — это набор страниц, используемых при k самых последних
обращений. Значение функции w(k, t) является размером рабочего набора в момент времени t
Иначе говоря, существует широкий диапазон значений k, для которого рабочий набор
остается неизменным. Поскольку со временем рабочий набор изменяется медленно,
появляется возможность выстроить разумные предположения о том, какие страницы
понадобятся при возобновлении работы программы, основываясь на том, каков был ее
рабочий набор при последней приостановке ее работы. Опережающая подкачка страниц
как раз и заключается в загрузке этих страниц перед возобновлением процесса.
Для реализации модели рабочего набора необходимо, чтобы операционная система
отслеживала, какие именно страницы входят в рабочий набор. При наличии такой
информации тут же напрашивается возможный алгоритм замещения страниц: при
возникновении ошибки отсутствия страницы нужно выселить ту страницу, которая не
относится к рабочему набору. Для реализации подобного алгоритма нам необходим четкий
способ определения того, какие именно страницы относятся к рабочему набору. По
определению рабочий набор — это набор страниц, используемых в k самых последних
обращений (некоторые авторы используют термин «k самых последних страничных
обращений», но это дело вкуса). Для реализации любого алгоритма рабочего набора
некоторые значения k должны быть выбраны заранее. Затем после каждого обращения
к памяти однозначно определяется и набор страниц, используемый при самых последних
k обращениях к памяти.
Разумеется, это определение рабочего набора не означает наличия эффективного
способа его вычисления в процессе выполнения программы. Можно представить себе
регистр со сдвигом, имеющий длину k, в котором при каждом обращении к памяти его
содержимое сдвигается влево на одну позицию и справа вставляется номер страницы,
к которой было самое последнее обращение. Набор из всех k номеров страниц в регистре
со сдвигом и будет представлять собой рабочий набор. Теоретически при возникновении
ошибки отсутствия страницы содержимое регистра со сдвигом может быть
считано и отсортировано. Затем могут быть удалены продублированные страницы.
В результате должен получиться рабочий набор. Но обслуживание регистра со сдвигом
и обработка его содержимого при возникновении ошибки отсутствия страницы окажется
недопустимо затратным делом, поэтому эта технология никогда не используется.
Вместо нее используются различные приближения. Одно из часто используемых приближений
сводится к отказу от идеи вычисления k обращений к памяти и использованию
вместо этого времени выполнения. Например, вместо определения рабочего набора
в качестве страниц, использовавшихся в течение предыдущих 10 млн обращений к памяти,
мы можем определить его как набор страниц, используемых в течение последних
100 мс времени выполнения. На практике с таким определением работать гораздо лучше
и проще. Следует заметить, что для каждого процесса вычисляется только его собственное
время выполнения. Таким образом, если процесс запускается во время T и получает
40 мс времени центрального процессора за время T + 100 мс, то для определения рабочего
набора берется время 40 мс. Интервал времени центрального процессора, реально
занимаемый процессом с момента его запуска, часто называют текущим виртуальным
временем. При этом приближении рабочим набором процесса является набор страниц,
к которым он обращался в течение последних t секунд виртуального времени.
Теперь взглянем на алгоритм замещения страниц, основанный на рабочем наборе.
Основной замысел состоит в том, чтобы найти страницу, не принадлежащую рабочему
набору, и удалить ее из памяти. На рис. 3.18 показана часть таблицы страниц, используемой
в некой машине. Поскольку в качестве кандидатов на выселение рассматриваются
только страницы, находящиеся в памяти, страницы, в ней отсутствующие, этим
алгоритмом игнорируются. Каждая запись состоит (как минимум) из двух ключевых
элементов информации: времени (приблизительного) последнего использования страницы
и бита R (Referenced — бита обращения). Пустыми белыми прямоугольниками
обозначены другие поля, не нужные для этого алгоритма, например номер страничного
блока, биты защиты и бит изменения — M (Modified).
Рис. 3.18. Алгоритм рабочего набора
Рассмотрим работу алгоритма. Предполагается, что аппаратура, как было рассмотрено
ранее, устанавливает биты R и M. Также предполагается, что периодические прерывания
от таймера запускают программу, очищающую бит обращения R. При каждой
ошибке отсутствия страницы происходит сканирование таблицы страниц с целью
найти страницу, пригодную для удаления.
При каждой обработке записи проверяется состояние бита R. Если его значение
равно 1, текущее виртуальное время записывается в поле времени последнего использования
таблицы страниц, показывая, что страница была использована при возникновении
ошибки отсутствия страницы. Если обращение к странице происходит в течение
текущего такта времени, становится понятно, что она принадлежит рабочему набору
и не является кандидатом на удаление (предполагается, что t охватывает несколько
системных тактов).
Если значение R равно 0, значит, за текущий такт времени обращений к странице не
было и она может быть кандидатом на удаление. Чтобы понять, должна ли она быть
удалена или нет, вычисляется ее возраст (текущее виртуальное время за вычетом времени
последнего использования), который сравнивается со значением t. Если возраст
превышает значение t, то страница уже не относится к рабочему набору и заменяется
новой страницей. Сканирование продолжается, и происходит обновление всех остальных
записей.
Но если значение R равно 0, но возраст меньше или равен t, то страница все еще относится
к рабочему набору. Страница временно избегает удаления, но страница с наибольшим
возрастом (наименьшим значением времени последнего использования)
берется на заметку. Если будет просканирована вся таблица страниц и не будет найдена
страница — кандидат на удаление, значит, к рабочему набору относятся все страницы.
В таком случае, если найдена одна и более страниц с R = 0, удаляется одна из них, имеющая
наибольший возраст. В худшем случае в течение текущего такта было обращение
ко всем страницам (и поэтому у всех страниц R = 1), поэтому для удаления одна из
них выбирается случайным образом, при этом предпочтение отдается неизмененной
странице, если таковая имеется.
3.4.9. Алгоритм WSClock
Базовый алгоритм рабочего набора слишком трудоемок, поскольку при возникновении
ошибки отсутствия страницы для определения местонахождения подходящего
кандидата на удаление необходимо просканировать всю таблицу страниц. Усовершенствованный
алгоритм, основанный на алгоритме «часы», но также использующий
информацию о рабочем наборе, называется WSClock (Carr and Hennessey, 1981).
Благодаря простоте реализации и хорошей производительности он довольно широко
используется на практике.
Необходимая структура данных сводится к циклическому списку страничных блоков,
как в алгоритме «часы» и как показано на рис. 3.19, а. Изначально этот список пуст.
При загрузке первой страницы она добавляется к списку. По мере загрузки следующих
страниц они попадают в список, формируя замкнутое кольцо. В каждой записи содержится
поле времени последнего использования из базового алгоритма рабочего набора,
а также бит R (показанный на рисунке) и бит M (не показанный на рисунке).
Как и в алгоритме «часы», при каждой ошибке отсутствия страницы сначала проверяется
страница, на которую указывает стрелка. Если бит R установлен в 1, значит, страница
была использована в течение текущего такта, поэтому она не является идеальным
кандидатом на удаление. Затем бит R устанавливается в 0, стрелка перемещается на
следующую страницу, и алгоритм повторяется уже для нее. Состояние, получившееся
после этой последовательности событий, показано на рис. 3.19, б.
Теперь посмотрим, что получится, если у страницы, на которую указывает стрелка,
бит R = 0 (рис. 3.19, в). Если ее возраст превышает значение t и страница не измеРис.
3.19. Работа алгоритма WSClock: а и б — пример того, что происходит, когда R = 1;
в и г — пример того, что происходит, когда R = 0
нена, она не относится к рабочему набору и ее точная копия присутствует на диске.
Тогда страничный блок просто истребуется и в него помещается новая страница
(рис. 3.19, г). Но если страница изменена, ее блок не может быть тотчас же истребован,
поскольку на диске нет ее точной копии. Чтобы избежать переключения процесса,
запись на диск планируется, а стрелка перемещается дальше и алгоритм продолжает
свою работу на следующей странице. В конце концов должна попасться старая, неизмененная
страница, которой можно будет тут же и воспользоваться.
В принципе, за один оборот часовой стрелки может быть запланирована операция
дискового ввода-вывода для всех страниц. Для уменьшения потока обмена данными
с диском может быть установлен лимит, позволяющий сбрасывать на диск максимум
n страниц. По достижении этого лимита новые записи на диск планироваться уже не
должны.
А что делать, если стрелка пройдет полный круг и вернется в начальную позицию?
Тогда следует рассмотреть два варианта.
1. Была запланирована хотя бы одна запись на диск.
2. Не было запланировано ни одной записи на диск.
В первом случае стрелка просто продолжит движение, выискивая неизмененную
страницу. Поскольку была запланирована одна или более записей на диск, со временем
одна из записей завершится, и задействованная в ней страница будет помечена
неизмененной. Первая же неизмененная страница и будет удалена. Эта страница не
обязательно должна быть первой запланированной, поскольку драйвер диска может
изменить порядок записи, чтобы оптимизировать производительность его работы.
Во втором случае все страницы относятся к рабочему набору, иначе должна была быть
запланирована хотя бы одна запись. При недостатке дополнительной информации
простейшее, что можно сделать, — истребовать любую неизмененную страницу и воспользоваться
ею. Расположение неизмененной страницы может быть отслежено в процессе
оборота стрелки. Если неизмененных страниц не имеется, то в качестве жертвы
выбирается текущая страница, которая и сбрасывается на диск.
3.4.10. Краткая сравнительная характеристика алгоритмов
замещения страниц
Только что мы рассмотрели несколько различных алгоритмов замещения страниц.
В этом разделе дадим им краткую сравнительную характеристику. Список рассмотренных
алгоритмов представлен в табл. 3.2.
Таблица 3.2. Список рассмотренных алгоритмов замещения страниц
Алгоритм Особенности
Оптимальный Не может быть реализован, но полезен в качестве
оценочного критерия
NRU (Not Recently Used) — алгоритм исключения
недавно использовавшейся страницы
Является довольно грубым приближением
к алгоритму LRU
FIFO (First In, First Out) — алгоритм «первой
пришла, первой и ушла»
Может выгрузить важные страницы
Алгоритм «второй шанс» Является существенным усовершенствованием
алгоритма FIFO
Алгоритм «часы» Вполне реализуемый алгоритм
LRU (Least Recently Used) — алгоритм замещения
наименее востребованной страницы
Очень хороший, но труднореализуемый во всех
тонкостях алгоритм
NFU (Not Frequently Used) — алгоритм нечастого
востребования
Является довольно грубым приближением
к алгоритму LRU
Алгоритм старения Вполне эффективный алгоритм, являющийся
неплохим приближением к алгоритму LRU
Алгоритм рабочего набора Весьма затратный для реализации алгоритм
WSClock Вполне эффективный алгоритм
Оптимальный алгоритм удаляет страницу с самым отдаленным предстоящим обращением.
К сожалению, у нас нет способа определения, какая это будет страница, поэтому
на практике этот алгоритм использоваться не может. Но он полезен в качестве
оценочного критерия при рассмотрении других алгоритмов.
Алгоритм исключения недавно использованной страницы (NRU) делит страницы на
четыре класса в зависимости от состояния битов R и M. Затем выбирает произвольную
страницу из класса с самым низким номером. Этот алгоритм нетрудно реализовать, но
он слишком примитивен. Есть более подходящие алгоритмы.
Алгоритм FIFO предполагает отслеживание порядка, в котором страницы были загружены
в память, путем сохранения сведений об этих страницах в связанном списке.
Это упрощает удаление самой старой страницы, но она-то как раз и может все еще
использоваться, поэтому FIFO — неподходящий выбор.
Алгоритм «второй шанс» является модификацией алгоритма FIFO и перед удалением
страницы проверяет, не используется ли она в данный момент. Если страница все еще
используется, она остается в памяти. Эта модификация существенно повышает производительность.
Алгоритм «часы» является простой разновидностью алгоритма «второй
шанс». Он имеет такой же показатель производительности, но требует несколько
меньшего времени на свое выполнение.
Алгоритм LRU превосходен во всех отношениях, но не может быть реализован без
специального оборудования. Если такое оборудование недоступно, то он не может быть
использован. Алгоритм NFU является грубой попыткой приблизиться к алгоритму
LRU. Его нельзя признать удачным. А вот алгоритм старения — куда более удачное
приближение к алгоритму LRU, которое к тому же может быть эффективно реализовано
и считается хорошим выбором.
В двух последних алгоритмах используется рабочий набор. Алгоритм рабочего набора
обеспечивает приемлемую производительность, но его реализация обходится
слишком дорого. Алгоритм WSClock является вариантом, который не только обеспечивает
неплохую производительность, но и может быть эффективно реализован.
В итоге наиболее приемлемыми алгоритмами являются алгоритм старения и алгоритм
WSClock. Они основаны на LRU и рабочем наборе соответственно. Оба обеспечивают
неплохую производительность страничной организации памяти и могут быть эффективно
реализованы. Существует также ряд других хороших алгоритмов, но эти два,
наверное, имеют наибольшее практическое значение.
3.5. Разработка систем страничной
организации памяти
В предыдущих разделах мы объяснили, как работает страничная организация памяти,
и дали описание нескольких основных алгоритмов замещения страниц. Но знания
одних лишь базовых механизмов еще недостаточно. Для разработки работоспособной
системы необходимо расширить свой кругозор. Это похоже на разницу между знанием
порядка передвижения ладьи, коня, слона и других шахматных фигур и навыком
хорошей игры. В следующих разделах мы рассмотрим другие вопросы, которым
разработчики операционных систем должны уделять пристальное внимание, чтобы
добиться хорошей производительности от системы страничной организации памяти.
3.5.1. Сравнительный анализ локальной
и глобальной политики
В предыдущих разделах мы рассмотрели несколько алгоритмов выбора удаляемой
страницы в случае возникновения ошибки отсутствия страницы.
Главный вопрос, связанный с этим выбором (который мы до сих пор тщательно обходили
стороной): как должна быть распределена память между конкурирующими
работоспособными процессами?
Посмотрите на рис. 3.20, а. На нем изображены три процесса: A, B и C, составляющие
набор работоспособных процессов. Предположим, что процесс A сталкивается с ошибкой
отсутствия страницы. Должен ли алгоритм замещения страниц попытаться найти
наиболее давно использованную страницу, рассматривая лишь шесть страниц, выделенных
на данный момент процессу A, или же он должен рассматривать все страницы,
имеющиеся в памяти? Если он осуществляет поиск только среди страниц, принадлежащих
процессу A, то страницей с наименьшим значением возраста будет A5, и мы
получим ситуацию, показанную на рис. 3.20, б.
Рис. 3.20. Сравнение локального и глобального алгоритмов замещения страниц:
а — исходная конфигурация; б — работа локального алгоритма замещения страниц;
в — работа глобального алгоритма замещения страниц
В то же время, если страница с наименьшим значением возраста удаляется независимо
от того, какому процессу она принадлежит, то будет выбрана страница B3, и мы получим
ситуацию, показанную на рис. 3.20, в. Алгоритм, чья работа показана на рис. 3.20, б,
называется локальным алгоритмом замещения страниц, а алгоритм, чья работа показана
на рис. 3.20, в, называется глобальным алгоритмом замещения страниц. Локальный
алгоритм хорошо подходит для выделения каждому процессу фиксированной доли
памяти. При использовании глобальных алгоритмов страничные блоки распределяются
среди работоспособных процессов в динамическом режиме. Поэтому со временем
изменяется количество страничных блоков, выделенных каждому процессу.
В целом глобальные алгоритмы работают лучше, особенно когда размер рабочего набора
может изменяться в течение жизненного цикла процесса. Если используется локальный
алгоритм, а рабочий набор разрастается, то это приводит к пробуксовке даже
при избытке свободных страничных блоков. Если рабочий набор сужается, локальные
алгоритмы приводят к нерациональному использованию памяти. Если используется
глобальный алгоритм, система должна постоянно принимать решение о том, сколько
страничных блоков выделить каждому процессу. Одним из способов может стать отслеживание
размера рабочего набора на основе показаний битов возраста, но не факт,
что этот подход предотвратит пробуксовку. Рабочий набор может изменять свой размер
за миллисекунды, в то время как весьма приблизительные показатели на основе битов
возраста складываются за несколько тактов системных часов.
Другой подход заключается в использовании алгоритма выделения процессам страничных
блоков. Один из способов заключается в периодическом определении количества
работающих процессов и выделении каждому процессу равной доли. Таким образом,
при наличии 12 416 доступных (то есть не принадлежащих операционной системе)
страничных блоков и 10 процессов каждый процесс получает 1241 страничный блок.
Оставшиеся шесть блоков переходят в резерв для использования в случае возникновения
ошибки отсутствия страницы.
Хотя этот метод может показаться справедливым, едва ли есть смысл предоставлять
одинаковые доли памяти процессу в 10 Кбайт и процессу в 300 Кбайт. Вместо этого
страницы должны быть распределены пропорционально общему размеру каждого процесса,
чтобы процессу в 300 Кбайт было выделено в 30 раз больше блоков, чем процессу
в 10 Кбайт. Наверное, разумно будет дать каждому процессу какое-то минимальное
количество, чтобы он мог запуститься независимо от того, насколько малым он будет.
К примеру, на некоторых машинах одиночная двухоперандная команда может нуждаться
не менее чем в шести страницах, потому что на границах страниц может оказаться все:
сама команда, операнд-источник и операнд-приемник. При выделении всего лишь пяти
страниц программа, содержащая подобные команды, вообще не сможет выполняться.
При использовании глобального алгоритма может появиться возможность запускать
каждый процесс с некоторым количеством страниц пропорционально размеру процесса,
но как только процессы будут запущены, распределение должно динамически
обновляться. Одним из способов управления распределением является использование
алгоритма частоты возникновения ошибки отсутствия страницы (Page Fault Frequency
(PFF)). Он подсказывает, когда нужно увеличивать или уменьшать количество выделенных
процессу страниц, но ничего не говорит о том, какую страницу следует удалить
в случае возникновения ошибки. Он всего лишь контролирует размер выделенного
набора.
Ранее уже говорилось, что для большого класса алгоритмов замещения страниц, включая
LRU, известно, что чем больше выделено страниц, тем меньше уровень ошибок.
Данное предположение положено в основу алгоритма PFF. Это свойство проиллюстрировано
на рис. 3.21.
Измерение уровня ошибок отсутствия страниц осуществляется простым подсчетом
количества ошибок в секунду, можно также взять скользящее среднее за несколько прошедших
секунд. Одним из простых методов осуществления подобного измерения является
прибавление количества ошибок отсутствия страниц в течение только что прошедшей
секунды к текущему значению скользящего среднего и деление результата на
два. Пунктирная линия, обозначенная буквой A, соответствует неприемлемо высокому
Рис. 3.21. Уровень ошибок как функция от количества выделенных
страничных блоков
уровню ошибок отсутствия страницы, поэтому, чтобы снизить этот уровень, процесс,
в котором происходят ошибки, получает больше страничных блоков. Пунктирная
линия, обозначенная буквой B, соответствует слишком низкому уровню ошибок отсутствия
страницы, который позволяет предположить, что процессу выделено чрезмерно
много памяти. В этом случае страничные блоки у него могут быть отобраны. Таким
образом алгоритм PFF пытается сохранить для каждого процесса уровень подкачки
страниц в пределах приемлемых границ.
Важно отметить, что некоторые алгоритмы замещения страниц могут работать как
с локальной, так и с глобальной политикой замещения. Например, FIFO может заменять
самые старые страницы во всем пространстве памяти (глобальный алгоритм) или
самые старые страницы, принадлежащие текущему процессу (локальный алгоритм).
Точно так же алгоритм LRU или приближения к его реализации могут заменять наиболее
давно использованную страницу во всей памяти (глобальный алгоритм) или
наиболее давно использованную страницу, принадлежащую текущему процессу (локальный
алгоритм). В некоторых случаях выбор локальной, а не глобальной стратегии
не зависит от алгоритма.
В то же время для других алгоритмов замещения страниц имеет смысл только локальная
стратегия. В частности, алгоритмы рабочего набора и WSClock обращаются
к некоторым конкретным процессам и должны применяться в этом контексте. По сути,
не существует рабочего набора для всей машины, и при попытке воспользоваться объединением
всех рабочих наборов алгоритм утратит свойство локальности и не сможет
работать эффективно.
3.5.2. Управление загрузкой
Даже при самом лучшем алгоритме замещения страниц и оптимальной системе распределения
страничных блоков между процессами система может пробуксовывать.
Фактически когда сумма рабочих наборов всех процессов превышает объем памяти,
можно ожидать пробуксовки. Одним из симптомов такой ситуации является показание
алгоритма PFF, свидетельствующее о том, что некоторые процессы нуждаются в дополнительной
памяти, но ни одному из процессов не нужен ее меньший объем. В таком
случае нуждающимся процессам невозможно предоставить дополнительную память,
не «ущемляя» другие процессы. Единственным реальным решением станет избавление
от некоторых процессов.
Неплохим способом сокращения количества соревнующихся за обладание памятью
процессов является сброс некоторых из них на диск и освобождение всех удерживавшихся
ими страниц. Например, один процесс может быть сброшен на диск, а его
страничные блоки — поделены между другими пробуксовывающими процессами.
Если пробуксовка прекратится, то система некоторое время может проработать в таком
состоянии. Если она не прекратится, потребуется сбросить на диск другой процесс
и продолжать в том же духе, пока пробуксовка не прекратится. Таким образом, даже
при страничной организации памяти свопинг может не утратить своей актуальности,
только теперь он используется для сокращения потенциальной потребности в памяти,
а не для повторного востребования страниц.
Свопинг процессов, призванный снизить нагрузку на память, напоминает двухуровневую
диспетчеризацию, при которой часть процессов помещается на диск, а для распределения
оставшихся процессов используется краткосрочный диспетчер. Понятно,
что эти две идеи можно сочетать, выгружая достаточное количество процессов, чтобы
достичь приемлемого уровня ошибок отсутствия страницы. Периодически какие-то
процессы загружаются с диска, а какие-то выгружаются на него.
Еще одним фактором, требующим рассмотрения, является степень многозадачности.
Когда в основной памяти находится слишком мало процессов, центральный процессор
может весьма существенные периоды времени быть недогружен. С учетом этого при
принятии решения о выгрузке процесса нужно принимать во внимание не только его
размер и уровень подкачки страниц, но и его характеристики, например ограничен ли
этот процесс скоростью вычислений или же он ограничен скоростью работы устройств
ввода-вывода, и принимать во внимание те характеристики, которыми обладают
остальные процессы.
3.5.3. Размер страницы
Размер страницы является тем параметром, который должен быть выбран операционной
системой. Даже если аппаратура была разработана, к примеру, под страницы
в 4096 байт, операционная система может запросто рассматривать пары страниц 0 и 1,
2 и 3, 4 и 5 и т. д. как страницы размером 8 Кбайт, всегда выделяя им два последовательных
страничных блока размером 8192 байт.
Определение наилучшего размера страницы требует сохранения баланса между несколькими
конкурирующими факторами. Таким образом, абсолютно оптимального
решения не существует. Для начала возьмем два фактора, являющихся аргументами
в пользу небольшого размера страницы. Произвольно взятые текст, данные или сегмент
стека не заполнят целое число страниц. В среднем половина последней страницы
останется незаполненной. Оставшееся пространство на этой странице тратится впустую.
Эти потери называются внутренней фрагментацией. Если в памяти n сегментов,
а размер страницы составляет p байт, то на внутреннюю фрагментацию будет потрачено
впустую np/2 байт. Эти соображения являются аргументом в пользу небольшого
размера страницы.
Другой аргумент в пользу небольшого размера страницы возникает при рассмотрении
программы, состоящей из восьми последовательных этапов, каждый размером 4 Кбайт.
При размере страницы 32 Кбайт программе всегда должно быть выделено 32 Кбайт.
При странице размером 16 Кбайт ей потребуется только 16 Кбайт. А при размере страницы
4 Кбайт или меньше ей в любой момент времени потребуется только 4 Кбайт.
В общем, при большом размере страницы в памяти будет больше неиспользуемого
пространства, чем при малом.
В то же время при небольших по объему страницах подразумевается, что программы
будут нуждаться в большом количестве страниц, а это приведет к большому размеру
таблицы страниц. Программе размером 32 Кбайт требуется только 4 страницы по
8 Кбайт, но 64 страницы по 512 байт. Как правило, на диск и с диска переносится сразу
вся страница, при этом основная часть времени тратится на задержки, связанные
с поиском нужного сектора и раскруткой диска, поэтому перенос небольшой страницы
занимает практически столько же времени, что и перенос большой страницы. Для загрузки
64 страниц по 512 байт может потребоваться 64 · 10 мс, а для загрузки четырех
страниц по 8 Кбайт — всего 4 · 12 мс.
Кроме того, страницы небольшого размера расходуют много ценного пространства
в TLB. Предположим, что ваша программа использует 1 Мбайт памяти с рабочим набором
размером 64 Кбайт. При страницах размером 4 Кбайт программа будет занимать
как минимум 16 записей в TLB. При страницах размером 2 Мбайт было бы достаточно
одной записи в TLB (теоретически вам может потребоваться разделить данные и инструкции).
Из-за дефицита TLB-записей и их значимого влияния на производительность
приходится везде, где только можно, расплачиваться использованием больших
страниц. Чтобы сбалансировать все эти компромиссы, операционные системы иногда
используют разные размеры страниц для разных частей системы. Например, большие
страницы для ядра и меньшие по размеру страницы для пользовательских процессов.
На некоторых машинах таблица страниц должна быть загружена (операционной системой)
в аппаратные регистры при каждом переключении центрального процессора
с одного процесса на другой. Для этих машин наличие небольших страниц означает
увеличение времени, необходимого для загрузки регистров страниц при уменьшении
размера страницы. Более того, при уменьшении размера страницы увеличивается пространство,
занимаемое таблицей страниц.
Последнее утверждение может быть проанализировано с математической точки зрения.
Пусть средний размер процесса будет составлять s байт, а размер страницы — p байт.
Кроме этого предположим, что на каждую страничную запись требуется e байт. Тогда
приблизительное количество страниц, необходимое каждому процессу, будет равно s/p,
что займет se/p байт пространства таблицы страниц. Из-за внутренней фрагментации
неиспользуемое пространство памяти в последней странице процесса будет равно p/2.
Таким образом, общие издержки на таблицу страниц и внутреннюю фрагментацию
будут получены за счет суммирования этих двух величин:
Издержки = se/p + p/2.
Первое слагаемое (размер таблицы страниц) будет иметь большее значение при небольшом
размере страницы. Второе слагаемое (внутренняя фрагментация) будет иметь
большее значение при большом размере страницы. Оптимальный вариант находится
где-то посередине. Если взять первую производную по переменной p и приравнять ее
к нулю, то мы получим уравнение
–se/p 2 + 1/2 = 0.
Из этого уравнения можно вывести формулу, дающую оптимальный размер страницы
(с учетом только потерь памяти на фрагментацию и на размер таблицы страниц).
Результат будет следующим:
Для s = 1 Мбайт и e = 8 байт на каждую запись в таблице страниц оптимальный размер
страницы будет 4 Кбайт. Имеющиеся в продаже компьютеры используют размер
страницы от 512 байт до 64 Кбайт. Раньше чаще всего использовался размер 1 Кбайт,
но сейчас чаще всего встречается размер страницы 4 Кбайт.
3.5.4. Разделение пространства команд и данных
У многих компьютеров имеется единое адресное пространство, в котором, как показано
на рис. 3.22, а, содержатся и программы и данные. При довольно большом объеме этого
пространства все работает нормально. Но зачастую объем адресного пространства
слишком мал, что заставляет программистов как-то выкручиваться, чтобы поместить
в него все необходимое.
Рис. 3.22. Адресное пространство: а — единое; б — отдельные адресные пространства
команд (I) и данных (D)
Одно из решений, впервые примененное на шестнадцатиразрядной машине PDP-11,
заключалось в использовании отдельных адресных пространств для команд (текста
программы) и данных, называемых I-пространством и D-пространством соответственно
(рис. 3.22, б). Каждое пространство простирается от 0 до некоторого максимума,
обычно 2 16 – 1 или 2 32 – 1. Компоновщик должен знать о том, что используются отдельные
I- и D-пространства, поскольку при их использовании данные переносятся
на виртуальный адрес 0, а не начинаются сразу после программы.
На компьютерах такой конструкции страничную организацию памяти могут иметь
оба пространства независимо друг от друга. У каждого из них имеется собственная
таблица страниц с собственным отображением виртуальных страниц на физические
страничные блоки. Когда аппаратуре требуется извлечь команду, она знает, что для этого
нужно использовать I-пространство и таблицу страниц этого I-пространства. Точно
так же обращение к данным должно вестись через таблицу страниц D-пространства.
Кроме этих тонкостей, наличие отдельных I- и D-пространств не приводит к какимто
особым осложнениям для операционной системы и при этом удваивает доступное
адресное пространство.
Поскольку теперь адресные пространства стали большими, серьезные проблемы,
связанные с их размерами, ушли в прошлое. Но даже сегодня разделение
I- и D-пространств встречается довольно часто. Правда, вместо обычных адресных
пространств теперь это разделение используется в кэше L1, который до сих пор испытывает
дефицит памяти.
3.5.5. Совместно используемые страницы
Еще одним вопросом разработки является совместное использование ресурсов. В больших
многозадачных системах одновременное использование несколькими пользователями
одной и той же программы является обычным делом. Даже отдельный пользователь
может запускать несколько программ, использующих одну и ту же библиотеку.
При этом вполне очевидна эффективность совместного использования страниц, чтобы
избежать одновременного присутствия в памяти двух копий одной и той же страницы.
Проблема в том, что не все страницы могут использоваться совместно. В частности,
страницы, предназначенные только для чтения, например содержащие текст программы,
могут использоваться совместно, а совместное использование страниц с данными
связано с дополнительными сложностями.
Если поддерживаются отдельные I- и D-пространства, задача совместного использования
программ становится относительно простой за счет наличия одного или нескольких
процессов, использующих одну и ту же таблицу страниц для своих I-пространств,
но разные таблицы страниц для своих D-пространств. Обычно в реализациях, поддерживающих
совместное использование страниц таким образом, таблица страниц является
структурой данных, независимой от таблицы процессов. При этом, как показано
на рис. 3.23, каждый процесс в своей таблице процесса имеет два указателя: один на
таблицу страниц I-пространства, другой на таблицу страниц D-пространства. Когда
планировщик процессов выбирает запускаемый процесс, он использует эти указатели
для определения местонахождения таблиц страниц и настройки с их помощью диспетчера
памяти (MMU). Процессы могут совместно использовать программы (или
иногда библиотеки) даже в отсутствие отдельных I- и D-пространств, но для этого
используется более сложный механизм.
Когда два и более процесса совместно используют один и тот же код, возникает проблема
совместно используемых страниц. Предположим, что два процесса, A и B, запускают
редактор и совместно используют его страницы. Если планировщик примет
решение удалить процесс A из памяти, пожертвовав всеми его страницами и заполнив
опустевшие страничные блоки какой-нибудь другой программой, это приведет к тому,
что процесс B сгенерирует большое количество ошибок отсутствия страницы и вернет
эти страницы назад.
Также при остановке процесса A необходимо иметь возможность определить, какие
страницы все еще используются, чтобы их дисковое пространство случайно не оказалось
освобожденным. Просмотр всех таблиц страниц для того, чтобы определить совместное
использование страницы, — обычно очень затратная операция, поэтому для
отслеживания совместно используемых страниц понадобится специальная структура
данных, особенно если предметом совместного использования является отдельная
страница (или ряд страниц), а не вся таблица страниц.
Совместное использование данных является более сложной задачей, чем совместное
использование кода, но и она не является невыполнимой. В частности, в UNIX после
системного вызова fork родительский и дочерний процессы вынуждены совместно использовать
как текст программы, так и данные. В системах со страничной организацией
Рис. 3.23. Два процесса, совместно использующие одну и ту же программу,
имеют общие таблицы страниц
памяти часто практикуется предоставление каждому из таких процессов собственной
таблицы страниц и наличие у них обоих указателя на один и тот же набор страниц.
Таким образом, при выполнении системного вызова fork копирования страниц не происходит.
Тем не менее все страницы с данными отображаются для каждого процесса
как страницы только для чтения — READ ONLY.
Пока оба процесса только читают свои данные, не внося в них изменений, эта ситуация
может продолжаться. Как только какой-нибудь из процессов обновит слово памяти,
нарушение защиты режима только для чтения приведет к системному прерыванию
операционной системы. После чего делается копия вызвавшей эту ситуацию страницы,
чтобы у каждого процесса имелся собственный экземпляр. Теперь для обеих копий
устанавливается режим чтения-записи — READ-WRITE, поэтому следующие записи
в каждую копию происходят без системного прерывания. Эта стратегия означает, что
те страницы, которые никогда не изменяются (включая все страницы программы), не
нуждаются в копировании. Копирование требуется только для тех страниц, которые
на самом деле подвергаются изменениям. Этот подход, названный копированием при
записи (copy on write), повышает производительность за счет сокращения объема
копирования.
3.5.6. Совместно используемые библиотеки
Совместное использование может быть с другой степенью структурированности. Если
программа будет запущена дважды, то большинство операционных систем автоматически
организуют совместное использование текстовых страниц, чтобы в памяти была
только одна копия. Текстовые страницы всегда используются в режиме только для чтения,
поэтому проблем не возникает. В зависимости от операционной системы каждый
процесс может получить собственную частную копию страниц с данными или же они
могут совместно использоваться и иметь пометку «Только для чтения». Если какойнибудь
процесс изменяет страницу данных, для него будет создана частная копия, то
есть будет использована копия, пригодная для записи.
В современных системах имеется множество больших библиотек, используемых многими
процессами, к примеру множество библиотек ввода-вывода и графических библиотек.
Статическая привязка всех этих библиотек к каждой исполняемой программе
на диске сделала бы их еще более раздутыми, чем есть на самом деле.
Вместо этого должна использоваться общая технология совместно используемых
(общих) библиотек, которые в Windows называются динамически подключаемыми
библиотеками (Dynamic Link Libraries (DLL)). Чтобы сделать идею совместно используемой
библиотеки более понятной, рассмотрим сначала традиционную компоновку.
При компоновке программы в команде компоновщику указывается один или несколько
объектных файлов и, возможно, несколько библиотек, как, например, в команде UNIX
ld *.o –lc –lm
которая компонует все файлы с расширением  .o (object), имеющиеся в текущем
каталоге, а затем сканирует две библиотеки,  /usr/lib/libc.a и  /usr/lib/libm.a . Любые
функции, вызываемые в объектных файлах, но не присутствующие в них (например,
printf), называются неопределенными внешними функциями и выискиваются
в библиотеках. Если они найдены, то их включают в исполняемый двоичный
файл. Любые вызываемые, но не присутствующие в них функции также становятся
неопределенными внешними функциями. К примеру, функции printf требуется
функция write, поэтому, если функция write еще не включена, компоновщик будет
ее разыскивать и, как только найдет, включит в двоичный файл. Когда компоновка
завершится, исполняемый двоичный файл, записываемый на диск, будет содержать
все необходимые функции. Имеющиеся в библиотеке, но невостребованные функции
в него не включаются. Когда программа загружается в память и выполняется, в ней
содержатся все необходимые ей функции.
Теперь предположим, что обычная программа использует 20–50 Мбайт функций, относящихся
к графике и пользовательскому интерфейсу. Статически скомпонованные
сотни программ со всеми этими библиотеками будут тратить впустую громадный объем
дискового пространства, а также пространства оперативной памяти, как только они
будут загружены, поскольку у системы не будет способа узнать о том, что она может
использовать эти библиотеки как общие. И тут на сцену выходят совместно используемые
библиотеки. Когда программа скомпонована с учетом совместного использования
библиотек (что несколько отличается от статической компоновки), вместо включения
реально вызываемых функций компоновщик включает небольшую подпрограмму-заглушку,
которая в процессе исполнения привязывается к вызываемой функции. В зависимости
от системы или от особенностей конфигурации совместно используемые
библиотеки загружаются либо при загрузке программы, либо когда присутствующие
в них функции вызываются в первый раз. Разумеется, если совместно используемая
библиотека уже загружена другой программой, то нет нужды загружать ее повторно —
именно в этом и заключается весь смысл. Следует заметить, что при загрузке или использовании
общей библиотеки вся библиотека разом в память не считывается. Она
загружается постранично, по мере надобности, поэтому функции, которые не были
вызваны, в оперативную память не переносятся.
Сделать исполняемые файлы меньшими по объему и сэкономить пространство памяти
помогает еще одно преимущество совместно используемых библиотек: если функция,
находящаяся в общей библиотеке, обновляется с целью устранения ошибки, то перекомпилировать
программу, которая ее вызывает, не нужно. Старые двоичные файлы
сохраняют свою работоспособность. Это свойство приобретает особое значение для
коммерческого программного обеспечения, код которого не доставляется клиенту.
Например, если корпорация Microsoft находит и исправляет ошибку, влияющую на
безопасность системы в некой стандартной библиотеке DLL, программа обновления
— Windows Update — загрузит новую DLL и заменит ею старую библиотеку, и все
программы, использующие данную DLL, будут при следующем запуске автоматически
использовать новую версию.
Но совместно используемые библиотеки пришли к нам с одной небольшой проблемой,
требующей решения. Эта проблема показана на рис. 3.24. Здесь отображены два
процесса, совместно использующие библиотеку размером 20 Кбайт (предположим,
что каждый ее блок занимает 4 Кбайт). Но библиотека в каждом процессе располагается
по разным адресам, по-видимому, потому что сами программы не совпадают по
размеру. В процессе 1 библиотека размещается, начиная с адреса 36 К; в процессе 2
ее размещение начинается с адреса 12 К. Предположим, первое, что должна сделать
первая функция библиотеки, — перейти в библиотеке к адресу 16. Если библиотека не
использовалась совместно, она может быть перемещена на лету в процессе загрузки, поэтому
переход (в процессе 1) может быть осуществлен на виртуальный адрес 36 К + 16.
Следует заметить, что физический адрес оперативной памяти, по которому размещается
библиотека, не имеет значения, пока все страницы отображаются с виртуальных
на физические адреса аппаратурой диспетчера памяти — MMU.
Но как только библиотека начинает использоваться совместно, перемещение на
лету уже работать не будет. В конце концов, когда первая функция вызывается
Рис. 3.24. Общая библиотека, используемая двумя процессами
процессом 2 (по адресу 12 К), команда перехода вынуждена осуществить его на адрес
12 К + 16, а не на адрес 36 К + 16. В этом и заключается небольшая проблема. Одним из
путей ее решения является использование копии при записи и создании новых страниц
для каждого процесса, использующего общую библиотеку, и перемещение их на лету
во время создания. Но эта схема, разумеется, дискредитирует всю цель совместного
использования библиотеки.
Лучшее решение заключается в компиляции совместно используемых библиотек со
специальным флажком для компилятора, указывающим этому компилятору не создавать
никаких команд, использующих абсолютную адресацию. Вместо этого применяются
лишь те команды, которые используют относительную адресацию. Например,
почти всегда есть команда, предписывающая переход вперед (или назад) на n байтов
(в качестве альтернативы той команде, которая дает для перехода конкретный адрес).
Эта команда работает правильно независимо от размещения совместно используемой
библиотеки в виртуальном адресном пространстве. Проблема может быть решена за
счет исключения абсолютной адресации. Код, использующий только относительные
смещения, называется позиционно независимым кодом.
3.5.7. Отображаемые файлы
На самом деле совместно используемые библиотеки являются частным случаем более
общих объектов, называемых отображаемыми на память файлами. Идея состоит в том,
что процесс может выдать системный вызов для отображения файла на какую-то часть
его виртуального адресного пространства. В большинстве реализаций на момент отображения
в память еще не введены никакие страницы, но поскольку мы имеем дело
со страницами, они требуют постраничной организации с использованием дискового
файла в качестве резервного хранилища. Когда процесс выходит из рабочего состояния
или явным образом демонтирует отображение файла, все измененные страницы
записываются обратно в файл на диске.
Отображаемые файлы предоставляют альтернативную модель для ввода-вывода.
Вместо осуществления операций чтения и записи к файлу можно обращаться как
к большому символьному массиву, находящемуся в памяти. В некоторых ситуациях
программисты находят эту модель более удобной.
Если два или более процесса одновременно отображаются на один и тот же файл, они
могут связываться посредством совместно используемой памяти. Запись, произведенная
одним процессом в общую память, становится тут же видна, если другой процесс
считывает данные из части своего виртуального адресного пространства, отображенного
на файл. Таким образом, данный механизм предоставляет канал между двумя
процессами, обладающий высокой пропускной способностью, и он довольно часто
используется именно в этом качестве (вплоть до отображения рабочего файла). Теперь
вы должны понять, что при доступности отображаемых на память файлов совместно
используемые библиотеки могут воспользоваться этим механизмом.
3.5.8. Политика очистки страниц
Замещение страниц лучше всего работает при наличии достаточного количества свободных
страничных блоков, которые могут потребоваться при возникновении ошибки
отсутствия страницы. Если заполнен и, более того, изменен каждый страничный блок,
то перед помещением в него новой страницы сначала должна быть записана на диск
старая страница. Для обеспечения поставки свободных страничных блоков системы
замещения страниц, как правило, имеют фоновый процесс, называемый страничным
демоном, который большую часть времени находится в состоянии спячки, но периодически
пробуждается для проверки состояния памяти. Если свободно слишком мало
страничных блоков, страничный демон начинает подбирать страницы для выгрузки,
используя какой-нибудь алгоритм замещения страниц. Если эти страницы со времени
своей загрузки подверглись изменению, они записываются на диск.
В любом случае предыдущее содержание страницы запоминается. Если одна из выгруженных
страниц понадобится опять перед тем, как ее страничный блок будет
переписан, она может быть восстановлена из резерва свободных страничных блоков.
Сохранение материалов страничных блоков улучшает производительность по сравнению
с использованием всей памяти с последующей попыткой найти блок в тот момент,
когда в нем возникает необходимость. Как минимум, страничный демон обеспечивает
чистоту всех свободных блоков, чтобы не приходилось в спешке записывать их на диск,
когда в них возникнет потребность.
Один из способов реализации этой политики очистки предусматривает использование
часов с двумя стрелками. Передняя стрелка управляется страничным демоном. Когда
она указывает на измененную страницу, эта страница сбрасывается на диск и передняя
стрелка перемещается вперед. Когда она указывает на чистую страницу, то происходит
только перемещение вперед. Задняя стрелка используется для замещения страниц, как
в стандартном алгоритме «часы». Только теперь благодаря работе страничного демона
повышается вероятность того, что задняя стрелка попадет на чистую страницу.
3.5.9. Интерфейс виртуальной памяти
До сих пор в нашем повествовании предполагалось, что виртуальная память вполне
обозрима процессами и программистами, то есть все, что они видят, — это большое
виртуальное адресное пространство на компьютере с малой (или меньшей) по объему
физической памятью. Это верно по отношению ко многим системам, но в некоторых
системах программистам доступен контроль над отображением памяти и они могут воспользоваться
им нетрадиционными способами, чтобы обогатить поведение программы.
В этом разделе мы вкратце рассмотрим некоторые из этих возможностей.
Одним из поводов предоставления программистам контроля над отображением памяти
является разрешение одному или нескольким процессам совместно использовать
одну и ту же память, иногда весьма сложными способами. Если программисты могут
присваивать имена областям памяти, то появляется возможность одному процессу
предоставить другому процессу имя области памяти, чтобы этот процесс мог также
отображаться на нее. Когда два (или несколько) процесса совместно используют одни
и те же страницы, появляется возможность использования общего высокоскоростного
канала: один процесс ведет запись в общую память, а другой процесс считывает из нее
данные. Сложный пример такого коммуникационного канала описан Де Брюйном
(De Bruijn, 2011).
Совместное использование страниц может быть применено также для реализации высокопроизводительной
системы сообщений. Как правило, когда передается сообщение,
данные копируются из одного адресного пространства в другое с существенными издержками.
Если процессы могут управлять своей таблицей страниц, сообщение может
быть передано за счет исключения из таблицы страницы (или страниц), содержащей
сообщение, и за счет включения ее в таблицу принимающего процесса. В этом случае
должны копироваться только имена, а не все данные.
Еще одна передовая технология управления памятью называется распределенной памятью
совместного доступа (Feeley et al., 1995; Li, 1986; Li and Hudak, 1989; Zekauskas
et al., 1994). В ее основе лежит идея, заключающаяся в том, чтобы позволить нескольким
процессам через сетевое подключение совместно использовать набор страниц, при
этом возможно, но не обязательно, в качестве единого общего линейного диапазона
адресов. Когда процесс обращается к странице, которая в данный момент не имеет
отображения, у него происходит ошибка отсутствия страницы. Затем обработчик этой
ошибки, который может быть в ядре или в пользовательском пространстве, определяет
машину, содержащую эту страницу, и посылает ей сообщение с просьбой отключить
отображение страницы и переслать ее по сети. По прибытии страницы она отображается,
и команда, вызвавшая ошибку, перезапускается. Более подробно распределенная
память совместного доступа будет рассмотрена в главе 8.
3.6. Проблемы реализации
Разработчики систем виртуальной памяти должны выбрать какие-нибудь из основных
теоретических алгоритмов, например отдать предпочтение алгоритму «второй шанс»,
а не алгоритму старения, локальному, а не глобальному выделению страниц и предоставлению
станиц по запросу, а не опережающей подкачке страниц. Но они также
должны знать о некоторых проблемах практической реализации. В этом разделе будет
рассмотрен ряд общих проблем и некоторые способы их решения.
3.6.1. Участие операционной системы в процессе
подкачки страниц
Операционная система занята работой, связанной с подкачкой страниц, в течение
четырех периодов времени: во время создания процесса, во время выполнения процесса,
при возникновении ошибки отсутствия страницы и при завершении процесса.
Кратко рассмотрим каждый из этих периодов времени, чтобы посмотреть, что должно
быть сделано.
При создании нового процесса в системе со страничной организацией памяти операционная
система должна определить, каким будет (первоначально) объем программы
и данных, и создать для них таблицу страниц. Для таблицы страниц нужно выделить
пространство в памяти, а затем ее нужно инициализировать. При выгрузке процесса
таблица страниц не должна быть резидентной, но она должна находиться в памяти
при запуске процесса. Кроме того, в области подкачки на диске должно быть выделено
пространство, чтобы при выгрузке страницы ее было куда поместить. Область
подкачки также должна быть инициализирована, туда должны быть помещены текст
программы и данные, чтобы после запуска нового процесса в случае возникновения
ошибки отсутствия страницы оттуда могли быть извлечены недостающие страницы.
Некоторые системы подкачивают текст программы непосредственно из исполняемого
файла, экономя дисковое пространство и время на инициализацию. И наконец,
информация о таблице страниц и области подкачки на диске должна быть записана
в таблице процесса.
Когда процесс планируется на выполнение, диспетчер памяти (MMU) должен быть
перезапущен под новый процесс, а содержимое буфера быстрого преобразования адреса
(TLB) должно быть очищено, чтобы избавиться от следов ранее выполнявшегося процесса.
Текущей должна стать таблица страниц нового процесса. Обычно это делается
путем копирования ее самой или указателя на нее в какой-нибудь аппаратный регистр
(или регистры). Чтобы уменьшить количество ошибок отсутствия страниц, в память
могут быть загружены некоторые страницы процесса или все его страницы (например,
точно известно, что понадобится страница, на которую указывает счетчик команд).
При возникновении ошибки отсутствия страницы операционная система должна считать
данные аппаратных регистров, чтобы определить, чей виртуальный адрес вызвал
ошибку. На основе этой информации она должна вычислить, какая страница востребована,
и найти ее место на диске. Затем она должна найти для новой страницы подходящий
страничный буфер, удалив из него, если необходимо, какую-нибудь старую
страницу. Потом она должна считать востребованную страницу в страничный блок.
И наконец, она должна вернуть назад счетчик команд, заставив его указывать на команду,
вызвавшую ошибку, и дать этой команде возможность повторного выполнения.
При завершении процесса операционная система должна освободить его таблицу страниц,
его страницы и дисковое пространство, которое занимали эти страницы, когда находились
на диске. Если некоторые из этих страниц совместно используются другими
процессами, то страницы в памяти и на диске могут быть освобождены только тогда,
когда будет прекращена работа последнего использующего их процесса.
3.6.2. Обработка ошибки отсутствия страницы
Наконец-то мы добрались до подробного описания всего, что происходит при возникновении
ошибки отсутствия страницы. Складывается следующая последовательность
событий:
1. Аппаратное прерывание передает управление ядру, сохраняя в стеке значение
счетчика команд. На большинстве машин в специальных регистрах центрального
процессора сохраняется информация о состоянии текущей команды.
2. Запускается код стандартной программы на ассемблере, предназначенный для
сохранения регистров общего назначения и другой изменяющейся информации,
чтобы защитить ее от разрушения со стороны операционной системы. Эта стандартная
программа вызывает операционную систему как процедуру.
3. Операционная система определяет, что произошла ошибка отсутствия страницы,
и пытается определить, какая виртуальная страница востребована. Зачастую эта
информация содержится в одном из аппаратных регистров. В противном случае
операционная система должна взять значение счетчика команд, извлечь команду
и провести ее разбор программным способом, чтобы определить, что происходило
в тот момент, когда возникла ошибка.
4. Когда известен виртуальный адрес, вызвавший ошибку, система проводит проверку
адреса на приемлемость и доступа к этому адресу — на согласованность
с системой защиты. При отрицательном результате проверки процессу посылается
сигнал или же он уничтожается. Если адрес вполне приемлем и не возникло
ошибки защиты, система проверяет, не занят ли страничный блок. Если свободные
страничные блоки отсутствуют, запускается алгоритм замещения страниц, чтобы
выбрать кандидата на удаление.
5. Если выбранный страничный блок содержит измененную страницу, она включается
в план сброса на диск и происходит переключение контекста, приостанавливающее
процесс, в котором произошла ошибка, и позволяющее запуститься другому процессу,
пока перенос страницы на диск не завершится. В любом случае блок помечается
как занятый, чтобы он не мог быть задействован другим процессом.
6. Как только страничный блок очистится (либо немедленно, либо после сброса его
содержимого на диск), операционная система ищет адрес на диске, по которому
находится востребованная страница, и в план включается дисковая операция,
предназначенная для ее извлечения. Пока страница загружается, процесс, в котором
произошла ошибка, остается приостановленным и запускается другой
пользовательский процесс, если таковой имеется.
7. Когда дисковое прерывание показывает, что страница получена, таблицы страниц
обновляются, чтобы отобразить ее позицию, и блок получает пометку нормального
состояния.
8. Команда, на которой произошла ошибка, возвращается к тому состоянию, в котором
она находилась с самого начала, и счетчик команд переключается, чтобы
указывать на эту команду.
9. Процесс, в котором произошла ошибка, включается в план, и операционная система
возвращает управление стандартной программе на ассемблере, которая ее
вызвала.
10. Эта стандартная программа перезагружает регистры и другую информацию о состоянии
и, если не произошло ошибки, возвращается в пространство пользователя
для продолжения выполнения.
3.6.3. Перезапуск команды
Когда программа обращается к странице, отсутствующей в памяти, команда, вызвавшая
ошибку, останавливается на полпути, и происходит перехват управления и передача
его операционной системе. После извлечения операционной системой востребованной
страницы она должна перезапустить команду, вызвавшую передачу управления. Но это
проще сказать, чем сделать.
Чтобы выявить природу данной проблемы в ее наихудшем виде, представим себе
центральный процессор, имеющий двухадресные команды, например Motorola 680x0,
который широко используется во встроенных системах. Возьмем, к примеру, показанную
на рис. 3.25 команду из 6 байт
MOV.L #6(A1),2(A0)
Чтобы перезапустить команду, операционная система должна определить, где находится
первый байт команды. Значение счетчика команд на момент передачи управления
зависит от того, какой из операндов вызвал ошибку, и от того, как устроен микрокод
центрального процессора.
Рис. 3.25. Команда, вызвавшая ошибку отсутствия страницы
На рис. 3.25 показана команда, начинающаяся по адресу 1000, которая осуществляет
три обращения к памяти: к слову самой команды и к двум смещениям на операнды.
В зависимости от того, какое из этих трех обращений вызвало ошибку страницы, на
момент возникновения ошибки счетчик команд может иметь значение 1000, 1002 или
1004. Зачастую операционная система не может однозначно определить, где начинается
команда. Если на момент ошибки счетчик команд имеет значение 1002, операционной
системе невозможно сообщить, является ли слово в ячейке 1002 адресом памяти,
связанным с командой в ячейке 1000 (то есть местом, где находится операнд), или же
кодом операции, принадлежащим команде.
Дело может принять еще более печальный оборот. Некоторые режимы адресации процессоров
680x0 используют автоинкремент, значит, может проявиться побочный эффект
от команды, которая должна увеличить значение одного или нескольких регистров.
Команды, использующие автоинкрементный режим, также могут вызвать ошибку. В зависимости
от особенностей микрокода инкремент может быть произведен до обращения
к памяти, и в таком случае операционная система перед перезапуском команды должна
программным способом уменьшить значение регистра. Или же автоинкремент может быть
осуществлен после обращения к памяти, в этом случае на момент передачи управления он
не будет выполнен и со стороны операционной системы не должно быть никаких обратных
действий. Существует также режим автодекремента, вызывающий сходные проблемы.
Точные данные о том, проводится или не проводится автоинкремент или автодекремент
перед соответствующим обращением к памяти, могут изменяться от команды к команде
и от одной модели центрального процессора к другой.
К счастью, на некоторых машинах разработчики центральных процессоров предоставили
решение, которое чаще всего выражается в виде скрытого внутреннего регистра,
в который перед выполнением каждой команды копируется значение счетчика команд.
У этих машин также может быть второй регистр, сообщающий о том, какой из регистров
уже подвергся автоинкременту или автодекременту и на какое именно значение.
Располагая данной информацией, операционная система может однозначно устранить
все последствия работы команды, вызвавшей ошибку, позволяя перезапустить эту команду.
Если эта информация недоступна, операционная система должна каким-то образом
исхитриться, чтобы определить, что произошло и как можно исправить ситуацию.
Похоже на то, что разработчики аппаратуры не смогли решить эту проблему, опустили
руки и переложили все на плечи разработчиков операционных систем. Славные ребята.
3.6.4. Блокировка страниц в памяти
Хотя в этой главе ввод-вывод информации рассматривался мало, тот факт, что у компьютера
есть виртуальная память, не означает, что ввод-вывод отсутствует. Виртуальная
память и операции ввода-вывода взаимодействуют весьма тонким образом. Рассмотрим
процесс, который только что сделал системный запрос на чтение из какого-то
файла или устройства в буфер, находящийся в его адресном пространстве. В ожидании
завершения операции ввода-вывода процесс приостанавливается, и разрешается работа
другого процесса. В этом другом процессе возникает ошибка отсутствия страницы.
Если алгоритм замещения страниц имеет глобальный характер, то появляется небольшой,
но не нулевой шанс, что страница, содержащая буфер ввода-вывода, будет
выбрана на удаление из памяти. Если устройство ввода-вывода в данный момент находится
в процессе переноса данных в режиме прямого доступа к памяти (DMA) на
эту страницу, то ее удаление приведет к тому, что часть данных будет записана в буфер,
которому они принадлежат, а другая часть — записана поверх только что загруженной
страницы. Одно из решений этой проблемы состоит в блокировке в памяти страниц,
занятых в операциях ввода-вывода, чтобы они не были удалены. Блокировку страницы
часто называют прикреплением (pinning) ее к памяти. Другое решение состоит в проведении
всех операций ввода-вывода с использованием буфера ядра с последующим
копированием данных в пользовательские страницы.
3.6.5. Резервное хранилище
Рассматривая алгоритмы замещения страниц, мы видели, как выбирается страница
для удаления, но не уделяли слишком много внимания тому, куда она помещается
на диске при выгрузке. Настало время рассмотреть некоторые вопросы, связанные
с управлением работой дискового устройства.
Простейший алгоритм для выделения страничного пространства на диске предусматривает
наличие на нем специального раздела подкачки (свопинга) или, что еще
лучше, отделения дискового устройства от файловой системы (чтобы сбалансировать
загруженность операциями ввода-вывода). Подобным образом работает большинство
UNIX-систем. В этом разделе отсутствует обычная файловая система, тем самым исключаются
все издержки перевода смещения в файлах в адреса блоков. Вместо этого
везде используются номера блоков относительно начала раздела.
При запуске системы раздел подкачки пуст и представлен в памяти единой записью
с указанием начального адреса и размера. По простейшей схеме при запуске первого
процесса за ним резервируется участок пространства раздела, соответствующий
размеру первого процесса, а оставшаяся область сокращается на эту величину. При
запуске новых процессов им выделяется участок раздела подкачки, равный по размеру
их основным образам. При завершении процессов их дисковые пространства
освобождаются. Раздел подкачки управляется как список свободных участков. Более
приемлемые алгоритмы будут рассмотрены в главе 10.
С каждым процессом связывается дисковый адрес его области подкачки, то есть тот
адрес, по которому в разделе подкачки хранится его образ. Эта информация хранится
в таблице процессов. При этом упрощается вычисление адреса записи страницы: нужно
лишь прибавить смещение страницы внутри виртуального адресного пространства
к началу области подкачки. Но перед тем как процесс сможет начать работу, область
свопинга должна быть инициализирована. Один из способов инициализации заключается
в копировании всего образа процесса в область свопинга, чтобы его можно было
получать по мере необходимости. Другой способ заключается в загрузке всего процесса
в память и разрешении ему по мере необходимости выгружать страницы.
Но с этой простой моделью связана одна проблема: размеры процессов после их запуска
могут изменяться. Хотя размер текста программы обычно не меняется, область
данных иногда может расти, а стек всегда склонен к росту. Следовательно, может быть
лучше резервировать отдельные области подкачки для текста, данных и стека и давать
возможность каждой из этих областей состоять более чем из одного дискового участка.
Другая крайность заключается в полном отказе от какого-либо предварительного распределения,
выделении дискового пространства для каждой страницы при ее выгрузке
на диск и его изъятии при обратной загрузке страницы в память. При этом находящиеся
в памяти процессы вообще не привязываются к пространству свопинга. Недостаток
такого способа заключается в необходимости хранения в памяти дискового адреса,
чтобы отслеживать на диске каждую страницу. Эти два альтернативных варианта показаны
на рис. 3.26.
Рис. 3.26. Таблица страниц: а — замещение страниц со статической областью подкачки;
б — динамическое резервное хранение страниц
На рис. 3.26, а показана таблица страниц с восемью страницами. Страницы 0, 3, 4 и 6
находятся в оперативной памяти, страницы 1, 2, 5 и 7 — на диске. Размер области свопинга
совпадает по размеру с виртуальным адресным пространством процесса (восемь
страниц), а у каждой страницы есть фиксированное место, в которое она записывается
при удалении из основной памяти. Для вычисления этого адреса нужно знать только
о том, где начинается принадлежащая процессу область замещения страниц, поскольку
страницы хранятся в ней рядом, в порядке их виртуальных номеров. У страницы,
находящейся в памяти, всегда есть ее копия на диске (закрашенная область), но эта
копия может устареть, если страница с момента загрузки подверглась изменению. На
рис. 3.26, а в памяти закрашенными областями показаны отсутствующие в ней страницы.
Страницы, соответствующие закрашенным областям, на диске должны быть
заменены (в принципе) копиями в памяти, хотя, если страница памяти должна быть
сброшена на диск и не подвергалась модификации со времени своей загрузки, то будет
использована ее дисковая (закрашенная) копия.
У страниц, изображенных на рис. 3.26, б нет фиксированных адресов на диске. При
выгрузке страницы на лету выбирается пустая дисковая страница и соответствующим
образом обновляется карта диска (в которой имеется место для одного дискового
адреса на каждую виртуальную страницу). Страница в памяти не имеет своей копии
на диске. Записи страниц на карте диска содержат либо неправильный адрес диска,
либо бит, помечающий их как неиспользующиеся.
Возможность иметь фиксированный раздел подкачки предоставляется не всегда.
Например, могут отсутствовать доступные дисковые разделы. В таком случае может
использоваться один или несколько заранее выделенных файлов внутри обычной
файловой системы. Именно такой подход используется в Windows. Но для уменьшения
объема необходимого дискового пространства здесь может быть использована
оптимизация. Поскольку текст программы каждого процесса берется из какого-нибудь
исполняемого файла, принадлежащего файловой системе, этот исполняемый файл
может быть использован в качестве области подкачки. Еще лучше то, что, поскольку
текст программы обычно имеет статус «Только для чтения», когда в памяти становится
тесно и страницы программы должны быть из нее удалены, они просто считаются
уничтоженными и считываются снова из исполняемого файла по мере надобности.
Таким же образом можно работать и с совместно используемыми библиотеками.
3.6.6. Разделение политики и механизма
Важным инструментом, позволяющим справиться со сложностью любой системы, является
отделение политики от механизма. Этот принцип может быть применен к управлению
памятью за счет запуска основной части диспетчера памяти как процесса на
уровне пользователя. Подобное разделение впервые было предпринято в системе Mach
(Young et al., 1987), на которой построено дальнейшее рассмотрение этого вопроса.
Простой пример того, как могут быть разделены политика и механизм, показан на
рис. 3.27. Здесь система управления памятью разделена на три части:
 низкоуровневую программу управления диспетчером памяти (MMU);
 обработчик ошибки отсутствия страницы, являющийся частью ядра;
 внешнюю программу страничной организации памяти, запущенную в пользовательском
пространстве.
Рис. 3.27. Обработка ошибки отсутствия страницы с использованием внешней системы
страничной организации памяти
Все тонкости работы MMU скрыты в программе управления этим диспетчером памяти,
код которой является машинозависимым и должен переписываться для каждой новой
платформы, на которую переносится операционная система. Обработчик ошибки отсутствия
страницы является машинонезависимым кодом и содержит основную часть
механизма страничной организации памяти. Политика определена в основном внешней
системой страничной организации памяти, запускаемой в виде пользовательского
процесса.
При запуске процесса уведомляется внешняя программа страничной организации,
чтобы установить отображение страниц процесса и выделить в случае необходимости
резервное хранилище на диске. Во время работы процесс может отображать в своем
адресном пространстве новые объекты, о чем опять же уведомляется внешняя программа.

Как только процесс начнет работу, он может столкнуться с ошибкой отсутствия страницы.
Обработчик ошибки определяет, какая виртуальная страница требуется процессу,
и посылает сообщение внешней программе, сообщая ей о возникшей проблеме. Затем
эта внешняя программа считывает нужную страницу с диска и копирует ее в раздел
собственного адресного пространства. Затем она сообщает обработчику, где находится
страница. После этого обработчик ошибки удаляет отображение страницы из адресного
пространства внешней программы и просит управляющую программу MMU поместить
ее в нужное место адресного пространства пользователя. Затем пользовательский процесс
может быть перезапущен.
Эта реализация оставляет открытым вопрос, куда поместить алгоритм замещения
страниц. Казалось бы, ясно, что он должен быть во внешней программе, но реализация
такого подхода сталкивается с рядом проблем. Самой принципиальной из них является
то, что внешняя программа управления страницами не имеет доступа к битам R
и M всех страниц, а эти биты играют важную роль во многих алгоритмах замещения
страниц. Таким образом, либо необходим какой-нибудь механизм для передачи этой
информации вверх внешней программе управления, либо алгоритм замещения страниц
должен быть помещен в ядро. В последнем варианте обработчик ошибки сообщает
внешней программе управления, какую страницу он выбрал для удаления, и предоставляет
данные, либо отображая эту страницу в адресном пространстве внешней
программы управления, либо включая их в сообщение. В любом случае внешняя программа
управления записывает данные на диск.
Основным преимуществом такой реализации является большая модульность кода и более
высокая степень гибкости. Основной недостаток заключается в дополнительных
издержках на неоднократные пересечения границы пользовательского пространства
и пространства ядра, а также в издержках на пересылку между частями системы различных
сообщений. Сейчас вопрос носит весьма спорный характер, но по мере того
как компьютеры становятся все более быстродействующими, а программное обеспечение
— все более сложным, вероятно, большинству разработчиков будет лучше пожертвовать
какой-то долей производительности в пользу более надежного программного
обеспечения.
3.7. Сегментация
До сих пор рассматриваемая виртуальная память была одномерной, поскольку в ней
адреса следовали друг за другом от 0 до некоторого максимального значения. Но для
решения многих проблем наличие двух и более отдельных виртуальных адресных
пространств может быть более рациональным вариантом, чем наличие только одного
адресного пространства. Например, у компилятора имеется множество таблиц, выстраиваемых
в процессе компиляции, к которым могут относиться:
 исходный текст, сохраненный для печати листинга (в пакетных системах);
 таблица имен, содержащая имена и атрибуты переменных;
 таблица, содержащая все используемые константы, как целочисленные, так и с плавающей
точкой;
 дерево разбора, в котором содержится синтаксический анализ программы;
 стек, используемый для вызовов процедур внутри компилятора.
В процессе компиляции каждая из первых четырех таблиц постоянно растет. А последняя
увеличивается и уменьшается в размерах совершенно непредсказуемым образом.
В одномерной памяти этим пяти таблицам должны быть выделены последовательные
участки виртуального адресного пространства, показанные на рис. 3.28.
Рис. 3.28. В одномерном адресном пространстве с разрастающимися таблицами
одна таблица может упереться в другую
Рассмотрим, что получится, если программа содержит намного большее, чем обычно,
количество переменных, но вполне обычное количество всех остальных компонентов.
Участок адресного пространства, выделенный под таблицу имен, может заполниться
до отказа, но для других таблиц может остаться большое количество свободного пространства.

На самом деле здесь нужен способ избавить программиста от необходимости усмирения
увеличивающихся и уменьшающихся в размерах таблиц аналогично тому, как виртуальная
память устраняет беспокойство по поводу организации программы в оверлеи.
Простым и универсальным решением является предоставление машины с большим
количеством совершенно независимых адресных пространств, называемых сегментами.
Каждый сегмент состоит из линейной последовательности адресов от 0 до некоторого
максимума. Длина каждого сегмента может иметь любое значение от 0 до максимально
разрешенного. Различные сегменты могут быть разной длины, как это обычно и случается.
Кроме того, длина сегмента может изменяться в процессе выполнения программы.
Длина сегмента стека может увеличиваться при поступлении в него данных
и уменьшаться при их извлечении из него.
Поскольку каждый сегмент содержит отдельное адресное пространство, различные сегменты
могут разрастаться или сужаться независимо, не влияя друг на друга. Если стек
в соответствующем сегменте, для того чтобы вырасти, нуждается в дополнительном
адресном пространстве, он может его получить, поскольку в его адресном пространстве
нет ничего, во что бы он мог упереться. Разумеется, сегмент может заполниться до
отказа, но обычно сегменты имеют очень большие размеры, поэтому такое случается
крайне редко. Для указания адреса в такой сегментированной, или двумерной, памяти,
программа должна предоставить адрес, состоящий из двух частей: номера сегмента
и адреса внутри этого сегмента. На рис. 3.29 показана сегментированная память, используемая
для рассмотренных ранее таблиц компилятора. На нем показаны пять
независимых сегментов.
Рис. 3.29. Сегментированная память дает возможность каждой таблице разрастаться
или сужаться независимо от всех остальных таблиц
Стоит подчеркнуть, что сегмент — это логический объект. Программист знает это
и использует его именно в этом качестве. Сегмент может содержать процедуру, или
массив, или стек, или набор скалярных переменных, но обычно он не содержит смесь
из разнотипных данных.
Сегментированная память помимо упрощения обращения с разрастающимися или
сужающимися структурами данных имеет и другие преимущества. Если каждая процедура
занимает отдельный сегмент, имея 0 в качестве начального адреса, то компоновка
отдельно скомпилированных процедур существенно упрощается. После того как
все составляющие программу процедуры скомпилированы и скомпонованы, в вызове
процедуры, обращенном к процедуре, в сегменте n будет использован адрес, состоящий
из двух частей (n, 0) и адресованный к слову 0 (к точке входа).
Если впоследствии процедура в сегменте n будет изменена и перекомпилирована, то
изменять другие процедуры уже не придется (поскольку начальные адреса не будут
изменены), даже если новая версия будет больше старой. При использовании одномерной
памяти процедуры компонуются непосредственно друг за другом, без какоголибо
адресного пространства между ними. Следовательно, изменение размеров одной
процедуры повлияет на начальные адреса других (не связанных с ней) процедур
в сегменте. А это, в свою очередь, потребует изменения всех процедур, из которых вызываются
любые перемещенные процедуры, чтобы учесть их новые начальные адреса.
Если программа содержит несколько сотен процедур, этот процесс может стать весьма
затратным.
Сегментация также облегчает совместное использование процедур или данных несколькими
процессами. Типичным примером может послужить совместно используемая
библиотека. Современные рабочие станции, работающие с передовыми оконными
системами, зачастую используют весьма объемные графические библиотеки, откомпилированные
чуть ли не в каждой программе. В сегментированной системе графические
библиотеки могут быть помещены в сегмент и совместно использоваться несколькими
процессами, исключая потребность в своем присутствии в адресном пространстве каждого
процесса. Хотя совместно используемые библиотеки можно иметь и в системах,
построенных только на страничной организации памяти, но в них это достигается значительно
сложнее. В сущности, в этих системах подобное использование реализуется
путем моделирования сегментации.
Поскольку каждый сегмент формирует известный программисту логический объект,
например процедуру, или массив, или стек, у разных сегментов могут быть разные виды
защиты. Сегмент процедуры может быть определен только как исполняемый, с запрещением
попыток что-либо в нем прочитать или сохранить. Массив чисел с плавающей
точкой может быть определен для чтения и записи, но не для выполнения, и попытки
передать ему управление будут отловлены. Подобная защита весьма полезна при выявлении
ошибок программирования.
Сравнение страничной организации памяти и сегментации приведено в табл. 3.3.
Таблица 3.3. Сравнение страничной организации памяти и сегментации
Вопрос Страничная
организация
Сегментация
Нужно ли программисту знать, что используется
именно эта технология?
Нет Да
Сколько имеется линейных адресных
пространств?
1 Много
Может ли все адресное пространство
превысить размер физической
памяти?
Да Да
Могут ли различаться и быть отдельно
защищены процедуры и данные?
Нет Да
Можно ли без особого труда предоставить
пространство таблицам, изменяющим
свой размер?
Нет Да
Облегчается ли для пользователей совместный
доступ к процедурам?
Нет Да
Вопрос Страничная
организация
Сегментация
Зачем была изобретена эта технология?

Для получения большого
линейного адресного
пространства без
приобретения дополнительной
физической
памяти
Чтобы дать возможность
разбить программы и данные
на логически независимые
адресные пространства
и облегчить их совместное
использование и защиту
3.7.1. Реализация чистой сегментации
Реализация сегментации существенным образом отличается от реализации страничной
организации памяти: страницы имеют фиксированный размер, а сегменты его не имеют.
На рис. 3.30, а показан пример физической памяти, изначально имеющей пять сегментов.
Теперь рассмотрим, что получится, если сегмент 1 удаляется, а на его место помещается
меньший по размеру сегмент 7. У нас получится конфигурация памяти, показанная на
рис. 3.30, б. Между сегментами 7 и 2 будет неиспользуемая область, то есть дыра. Затем
сегмент 4 заменяется сегментом 5 (рис. 3.30, в), а сегмент 3 — сегментом 6 (рис. 3.30, г).
Рис. 3.30. Физическая память: а — г — нарастание внешней фрагментации;
д — избавление от внешней фрагментации за счет уплотнения
После того как система какое-то время поработает, память разделится на несколько
участков, часть из которых будут содержать сегменты, а часть — дыры. Это явление,
названное явлением шахматной доски, или внешней фрагментацией, приводит к пустой
трате памяти на дыры. С ним можно справиться за счет уплотнения (рис. 3.30, д).
3.7.2. Сегментация со страничной организацией памяти:
система MULTICS
При большом размере сегментов может стать неудобно или даже невозможно хранить
их целиком в оперативной памяти. Это наталкивает на идею применения к ним страничной
организации, чтобы иметь дело только с теми страницами сегмента, которые
нужны в данный момент. Поддержка страничных сегментов реализована в нескольких
важных для нас системах. В этом разделе мы рассмотрим первую из таких систем,
MULTICS. В следующем разделе обратимся к более современной системе Intel x86 —
вплоть до x86-64.
Операционная система MULTICS была одной из самых влиятельных из когда-либо
созданных операционных систем, оказавших серьезное воздействие на такие довольно-таки
несхожие темы, как UNIX, архитектура памяти x86, TLB-буферы и облачные
вычисления. Ее создание началось с исследовательского проекта M.I.T., а в реальную
жизнь она была запущена в 1969 году. Последняя MULTICS-система, проработавшая
31 год, была остановлена в 2000-м. Немногим операционным системам удалось прожить
без существенных изменений столь долгую жизнь. Несмотря на весьма продолжительное
существование операционных систем под названием Windows, Windows 8
не имеет ничего общего с Windows 1.0, за исключением названия и того факта, что она
была написана компанией Microsoft.
Более того, идеи, проработанные в MULTICS, не утратили своей актуальности и полезности
и в том виде, в котором они были сформулированы в 1965 году, когда была
опубликована первая статья (Corbató и Vyssotsky, 1965). Поэтому мы сейчас потратим
немного времени на рассмотрение одного из наиболее инновационных аспектов
MULTICS — архитектуры виртуальной памяти. Дополнительные сведения о MULTICS
можно найти по адресу  www.multicians.org .
Система MULTICS работала на машинах Honeywell 6000 и их потомках и обеспечивала
каждую программу виртуальной памятью размером вплоть до 2 18 сегментов, каждый
из которых был до 65 536 (36-разрядных) слов длиной. Чтобы осуществить это, разработчики
системы MULTICS решили трактовать каждый сегмент как виртуальную
память и разбить его на страницы, комбинируя преимущества страничной организации
памяти (постоянный размер страницы и отсутствие необходимости хранения целого
сегмента в памяти, если используется только его часть) с преимуществом сегментации
(облегчение программирования, модульности, защиты и совместного доступа).
Каждая программа в системе MULTICS использовала таблицу сегментов, в которой
имелось по одному дескриптору на каждый сегмент. Поскольку потенциальное количество
записей в таблице превышало четверть миллиона, сама таблица сегментов
также являлась сегментом и была разбита на страницы. Дескриптор сегмента содержал
индикатор того, находится ли сегмент в памяти или нет. Если какая-то часть сегмента
присутствовала в памяти, считалось, что в памяти находится весь сегмент и его таблица
страниц будет в памяти. Если сегмент находился в памяти, то его дескриптор
(рис. 3.31, а) содержал 18-разрядный указатель на его таблицу страниц. Поскольку
использовались 24-разрядные физические адреса, а страницы выстраивались по
64-байтным границам (предполагалось, что 6 бит низших разрядов адреса страницы —
это 000000), для хранения в дескрипторе адреса таблицы страниц необходимо было
только 18 бит. Дескриптор содержал также размер сегмента, биты защиты и несколько
других полей. Дескриптор сегмента в системе MULTICS показан на рис. 3.31, б. Адрес
сегмента во вспомогательной памяти находился не в дескрипторе сегмента, а в другой
таблице, используемой обработчиком ошибки отсутствия сегмента.
Каждый сегмент представлял собой обыкновенное виртуальное адресное пространство
и был разбит на страницы точно так же, как и несегментированная страничная память,
рассмотренная ранее в этой главе. Обычный размер страницы был равен 1024 словам
Рис. 3.31. Виртуальная память в системе MULTICS: а — сегмент дескрипторов указывает
на таблицы страниц; б — дескриптор сегмента. Числа означают длину полей
(хотя ряд несколько меньших по размеру сегментов, используемых самой системой
MULTICS, не были разбиты на страницы или все же для экономии физической памяти
были разбиты на страницы по 64 слова).
Адрес в системе MULTICS состоял из двух частей: сегмента и адреса внутри сегмента.
Последний, в свою очередь, делился на номер страницы и слово внутри страницы
(рис. 3.32).
Когда происходило обращение к памяти, выполнялся следующий алгоритм:
1. Номер сегмента использовался для нахождения дескриптора сегмента.
2. Проверялось, находится ли таблица страниц сегмента в памяти. Если таблица
страниц присутствовала в памяти, определялось ее местоположение. Если таблица
в памяти отсутствовала, возникала ошибка отсутствия сегмента. При нарушении
защиты возникала ошибка (происходило системное прерывание).
3. Изучалась запись в таблице страниц для запрашиваемой виртуальной страницы.
Если страница не находилась в памяти, возникала ошибка отсутствия страницы.
Если она была в памяти, из записи таблицы страниц извлекался адрес начала
страницы в оперативной памяти.
4. К адресу начала страницы прибавлялось смещение, что давало в результате адрес
в оперативной памяти, по которому располагалось нужное слово.
5. И наконец, осуществлялось чтение или сохранение данных.
Рис. 3.32. 34-разрядный виртуальный адрес в системе MULTICS
Этот процесс показан на рис. 3.33. Чтобы его упростить, был опущен тот факт, что
сегмент дескрипторов сам по себе имел страничную организацию. На самом деле происходило
следующее: сначала использовался регистр (основной регистр дескриптора),
чтобы определить расположение таблицы страниц сегмента дескрипторов, которая
в свою очередь указывала на страницы сегмента дескрипторов. Как только дескриптор
для требуемого сегмента находился, происходила адресация (рис. 3.33).
Рис. 3.33. Преобразование состоящего из двух частей адреса в системе MULTICS в адрес
в оперативной памяти
Как вы теперь уже, безо всякого сомнения, догадались, если бы на практике предыдущий
алгоритм выполнялся операционной системой для каждой команды процессора, работа
программ не отличалась бы особой быстротой. В действительности аппаратура системы
MULTICS содержала высокоскоростной буфер быстрого преобразования адреса (TLB)
размером 16 слов, который был способен производить поиск параллельно по всем своим
записям для заданного ключа. Этот процесс показан на рис. 3.34. Когда компьютер
получал адрес, аппаратура адресации сначала проверяла наличие виртуального адреса
в TLB. Если этот адрес присутствовал в буфере, она получала номер страничного блока
прямиком из TLB и формировала фактический адрес слова, к которому происходило
обращение, не выполняя поиск в сегменте дескрипторов или в таблице страниц.
Рис. 3.34. Простейший вариант TLB в системе MULTICS. На самом деле наличие страниц
двух размеров делает строение TLB более сложным
В буфере быстрого преобразования адреса хранились адреса 16 страниц, к которым
происходили самые последние обращения. Программы, у которых рабочий набор был
меньше размера TLB, хранили адреса всего рабочего набора в TLB, и следовательно, эти
программы работали эффективно, в противном случае происходила ошибка TLB.
3.7.3. Сегментация со страничной организацией памяти:
система Intel x86
До появления x86-64 виртуальная память в системе x86 во многих отношениях напоминала
память в системе MULTICS, включая наличие как сегментации, так и страничной
организации. Но система MULTICS имела 256 K независимых сегментов, каждый
до 64 К 36-разрядных слов, а система x86 поддерживает 16 K независимых сегментов,
каждый до 1 млрд 32-разрядных слов. Хотя в последней системе меньше сегментов,
их больший размер куда важнее, поскольку программы, которым требуется более чем
1000 сегментов, встречаются довольно редко, в то время как многим программам необходимы
большие по размеру сегменты. Что же касается x86-64, то сегментация считается
устаревшей и больше не поддерживается, исключая работу в унаследованном режиме.
Хотя некоторые остатки старых механизмов сегментации в исходном режиме работы
систем x86-64 все еще доступны, главным образом для обеспечения совместимости, они
больше не играют ту же роль и не предлагают реальную сегментацию. Но системы x86-32
до сих пор поставляются оборудованными по полной схеме, и именно этот центральный
процессор и будет рассматриваться в данном разделе.
Основа виртуальной памяти системы x86 состоит их двух таблиц: локальной таблицы
дескрипторов (Local Descriptor Table (LDT)) и глобальной таблицы дескрипторов
(Global Descriptor Table (GDT)). У каждой программы есть собственная таблица LDT,
но глобальная таблица дескрипторов, которую совместно используют все программы
в компьютере, всего одна. В таблице LDT описываются сегменты, локальные для каждой
программы, включая код этих программ, их данные, стек и т. д., а в таблице GDT
описываются системные сегменты, включая саму операционную систему.
Чтобы получить доступ к сегменту, программа, работающая в системе x86, сначала загружает
селектор для этого сегмента в один из шести сегментных регистров машины.
Во время выполнения программы регистр CS содержит селектор для сегмента кода,
а регистр DS хранит селектор для сегмента данных. Каждый селектор (рис. 3.35) представляет
собой 16-разрядное целое число.
Рис. 3.35. Селектор системы Pentium
Один из битов селектора несет информацию о том, является ли данный сегмент локальным
или глобальным (то есть к какой таблице дескрипторов он относится, локальной
или глобальной). Следующие 13 битов определяют номер записи в таблице дескрипторов,
поэтому в каждой из этих таблиц не может содержаться более чем 8 К сегментных
дескрипторов. Остальные 2 бита имеют отношение к защите и будут рассмотрены
позже. Дескриптор 0 запрещен. Его можно без всякой опаски загрузить в сегментный
регистр, чтобы обозначить, что этот сегментный регистр в данный момент недоступен.
Попытка им воспользоваться приведет к системному прерыванию.
Во время загрузки селектора в сегментный регистр из локальной или глобальной
таблицы дескрипторов извлекается соответствующий дескриптор, который, чтобы
ускорить к нему обращение, сохраняется в микропрограммных регистрах. Как показано
на рис. 3.36, дескриптор состоит из 8 байтов, в которые входят базовый адрес сегмента,
размер и другая информация.
Чтобы облегчить определение местоположения дескриптора, был искусно подобран
формат селектора. Сначала на основе бита 2 селектора выбирается локальная или
глобальная таблица дескрипторов. Затем селектор копируется во внутренний рабочий
регистр, и значения трех младших битов устанавливаются в 0. Наконец, к этой копии
прибавляется адрес одной из таблиц, LDT или GDT, чтобы получить прямой указатель
на дескриптор. Например, селектор 72 ссылается на запись 9 в глобальной таблице
дескрипторов, которая расположена по адресу в таблице GDT + 72.
Теперь проследим шаги, с помощью которых пара (селектор, смещение) преобразуется
в физический адрес. Как только микропрограмма узнает, какой сегментный регистр
бита
Рис. 3.36. Дескриптор сегмента кода в системе Pentium.
Сегменты данных имеют незначительные отличия
используется, она может найти в своих внутренних регистрах полный дескриптор, соответствующий
этому селектору. Если сегмент не существует (селектор равен 0) или
в данный момент выгружен, возникает системное прерывание.
Затем аппаратура использует поле предела Limit, чтобы проверить, не выходит ли смещение
за предел сегмента, и в этом случае также возникает системное прерывание. По
логике, для предоставления размера сегмента в дескрипторе должно быть 32-разрядное
поле, но доступны только 20 бит, поэтому используется другая схема. Если поле Gbit
(Granularity — степень детализации) равно 0, в поле Limit содержится точный размер
сегмента вплоть до 1 Мбайт. Если оно равно 1, то в поле Limit предоставляется размер
сегмента в страницах, а не в байтах. При размере страниц, равном 4 Кбайт, 20 битов
вполне достаточно для сегментов размером до 2 32 байт.
Предположим, что сегмент находится в памяти и смещение попало в нужный интервал,
тогда система x86 прибавляет 32-разрядное поле Base (база) в дескрипторе к смещению,
формируя то, что называется линейным адресом (рис. 3.37). Поле Base разбито
на три части, которые разбросаны по дескриптору для совместимости с процессором
Intel 80286, в котором поле Base имеет только 24 бита. В сущности, поле Base позволяет
каждому сегменту начинаться в произвольном месте внутри 32-разрядного линейного
адресного пространства.
Рис. 3.37. Преобразование пары «селектор — смещение» в линейный адрес
Если страничная организация отключена (установкой бита в глобальном управляющем
регистре), линейный адрес интерпретируется как физический адрес и посылается
в память для чтения или записи. Таким образом, при отключенной страничной схеме
памяти мы получаем чистую схему сегментации с базовым адресом каждого сегмента,
выдаваемым его дескриптором. Сегменты не предохранены от наложения друг на друга,
возможно, из-за слишком больших хлопот и слишком больших временных затрат на
проверку того факта, что все они друг от друга отделены.
С другой стороны, если включена подкачка страниц, линейный адрес интерпретируется
как виртуальный и отображается на физический адрес с помощью таблицы
страниц практически так же, как в предыдущих примерах. Единственное реальное
затруднение заключается в том, что при 32-разрядном виртуальном адресе и странице
размером 4 Кбайт сегмент может содержать 1 млн страниц, поэтому используется
двухуровневое отображение с целью уменьшения размера таблицы страниц для небольших
сегментов.
У каждой работающей программы есть страничный каталог, состоящий из 1024 32-разрядных
записей. Он расположен по адресу, который указан в глобальном регистре.
Каждая запись в каталоге указывает на таблицу страниц, также содержащую 1024
32-разрядных записи. Записи в таблицах страниц, в свою очередь, указывают на страничные
блоки. Эта схема показана на рис. 3.38.
Рис. 3.38. Отображение линейного адреса на физический
Здесь показан линейный адрес, разделенный на три поля: Каталог, Страница и Смещение.
Поле Каталог используется как индекс в страничном каталоге, определяющий
расположение указателя на правильную таблицу страниц. Поле Страница используется
в качестве индекса в таблице страниц, чтобы найти физический адрес страничного
блока. И наконец, чтобы получить физический адрес требуемого байта или слова,
к адресу страничного блока прибавляется поле Смещение.
Каждая запись в таблице страниц имеет размер 32 бита, 20 из которых содержат номер
страничного блока. Остальные биты включают в себя биты доступа и бит изменения
страницы, устанавливаемые аппаратурой для операционной системы, биты защиты
и другие полезные биты.
Каждая таблица страниц включает в себя записи для 1024 страничных блоков размером
по 4 Кбайт, таким образом, одна таблица страниц справляется с 4 Мбайт памяти. Сегмент,
длина которого меньше 4 Мбайт, будет иметь страничный каталог с единственной
записью — указателем на его единственную таблицу страниц. Следовательно, в случае
короткого сегмента на поддержку таблиц страниц расходуется только две страницы
вместо 1 млн, которые были бы нужны в одноуровневой таблице страниц.
Чтобы избежать повторных обращений к памяти, система x86, как и система MULTICS,
имеет небольшой буфер быстрого преобразования адреса (TLB), который напрямую
отображает наиболее часто использующиеся комбинации Каталог — Страница на
физический адрес страничного блока. Механизм, показанный на рис. 3.38, задействуется
лишь при отсутствии текущей комбинации в буфере TLB, при этом сам буфер
обновляется. Если отсутствие нужной информации в буфере TLB встречается довольно
редко, система достигает неплохой производительности.
Также следует отметить, что эта модель работает и в том случае, когда некоторые
приложения не требуют сегментации, а просто довольствуются единым, разбитым на
страницы 32-разрядным адресным пространством. Все сегментные регистры могут
быть настроены тем же самым селектором, в дескрипторе которого поле Base = 0, а поле
Limit установлено на максимум. Тогда смещение команды будет линейным адресом
и будет использоваться только одно адресное пространство, что приведет к обычной
страничной организации памяти. Фактически таким образом работают все современные
операционные системы для компьютера x86. Единственным исключением была
система OS/2, в которой использовались все возможности архитектуры диспетчера
памяти (MMU) фирмы Intel.
Так почему же Intel отменила то, что было вариантом весьма неплохой модели памяти
MULTICS, поддерживаемой на протяжении почти трех десятилетий? Возможно, основной
причиной стало то, что ни UNIX, ни Windows никогда не использовали этот
вариант, несмотря на его высокую эффективность, по причине исключения системных
вызовов и превращения их в молниеносные вызовы процедур по соответствующим
адресам внутри защищенного сегмента операционной системы. Ни один из разработчиков
любой UNIX- или Windows-системы не захотел менять свою модель памяти
на нечто присущее только x86, так как это нарушило бы переносимость на другие
платформы. Поскольку эта возможность оказалась невостребованной со стороны программного
обеспечения, компании Intel надоело тратить впустую площадь микросхемы
на ее поддержку и из 64-разрядных процессоров она была убрана.
В конце концов, кто-то же должен похвалить разработчиков системы x86. При столь
противоречивых задачах: реализовать чистую страничную организацию памяти, чистое
сегментирование и страничные сегменты и в то же время обеспечить совместимость
с 286-м процессором, а кроме того, сделать все это эффективно, — у них получилась
удивительно простая и понятная конструкция.
3.8. Исследования в области управления памятью
Традиционное управление памятью, особенно алгоритмы замещения страниц для центральных
процессоров с одним ядром, когда-то было весьма плодотворной областью
исследований, но, похоже, большая часть этих исследований, по крайней мере для
универсальных систем, в настоящее время уже отмерла, хотя имеются и те, кто с этим
категорически не согласен (Moruz et al., 2012) или сосредоточился на некоторых приложениях,
таких как оперативная обработка транзакций, которая имеет специализированные
требования (Stoica and Ailamaki, 2013). Даже на однопроцессорных системах
замещение страниц на твердотельных накопителях, а не на жестких дисках вызвало
новые вопросы и потребовало новых алгоритмов (Chen et al., 2012). Замещение страниц
на многообещающей энергонезависимой памяти на основе фазовых переходов также
потребовало переосмысления этого замещения с целью повышения производительности
(Lee et al., 2013), а также по причине задержек (Saito and Oikawa, 2012) или износа
при слишком интенсивном использовании (Bheda et al., 2011, 2012).
В целом исследования по замещению страниц все еще продолжаются, но сосредотачиваются
на новых видах систем. Например, интерес к управлению памятью возродили
виртуальные машины (Bugnion et al., 2012). К той же области относится и работа Jantz
et al. (2013), позволяющая приложениям ориентировать систему относительно принятия
решения о физической странице для поддержки виртуальной страницы. Требует
новых алгоритмов и аспект объединения серверов в облаке, что влияет на замещение
страниц из-за возможности изменения со временем того объема физической памяти,
который доступен виртуальной машине (Peserico, 2013).
Новой областью активных исследований стало замещение страниц в многоядерных
системах (Boyd-Wickizer et al., 2008, Baumann et al., 2009). Одним из побуждающих
факторов является стремление иметь в многоядерных системах множество кэшей, совместно
используемых довольно сложными путями (Lopez-Ortiz and Salinger, 2012).
Тесно связанным с этой работой по многоядерности является исследование замещения
страниц в NUMA-системах, где к разным частям памяти может быть разное время доступа
(Dashti et al., 2013; Lankes et al., 2012).
Кроме того, в небольшие персональные компьютеры превратились смартфоны и планшетные
устройства, и многие из них сбрасывают страницы оперативной памяти на
«диск», вот только в качестве диска у них выступает флеш-память. О некоторых последних
работах имеется сообщение от Joo et al. (2012).
И наконец, по-прежнему существует интерес к управлению памятью в системах реального
времени (Kato et al., 2011).
3.9. Краткие выводы
Эта глава была посвящена исследованию вопросов управления памятью. Мы увидели,
что свопинг или страничная организация памяти в простейших системах вообще не
используются. Программа, загруженная в память, остается в ней до своего завершения.
Некоторые операционные системы не позволяют находиться в памяти более чем одному
процессу, в то время как другие поддерживают многозадачность. Эта модель все
еще распространена на небольших встроенных системах реального времени.
Следующим шагом стал свопинг. При его использовании система может работать
с таким количеством процессов, которое превышает возможности памяти по их одновременному
размещению. Процессы, для которых не хватает места в памяти, целиком
выгружаются на диск. Свободные области в памяти и на диске могут отслеживаться
с помощью битовой матрицы или списка свободных участков.
Современные компьютеры зачастую поддерживают одну из форм виртуальной памяти.
В простейшем виде адресное пространство каждого процесса делится на одинаковые по
размеру блоки, называемые страницами, которые могут размещаться в любом доступном
страничном блоке в памяти. Существует множество алгоритмов замещения страниц,
наиболее подходящими из которых являются алгоритмы «старения» и WSClock.
Одного выбора алгоритма еще недостаточно, чтобы добиться от систем со страничной
организацией памяти приемлемой работы, необходимо обратить внимание на такие
вопросы, как определение рабочего набора, политика выделения памяти и размер
страниц.
Сегментация помогает в управлении структурами данных, изменяющими свой размер
во время выполнения программы, и упрощает процессы компоновки и совместного
доступа. Она также облегчает предоставление различных видов защиты разным сегментам.
Иногда сегментация и разбивка на страницы комбинируются, предоставляя
двумерную виртуальную память. Сегментация и страничная организация памяти
поддерживаются такими системами, как MULTICS и 32-разрядная Intel x86. Вполне
очевидно, что разработчики операционных систем теперь вряд ли сильно озабочены
сегментацией (поскольку сделали ставку на другую модель памяти). Следовательно,
похоже, что она очень быстро выйдет из моды. Сейчас поддержка реальной сегментации
отсутствует даже на 64-разрядных версиях x86.
